{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PBqKPKFtsiKi"
   },
   "source": [
    "## データの読込"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "id": "TSY5GPLirTwt",
    "outputId": "e2812df2-85c3-45b9-9891-d35b4b9cb7c5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>basename</th>\n",
       "      <th>Genre</th>\n",
       "      <th>ESRB_Rating</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Developer</th>\n",
       "      <th>VGChartz_Score</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>...</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>PAL_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Year</th>\n",
       "      <th>Last_Update</th>\n",
       "      <th>url</th>\n",
       "      <th>status</th>\n",
       "      <th>Vgchartzscore</th>\n",
       "      <th>img_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Wii Sports</td>\n",
       "      <td>wii-sports</td>\n",
       "      <td>Sports</td>\n",
       "      <td>E</td>\n",
       "      <td>Wii</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>Nintendo EAD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.7</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.vgchartz.com/game/2667/wii-sports/?...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/games/boxart/full_2258645AmericaFrontccc.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Super Mario Bros.</td>\n",
       "      <td>super-mario-bros</td>\n",
       "      <td>Platform</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NES</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>Nintendo EAD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.vgchartz.com/game/6455/super-mario-...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/games/boxart/8972270ccc.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Mario Kart Wii</td>\n",
       "      <td>mario-kart-wii</td>\n",
       "      <td>Racing</td>\n",
       "      <td>E</td>\n",
       "      <td>Wii</td>\n",
       "      <td>Nintendo</td>\n",
       "      <td>Nintendo EAD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>11th Apr 18</td>\n",
       "      <td>http://www.vgchartz.com/game/6968/mario-kart-w...</td>\n",
       "      <td>1</td>\n",
       "      <td>8.7</td>\n",
       "      <td>/games/boxart/full_8932480AmericaFrontccc.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank               Name          basename     Genre ESRB_Rating Platform  \\\n",
       "0     1         Wii Sports        wii-sports    Sports           E      Wii   \n",
       "1     2  Super Mario Bros.  super-mario-bros  Platform         NaN      NES   \n",
       "2     3     Mario Kart Wii    mario-kart-wii    Racing           E      Wii   \n",
       "\n",
       "  Publisher     Developer  VGChartz_Score  Critic_Score  ...  NA_Sales  \\\n",
       "0  Nintendo  Nintendo EAD             NaN           7.7  ...       NaN   \n",
       "1  Nintendo  Nintendo EAD             NaN          10.0  ...       NaN   \n",
       "2  Nintendo  Nintendo EAD             NaN           8.2  ...       NaN   \n",
       "\n",
       "   PAL_Sales  JP_Sales  Other_Sales    Year  Last_Update  \\\n",
       "0        NaN       NaN          NaN  2006.0          NaN   \n",
       "1        NaN       NaN          NaN  1985.0          NaN   \n",
       "2        NaN       NaN          NaN  2008.0  11th Apr 18   \n",
       "\n",
       "                                                 url  status Vgchartzscore  \\\n",
       "0  http://www.vgchartz.com/game/2667/wii-sports/?...       1           NaN   \n",
       "1  http://www.vgchartz.com/game/6455/super-mario-...       1           NaN   \n",
       "2  http://www.vgchartz.com/game/6968/mario-kart-w...       1           8.7   \n",
       "\n",
       "                                         img_url  \n",
       "0  /games/boxart/full_2258645AmericaFrontccc.jpg  \n",
       "1                   /games/boxart/8972270ccc.jpg  \n",
       "2  /games/boxart/full_8932480AmericaFrontccc.jpg  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"vgsales-12-4-2019.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4jFtERsyeJBr"
   },
   "source": [
    "## Optunaによるハイパーパラメーターチューニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T-3ptRZReJHh",
    "outputId": "c3ee7955-155d-49e1-c978-015dfab5223e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from natsort import natsorted \n",
    "\n",
    "import lightgbm as lgb\n",
    "import optuna.integration.lightgbm as opt_lgb\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import category_encoders as ce\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ixrhYZWzeeLB"
   },
   "outputs": [],
   "source": [
    "# シード値の固定\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "XBxmLMFEex0k"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                                    df.dropna(subset=[\"Global_Sales\"]).drop([\"Global_Sales\",  \"NA_Sales\", \"PAL_Sales\", \"JP_Sales\", \"Other_Sales\"], axis=1), \n",
    "                                                    df.dropna(subset=[\"Global_Sales\"])[\"Global_Sales\"],  \n",
    "                                                    test_size=0.3,\n",
    "                                                    shuffle=True, \n",
    "                                                    random_state=SEED\n",
    "                                                    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vR0hQtv_e6lV"
   },
   "outputs": [],
   "source": [
    "### 欠損値補完\n",
    "X_train_ff = X_train.fillna(method='ffill')\n",
    "X_test_ff = X_test.fillna(method='ffill')\n",
    "\n",
    "#### カテゴリーエンコーディング\n",
    "\n",
    "# ユニーク数に応じてカラムを分割する\n",
    "category_unique_num = X_train_ff.select_dtypes(include=\"object\").nunique()\n",
    "\n",
    "few_kinds_category_columns = category_unique_num[category_unique_num < 10].index\n",
    "many_kinds_category_columns = category_unique_num[category_unique_num >= 10].index\n",
    "\n",
    "\n",
    "# カテゴリーのエンコーディング法則を指定する\n",
    "ordinal_all_cols_mapping_ce = []\n",
    "\n",
    "for i, column in enumerate(many_kinds_category_columns):\n",
    "    ordinal_one_cols_mapping = {}\n",
    "    ordinal_one_cols_mapping_breakdown = {}\n",
    "    for j, category in enumerate(natsorted(X_train_ff[column].unique())):\n",
    "        ordinal_one_cols_mapping_breakdown[category] = j\n",
    "\n",
    "    ordinal_one_cols_mapping[\"col\"] = column\n",
    "    ordinal_one_cols_mapping[\"mapping\"] = ordinal_one_cols_mapping_breakdown\n",
    "    ordinal_all_cols_mapping_ce.append(ordinal_one_cols_mapping)\n",
    "\n",
    "\n",
    "# エンコーディング設定\n",
    "ode = ce.OrdinalEncoder(\n",
    "    mapping = ordinal_all_cols_mapping_ce,\n",
    "    cols = many_kinds_category_columns\n",
    ")\n",
    "\n",
    "ohe = ce.OneHotEncoder(\n",
    "    use_cat_names=True,\n",
    "    cols = few_kinds_category_columns\n",
    ")\n",
    "\n",
    "# 元データをコピー\n",
    "X_train_ce = X_train_ff.copy()\n",
    "X_test_ce = X_test_ff.copy()\n",
    "\n",
    "# OneHotEncoder\n",
    "X_train_ce = ohe.fit_transform(X_train_ce)\n",
    "X_test_ce = ohe.transform(X_test_ce)\n",
    "\n",
    "# OrdinalHotEncoder\n",
    "X_train_ce = ode.fit_transform(X_train_ce)\n",
    "X_test_ce = ode.transform(X_test_ce)\n",
    "\n",
    "# 正規化\n",
    "sc = StandardScaler()\n",
    "X_train_ce = pd.DataFrame(\n",
    "                            sc.fit_transform(X_train_ce),\n",
    "                            columns=X_train_ce.columns\n",
    "                            )\n",
    "\n",
    "X_test_ce = pd.DataFrame(\n",
    "                            sc.transform(X_test_ce),\n",
    "                            columns=X_test_ce.columns\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DTolOrbwiZNk",
    "outputId": "03e08605-f0f0-4f37-805b-d27aa3ecf015"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001260 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\tTrain's rmse: 0.145024\tTest's rmse: 0.345074\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000836 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.148628\tTest's rmse: 0.111997\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.146988\tTest's rmse: 0.141503\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\tTrain's rmse: 0.165773\tTest's rmse: 0.0217725\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000881 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\tTrain's rmse: 0.15906\tTest's rmse: 0.373033\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: [0.3450743092184951, 0.1119966357028154, 0.141502625741997, 0.021772539884382606, 0.37303280298429786]\n",
      "RMSE: 0.1986757827063976\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train.reset_index(drop=True)\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "groups = X_train_ce[\"Genre\"]\n",
    "\n",
    "params = {\n",
    "          'task': 'train',              # タスクを訓練に設定\n",
    "          'boosting_type': 'gbdt',      # GBDTを指定\n",
    "          'objective': 'regression',    # 回帰を指定\n",
    "          'metric': {'rmse'},           # 回帰の損失（誤差）\n",
    "          'learning_rate': 0.1,         # 学習率\n",
    "          'seed': SEED                   # シード値\n",
    "          }\n",
    "\n",
    "cv_result = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(gkf.split(X_train_ce, y_train, groups)):\n",
    "    X_train_gkf, X_test_gkf = X_train_ce.iloc[train_index], X_train_ce.iloc[test_index]\n",
    "    y_train_gkf, y_test_gkf = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "    # 学習、推論\n",
    "    lgb_train = lgb.Dataset(X_train_gkf, y_train_gkf)\n",
    "    lgb_test = lgb.Dataset(X_test_gkf, y_test_gkf, reference=lgb_train)\n",
    "\n",
    "    lgb_results = {}                                    # 学習の履歴を入れる入物\n",
    "\n",
    "    model = lgb.train(\n",
    "                    params=params,                    # ハイパーパラメータをセット\n",
    "                    train_set=lgb_train,              # 訓練データを訓練用にセット\n",
    "                    valid_sets=[lgb_train, lgb_test], # 訓練データとテストデータをセット\n",
    "                    valid_names=['Train', 'Test'],    # データセットの名前をそれぞれ設定\n",
    "                    num_boost_round=100,              # 計算回数\n",
    "                    early_stopping_rounds=50,         # アーリーストッピング設定\n",
    "                    evals_result=lgb_results,\n",
    "                    verbose_eval=-1,                  # ログを最後の1つだけ表示\n",
    "                    )  \n",
    "\n",
    "    # 損失推移を表示\n",
    "    loss_train = lgb_results['Train']['rmse']\n",
    "    loss_test = lgb_results['Test']['rmse']   \n",
    "    \n",
    "    fig = plt.figure()\n",
    "    \n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('logloss')\n",
    "\n",
    "    plt.title(f\"fold:{fold}\")\n",
    "    plt.plot(loss_train, label='train loss')\n",
    "    plt.plot(loss_test, label='test loss')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # 推論\n",
    "    y_pred = model.predict(X_test_gkf)\n",
    "\n",
    "    # 評価\n",
    "    rmse = mean_squared_error(y_test_gkf, y_pred, squared=False)\n",
    "    cv_result.append(rmse)\n",
    "\n",
    "print(\"RMSE:\", cv_result)\n",
    "print(\"RMSE:\", np.mean(cv_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jio6I7-pjVxD"
   },
   "source": [
    "### optuna.integration.lightgbm によるハイパーパラメーター調整実施\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "tkisg38iezSL",
    "outputId": "03f0bcc4-c5aa-4685-f3c0-8cdb05bae12e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:20:23,208]\u001b[0m A new study created in memory with name: no-name-07ba7d79-8fef-4da7-82d8-b888c408d729\u001b[0m\n",
      "feature_fraction, val_score: inf:   0%|                                                          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001392 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.341230:  14%|######4                                      | 1/7 [00:00<00:01,  3.68it/s]\u001b[32m[I 2021-12-27 16:20:23,584]\u001b[0m Trial 0 finished with value: 0.3412301298956539 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 0.3412301298956539.\u001b[0m\n",
      "feature_fraction, val_score: 0.341230:  14%|######4                                      | 1/7 [00:00<00:01,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[39]\tTrain's rmse: 0.148039\tTest's rmse: 0.34123\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001869 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.341230:  29%|############8                                | 2/7 [00:00<00:01,  3.90it/s]\u001b[32m[I 2021-12-27 16:20:23,829]\u001b[0m Trial 1 finished with value: 0.36319818283332056 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 0.3412301298956539.\u001b[0m\n",
      "feature_fraction, val_score: 0.341230:  29%|############8                                | 2/7 [00:00<00:01,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.119969\tTest's rmse: 0.363198\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000425 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.341230:  43%|###################2                         | 3/7 [00:00<00:01,  3.50it/s]\u001b[32m[I 2021-12-27 16:20:24,150]\u001b[0m Trial 2 finished with value: 0.35158111665403585 and parameters: {'feature_fraction': 0.5}. Best is trial 0 with value: 0.3412301298956539.\u001b[0m\n",
      "feature_fraction, val_score: 0.341230:  43%|###################2                         | 3/7 [00:00<00:01,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.112125\tTest's rmse: 0.351581\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.341230:  57%|#########################7                   | 4/7 [00:01<00:00,  3.61it/s]\u001b[32m[I 2021-12-27 16:20:24,413]\u001b[0m Trial 3 finished with value: 0.34334969762085965 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 0.3412301298956539.\u001b[0m\n",
      "feature_fraction, val_score: 0.341230:  57%|#########################7                   | 4/7 [00:01<00:00,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[39]\tTrain's rmse: 0.153983\tTest's rmse: 0.34335\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002034 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.341230:  71%|################################1            | 5/7 [00:01<00:00,  3.79it/s]\u001b[32m[I 2021-12-27 16:20:24,653]\u001b[0m Trial 4 finished with value: 0.3534894306752722 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.3412301298956539.\u001b[0m\n",
      "feature_fraction, val_score: 0.341230:  71%|################################1            | 5/7 [00:01<00:00,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.107351\tTest's rmse: 0.353489\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000819 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.341230:  86%|######################################5      | 6/7 [00:01<00:00,  3.78it/s]\u001b[32m[I 2021-12-27 16:20:24,919]\u001b[0m Trial 5 finished with value: 0.35272197059535476 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 0.3412301298956539.\u001b[0m\n",
      "feature_fraction, val_score: 0.341230:  86%|######################################5      | 6/7 [00:01<00:00,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.105091\tTest's rmse: 0.352722\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001492 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.341230: 100%|#############################################| 7/7 [00:01<00:00,  3.89it/s]\u001b[32m[I 2021-12-27 16:20:25,160]\u001b[0m Trial 6 finished with value: 0.3450742997835388 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 0.3412301298956539.\u001b[0m\n",
      "feature_fraction, val_score: 0.341230: 100%|#############################################| 7/7 [00:01<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[46]\tTrain's rmse: 0.145024\tTest's rmse: 0.345074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.341230:   0%|                                                          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001013 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.341230:   5%|##5                                               | 1/20 [00:01<00:22,  1.16s/it]\u001b[32m[I 2021-12-27 16:20:26,334]\u001b[0m Trial 7 finished with value: 0.34597810981784277 and parameters: {'num_leaves': 217}. Best is trial 7 with value: 0.34597810981784277.\u001b[0m\n",
      "num_leaves, val_score: 0.341230:   5%|##5                                               | 1/20 [00:01<00:22,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.118865\tTest's rmse: 0.345978\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001987 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.341230:  10%|#####                                             | 2/20 [00:01<00:14,  1.27it/s]\u001b[32m[I 2021-12-27 16:20:26,854]\u001b[0m Trial 8 finished with value: 0.34738864696253474 and parameters: {'num_leaves': 99}. Best is trial 7 with value: 0.34597810981784277.\u001b[0m\n",
      "num_leaves, val_score: 0.341230:  10%|#####                                             | 2/20 [00:01<00:14,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[40]\tTrain's rmse: 0.145488\tTest's rmse: 0.347389\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.341230:  15%|#######5                                          | 3/20 [00:02<00:11,  1.42it/s]\u001b[32m[I 2021-12-27 16:20:27,459]\u001b[0m Trial 9 finished with value: 0.3449076718477329 and parameters: {'num_leaves': 108}. Best is trial 9 with value: 0.3449076718477329.\u001b[0m\n",
      "num_leaves, val_score: 0.341230:  15%|#######5                                          | 3/20 [00:02<00:11,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[48]\tTrain's rmse: 0.138024\tTest's rmse: 0.344908\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000634 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.341230:  20%|##########                                        | 4/20 [00:03<00:11,  1.34it/s]\u001b[32m[I 2021-12-27 16:20:28,277]\u001b[0m Trial 10 finished with value: 0.34517204033045135 and parameters: {'num_leaves': 166}. Best is trial 9 with value: 0.3449076718477329.\u001b[0m\n",
      "num_leaves, val_score: 0.341230:  20%|##########                                        | 4/20 [00:03<00:11,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[48]\tTrain's rmse: 0.142346\tTest's rmse: 0.345172\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000642 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.341230:  25%|############5                                     | 5/20 [00:04<00:13,  1.09it/s]\u001b[32m[I 2021-12-27 16:20:29,501]\u001b[0m Trial 11 finished with value: 0.3475075529386648 and parameters: {'num_leaves': 245}. Best is trial 9 with value: 0.3449076718477329.\u001b[0m\n",
      "num_leaves, val_score: 0.341230:  25%|############5                                     | 5/20 [00:04<00:13,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[48]\tTrain's rmse: 0.142861\tTest's rmse: 0.347508\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000718 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.340568:  30%|###############                                   | 6/20 [00:04<00:09,  1.46it/s]\u001b[32m[I 2021-12-27 16:20:29,733]\u001b[0m Trial 12 finished with value: 0.34056777216761136 and parameters: {'num_leaves': 22}. Best is trial 12 with value: 0.34056777216761136.\u001b[0m\n",
      "num_leaves, val_score: 0.340568:  30%|###############                                   | 6/20 [00:04<00:09,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[48]\tTrain's rmse: 0.141086\tTest's rmse: 0.340568\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002291 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.340568:  35%|#################5                                | 7/20 [00:05<00:10,  1.25it/s]\u001b[32m[I 2021-12-27 16:20:30,767]\u001b[0m Trial 13 finished with value: 0.3470189004331763 and parameters: {'num_leaves': 206}. Best is trial 12 with value: 0.34056777216761136.\u001b[0m\n",
      "num_leaves, val_score: 0.340568:  35%|#################5                                | 7/20 [00:05<00:10,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[48]\tTrain's rmse: 0.142551\tTest's rmse: 0.347019\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.340568:  40%|####################                              | 8/20 [00:05<00:07,  1.58it/s]\u001b[32m[I 2021-12-27 16:20:31,047]\u001b[0m Trial 14 finished with value: 0.34492073663172995 and parameters: {'num_leaves': 49}. Best is trial 12 with value: 0.34056777216761136.\u001b[0m\n",
      "num_leaves, val_score: 0.340568:  40%|####################                              | 8/20 [00:05<00:07,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[37]\tTrain's rmse: 0.147963\tTest's rmse: 0.344921\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000745 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.340568:  45%|######################5                           | 9/20 [00:06<00:06,  1.64it/s]\u001b[32m[I 2021-12-27 16:20:31,601]\u001b[0m Trial 15 finished with value: 0.3479395012084193 and parameters: {'num_leaves': 109}. Best is trial 12 with value: 0.34056777216761136.\u001b[0m\n",
      "num_leaves, val_score: 0.340568:  45%|######################5                           | 9/20 [00:06<00:06,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[48]\tTrain's rmse: 0.142351\tTest's rmse: 0.34794\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001416 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.340568:  50%|########################5                        | 10/20 [00:07<00:07,  1.28it/s]\u001b[32m[I 2021-12-27 16:20:32,773]\u001b[0m Trial 16 finished with value: 0.3468220071228944 and parameters: {'num_leaves': 253}. Best is trial 12 with value: 0.34056777216761136.\u001b[0m\n",
      "num_leaves, val_score: 0.340568:  50%|########################5                        | 10/20 [00:07<00:07,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[48]\tTrain's rmse: 0.142715\tTest's rmse: 0.346822\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000798 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\tTrain's rmse: 0.150586\tTest's rmse: 0.336448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.336448:  55%|##########################9                      | 11/20 [00:07<00:05,  1.71it/s]\u001b[32m[I 2021-12-27 16:20:32,902]\u001b[0m Trial 17 finished with value: 0.33644761370257537 and parameters: {'num_leaves': 7}. Best is trial 17 with value: 0.33644761370257537.\u001b[0m\n",
      "num_leaves, val_score: 0.336448:  60%|#############################4                   | 12/20 [00:07<00:03,  2.24it/s]\u001b[32m[I 2021-12-27 16:20:33,036]\u001b[0m Trial 18 finished with value: 0.337884817089808 and parameters: {'num_leaves': 10}. Best is trial 17 with value: 0.33644761370257537.\u001b[0m\n",
      "num_leaves, val_score: 0.336448:  60%|#############################4                   | 12/20 [00:07<00:03,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001618 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\tTrain's rmse: 0.151205\tTest's rmse: 0.337885\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000580 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.174981\tTest's rmse: 0.328631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.328631:  60%|#############################4                   | 12/20 [00:07<00:03,  2.24it/s]\u001b[32m[I 2021-12-27 16:20:33,132]\u001b[0m Trial 19 finished with value: 0.3286306115870888 and parameters: {'num_leaves': 3}. Best is trial 19 with value: 0.3286306115870888.\u001b[0m\n",
      "num_leaves, val_score: 0.328631:  65%|###############################8                 | 13/20 [00:07<00:03,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000451 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.328631:  70%|##################################3              | 14/20 [00:08<00:02,  2.89it/s]\u001b[32m[I 2021-12-27 16:20:33,495]\u001b[0m Trial 20 finished with value: 0.3464759502417622 and parameters: {'num_leaves': 62}. Best is trial 19 with value: 0.3286306115870888.\u001b[0m\n",
      "num_leaves, val_score: 0.328631:  75%|####################################7            | 15/20 [00:08<00:01,  3.46it/s]\u001b[32m[I 2021-12-27 16:20:33,613]\u001b[0m Trial 21 finished with value: 0.3286306115870888 and parameters: {'num_leaves': 3}. Best is trial 19 with value: 0.3286306115870888.\u001b[0m\n",
      "num_leaves, val_score: 0.328631:  75%|####################################7            | 15/20 [00:08<00:01,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[37]\tTrain's rmse: 0.150048\tTest's rmse: 0.346476\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.174981\tTest's rmse: 0.328631\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000982 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.328631:  80%|#######################################2         | 16/20 [00:08<00:01,  3.20it/s]\u001b[32m[I 2021-12-27 16:20:33,992]\u001b[0m Trial 22 finished with value: 0.3433692372614874 and parameters: {'num_leaves': 58}. Best is trial 19 with value: 0.3286306115870888.\u001b[0m\n",
      "num_leaves, val_score: 0.328631:  80%|#######################################2         | 16/20 [00:08<00:01,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.1224\tTest's rmse: 0.343369\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002449 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.328631:  85%|#########################################6       | 17/20 [00:09<00:01,  2.38it/s]\u001b[32m[I 2021-12-27 16:20:34,697]\u001b[0m Trial 23 finished with value: 0.3450305926732971 and parameters: {'num_leaves': 157}. Best is trial 19 with value: 0.3286306115870888.\u001b[0m\n",
      "num_leaves, val_score: 0.328631:  85%|#########################################6       | 17/20 [00:09<00:01,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[40]\tTrain's rmse: 0.142323\tTest's rmse: 0.345031\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.328631:  90%|############################################1    | 18/20 [00:09<00:00,  2.63it/s]\u001b[32m[I 2021-12-27 16:20:34,977]\u001b[0m Trial 24 finished with value: 0.34294986590607307 and parameters: {'num_leaves': 40}. Best is trial 19 with value: 0.3286306115870888.\u001b[0m\n",
      "num_leaves, val_score: 0.328631:  90%|############################################1    | 18/20 [00:09<00:00,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.121407\tTest's rmse: 0.34295\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.328631:  95%|##############################################5  | 19/20 [00:10<00:00,  2.57it/s]\u001b[32m[I 2021-12-27 16:20:35,388]\u001b[0m Trial 25 finished with value: 0.34678151358665277 and parameters: {'num_leaves': 79}. Best is trial 19 with value: 0.3286306115870888.\u001b[0m\n",
      "num_leaves, val_score: 0.328631:  95%|##############################################5  | 19/20 [00:10<00:00,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[48]\tTrain's rmse: 0.1426\tTest's rmse: 0.346782\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.328631: 100%|#################################################| 20/20 [00:10<00:00,  2.93it/s]\u001b[32m[I 2021-12-27 16:20:35,612]\u001b[0m Trial 26 finished with value: 0.3412301298956539 and parameters: {'num_leaves': 31}. Best is trial 19 with value: 0.3286306115870888.\u001b[0m\n",
      "num_leaves, val_score: 0.328631: 100%|#################################################| 20/20 [00:10<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[39]\tTrain's rmse: 0.148039\tTest's rmse: 0.34123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.328631:   0%|                                                             | 0/10 [00:00<?, ?it/s]\u001b[32m[I 2021-12-27 16:20:35,711]\u001b[0m Trial 27 finished with value: 0.3297299854972565 and parameters: {'bagging_fraction': 0.8122886196837404, 'bagging_freq': 1}. Best is trial 27 with value: 0.3297299854972565.\u001b[0m\n",
      "bagging, val_score: 0.328631:  10%|#####3                                               | 1/10 [00:00<00:00,  9.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000459 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.168802\tTest's rmse: 0.32973\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001414 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.328631:  20%|##########6                                          | 2/10 [00:00<00:00,  9.60it/s]\u001b[32m[I 2021-12-27 16:20:35,829]\u001b[0m Trial 28 finished with value: 0.3318369238577535 and parameters: {'bagging_fraction': 0.8506303643899127, 'bagging_freq': 4}. Best is trial 27 with value: 0.3297299854972565.\u001b[0m\n",
      "bagging, val_score: 0.328631:  20%|##########6                                          | 2/10 [00:00<00:00,  9.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.165382\tTest's rmse: 0.331837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.328631:  20%|##########6                                          | 2/10 [00:00<00:00,  9.60it/s]\u001b[32m[I 2021-12-27 16:20:35,933]\u001b[0m Trial 29 finished with value: 0.3342234631080229 and parameters: {'bagging_fraction': 0.5656179327644254, 'bagging_freq': 3}. Best is trial 27 with value: 0.3297299854972565.\u001b[0m\n",
      "bagging, val_score: 0.328631:  30%|###############9                                     | 3/10 [00:00<00:00,  9.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000645 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.173936\tTest's rmse: 0.334223\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[98]\tTrain's rmse: 0.170548\tTest's rmse: 0.329262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.328631:  40%|#####################2                               | 4/10 [00:00<00:00,  9.43it/s]\u001b[32m[I 2021-12-27 16:20:36,043]\u001b[0m Trial 30 finished with value: 0.3292618115048559 and parameters: {'bagging_fraction': 0.4949564918468586, 'bagging_freq': 2}. Best is trial 30 with value: 0.3292618115048559.\u001b[0m\n",
      "bagging, val_score: 0.328631:  50%|##########################5                          | 5/10 [00:00<00:00,  9.50it/s]\u001b[32m[I 2021-12-27 16:20:36,145]\u001b[0m Trial 31 finished with value: 0.328985817798057 and parameters: {'bagging_fraction': 0.7727010380040904, 'bagging_freq': 3}. Best is trial 31 with value: 0.328985817798057.\u001b[0m\n",
      "bagging, val_score: 0.328631:  50%|##########################5                          | 5/10 [00:00<00:00,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.168988\tTest's rmse: 0.328986\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\tTrain's rmse: 0.174912\tTest's rmse: 0.329885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.328631:  60%|###############################8                     | 6/10 [00:00<00:00,  8.78it/s]\u001b[32m[I 2021-12-27 16:20:36,281]\u001b[0m Trial 32 finished with value: 0.3298854951738962 and parameters: {'bagging_fraction': 0.41077942837851145, 'bagging_freq': 1}. Best is trial 31 with value: 0.328985817798057.\u001b[0m\n",
      "bagging, val_score: 0.328631:  70%|#####################################                | 7/10 [00:00<00:00,  8.59it/s]\u001b[32m[I 2021-12-27 16:20:36,404]\u001b[0m Trial 33 finished with value: 0.33261781582493727 and parameters: {'bagging_fraction': 0.8567193010715681, 'bagging_freq': 1}. Best is trial 31 with value: 0.328985817798057.\u001b[0m\n",
      "bagging, val_score: 0.328631:  70%|#####################################                | 7/10 [00:00<00:00,  8.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000583 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.169005\tTest's rmse: 0.332618\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000724 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.169311\tTest's rmse: 0.331481"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.328631:  80%|##########################################4          | 8/10 [00:00<00:00,  8.76it/s]\u001b[32m[I 2021-12-27 16:20:36,513]\u001b[0m Trial 34 finished with value: 0.3314810927624084 and parameters: {'bagging_fraction': 0.8571931493839067, 'bagging_freq': 1}. Best is trial 31 with value: 0.328985817798057.\u001b[0m\n",
      "bagging, val_score: 0.328631:  80%|##########################################4          | 8/10 [00:00<00:00,  8.76it/s]\u001b[32m[I 2021-12-27 16:20:36,595]\u001b[0m Trial 35 finished with value: 0.33421002561279434 and parameters: {'bagging_fraction': 0.40236418206305696, 'bagging_freq': 4}. Best is trial 31 with value: 0.328985817798057.\u001b[0m\n",
      "bagging, val_score: 0.328631:  90%|###############################################7     | 9/10 [00:01<00:00,  8.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000650 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\tTrain's rmse: 0.181174\tTest's rmse: 0.33421\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000530 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.171222\tTest's rmse: 0.332377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.328631: 100%|####################################################| 10/10 [00:01<00:00,  9.63it/s]\u001b[32m[I 2021-12-27 16:20:36,701]\u001b[0m Trial 36 finished with value: 0.3323773544485161 and parameters: {'bagging_fraction': 0.6860574765646368, 'bagging_freq': 7}. Best is trial 31 with value: 0.328985817798057.\u001b[0m\n",
      "bagging, val_score: 0.328631: 100%|####################################################| 10/10 [00:01<00:00,  9.22it/s]\n",
      "feature_fraction_stage2, val_score: 0.327451:  17%|######3                               | 1/6 [00:00<00:00,  8.23it/s]\u001b[32m[I 2021-12-27 16:20:36,830]\u001b[0m Trial 37 finished with value: 0.3274514860606093 and parameters: {'feature_fraction': 0.9799999999999999}. Best is trial 37 with value: 0.3274514860606093.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.327451:  17%|######3                               | 1/6 [00:00<00:00,  8.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001981 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.16744\tTest's rmse: 0.327451\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001800 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.172675\tTest's rmse: 0.328592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.327451:  33%|############6                         | 2/6 [00:00<00:00,  8.56it/s]\u001b[32m[I 2021-12-27 16:20:36,944]\u001b[0m Trial 38 finished with value: 0.32859161648908114 and parameters: {'feature_fraction': 0.82}. Best is trial 37 with value: 0.3274514860606093.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.327451:  50%|###################                   | 3/6 [00:00<00:00,  8.87it/s]\u001b[32m[I 2021-12-27 16:20:37,051]\u001b[0m Trial 39 finished with value: 0.3292093522750144 and parameters: {'feature_fraction': 0.852}. Best is trial 37 with value: 0.3274514860606093.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.327451:  50%|###################                   | 3/6 [00:00<00:00,  8.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000674 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.174118\tTest's rmse: 0.329209\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.175198\tTest's rmse: 0.328385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.327451:  67%|#########################3            | 4/6 [00:00<00:00,  8.92it/s]\u001b[32m[I 2021-12-27 16:20:37,163]\u001b[0m Trial 40 finished with value: 0.3283850696720228 and parameters: {'feature_fraction': 0.948}. Best is trial 37 with value: 0.3274514860606093.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.327451:  83%|###############################6      | 5/6 [00:00<00:00,  9.27it/s]\u001b[32m[I 2021-12-27 16:20:37,265]\u001b[0m Trial 41 finished with value: 0.3286306115870888 and parameters: {'feature_fraction': 0.9159999999999999}. Best is trial 37 with value: 0.3274514860606093.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.327451: 100%|######################################| 6/6 [00:00<00:00,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000677 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.174981\tTest's rmse: 0.328631\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000823 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.174118\tTest's rmse: 0.329209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:20:37,373]\u001b[0m Trial 42 finished with value: 0.3292093522750144 and parameters: {'feature_fraction': 0.8839999999999999}. Best is trial 37 with value: 0.3274514860606093.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.327451: 100%|######################################| 6/6 [00:00<00:00,  8.99it/s]\n",
      "regularization_factors, val_score: 0.325121:   5%|#9                                    | 1/20 [00:00<00:01,  9.80it/s]\u001b[32m[I 2021-12-27 16:20:37,496]\u001b[0m Trial 43 finished with value: 0.3251210712992262 and parameters: {'lambda_l1': 0.004748605314494391, 'lambda_l2': 0.018890960031826737}. Best is trial 43 with value: 0.3251210712992262.\u001b[0m\n",
      "regularization_factors, val_score: 0.325121:   5%|#9                                    | 1/20 [00:00<00:01,  9.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000936 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.16679\tTest's rmse: 0.325121\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000693 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.166672\tTest's rmse: 0.330267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.325121:  10%|###8                                  | 2/20 [00:00<00:02,  8.45it/s]\u001b[32m[I 2021-12-27 16:20:37,613]\u001b[0m Trial 44 finished with value: 0.3302671718470986 and parameters: {'lambda_l1': 0.000544934157110776, 'lambda_l2': 2.3103797871500644}. Best is trial 43 with value: 0.3251210712992262.\u001b[0m\n",
      "regularization_factors, val_score: 0.325121:  15%|#####7                                | 3/20 [00:00<00:02,  8.11it/s]\u001b[32m[I 2021-12-27 16:20:37,743]\u001b[0m Trial 45 finished with value: 0.32745149166310056 and parameters: {'lambda_l1': 1.0626611739059014e-05, 'lambda_l2': 1.6177851025357858e-05}. Best is trial 43 with value: 0.3251210712992262.\u001b[0m\n",
      "regularization_factors, val_score: 0.325121:  15%|#####7                                | 3/20 [00:00<00:02,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001194 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.16744\tTest's rmse: 0.327451\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000674 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.325121:  20%|#######6                              | 4/20 [00:00<00:01,  8.04it/s]\u001b[32m[I 2021-12-27 16:20:37,868]\u001b[0m Trial 46 finished with value: 0.327451486674711 and parameters: {'lambda_l1': 1.1504760236525305e-06, 'lambda_l2': 2.334202951522562e-06}. Best is trial 43 with value: 0.3251210712992262.\u001b[0m\n",
      "regularization_factors, val_score: 0.325121:  25%|#########5                            | 5/20 [00:00<00:01,  8.38it/s]\u001b[32m[I 2021-12-27 16:20:37,992]\u001b[0m Trial 47 finished with value: 0.3274514864178353 and parameters: {'lambda_l1': 7.687121727053781e-07, 'lambda_l2': 2.36390703602373e-07}. Best is trial 43 with value: 0.3251210712992262.\u001b[0m\n",
      "regularization_factors, val_score: 0.325121:  25%|#########5                            | 5/20 [00:00<00:01,  8.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.16744\tTest's rmse: 0.327451\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.16744\tTest's rmse: 0.327451\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000704 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.325121:  30%|###########4                          | 6/20 [00:00<00:01,  8.35it/s]\u001b[32m[I 2021-12-27 16:20:38,106]\u001b[0m Trial 48 finished with value: 0.32745150275135587 and parameters: {'lambda_l1': 3.7995032209545826e-05, 'lambda_l2': 1.8092059250954576e-06}. Best is trial 43 with value: 0.3251210712992262.\u001b[0m\n",
      "regularization_factors, val_score: 0.325121:  35%|#############3                        | 7/20 [00:00<00:01,  8.29it/s]\u001b[32m[I 2021-12-27 16:20:38,221]\u001b[0m Trial 49 finished with value: 0.3274514878123629 and parameters: {'lambda_l1': 1.7429459354408283e-06, 'lambda_l2': 1.7621128814416578e-05}. Best is trial 43 with value: 0.3251210712992262.\u001b[0m\n",
      "regularization_factors, val_score: 0.325121:  35%|#############3                        | 7/20 [00:00<00:01,  8.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.16744\tTest's rmse: 0.327452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000712 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.16744\tTest's rmse: 0.327451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.322952:  40%|###############2                      | 8/20 [00:00<00:01,  8.57it/s]\u001b[32m[I 2021-12-27 16:20:38,327]\u001b[0m Trial 50 finished with value: 0.3229516160736119 and parameters: {'lambda_l1': 1.7194156314048008, 'lambda_l2': 1.2162570534468838e-07}. Best is trial 50 with value: 0.3229516160736119.\u001b[0m\n",
      "regularization_factors, val_score: 0.322952:  40%|###############2                      | 8/20 [00:00<00:01,  8.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000807 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.16549\tTest's rmse: 0.322952\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000675 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.322952:  45%|#################1                    | 9/20 [00:01<00:01,  8.48it/s]\u001b[32m[I 2021-12-27 16:20:38,450]\u001b[0m Trial 51 finished with value: 0.3274515887842803 and parameters: {'lambda_l1': 2.5823192940560486e-07, 'lambda_l2': 0.001892462650806088}. Best is trial 50 with value: 0.3229516160736119.\u001b[0m\n",
      "regularization_factors, val_score: 0.322952:  45%|#################1                    | 9/20 [00:01<00:01,  8.48it/s]\u001b[32m[I 2021-12-27 16:20:38,546]\u001b[0m Trial 52 finished with value: 0.3274514871627959 and parameters: {'lambda_l1': 2.5468597084449156e-06, 'lambda_l2': 2.987300735690955e-08}. Best is trial 50 with value: 0.3229516160736119.\u001b[0m\n",
      "regularization_factors, val_score: 0.322952:  50%|##################5                  | 10/20 [00:01<00:01,  8.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.167441\tTest's rmse: 0.327452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000757 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.16744\tTest's rmse: 0.327451\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000735 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.322952:  55%|####################3                | 11/20 [00:01<00:01,  8.58it/s]\u001b[32m[I 2021-12-27 16:20:38,681]\u001b[0m Trial 53 finished with value: 0.32915449245327505 and parameters: {'lambda_l1': 8.285012902289644, 'lambda_l2': 1.593560868871408e-08}. Best is trial 50 with value: 0.3229516160736119.\u001b[0m\n",
      "regularization_factors, val_score: 0.322952:  60%|######################2              | 12/20 [00:01<00:00,  8.41it/s]\u001b[32m[I 2021-12-27 16:20:38,807]\u001b[0m Trial 54 finished with value: 0.32638396417492116 and parameters: {'lambda_l1': 0.12068550778805706, 'lambda_l2': 0.008797973751412277}. Best is trial 50 with value: 0.3229516160736119.\u001b[0m\n",
      "regularization_factors, val_score: 0.322952:  60%|######################2              | 12/20 [00:01<00:00,  8.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.172091\tTest's rmse: 0.329154\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000670 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.166313\tTest's rmse: 0.326384\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001937 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.322952:  65%|########################             | 13/20 [00:01<00:00,  7.91it/s]\u001b[32m[I 2021-12-27 16:20:38,953]\u001b[0m Trial 55 finished with value: 0.325818585058367 and parameters: {'lambda_l1': 0.01070355719945491, 'lambda_l2': 0.12644805811747747}. Best is trial 50 with value: 0.3229516160736119.\u001b[0m\n",
      "regularization_factors, val_score: 0.322952:  65%|########################             | 13/20 [00:01<00:00,  7.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.166806\tTest's rmse: 0.325819\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001780 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.322952:  70%|#########################9           | 14/20 [00:01<00:00,  8.15it/s]\u001b[32m[I 2021-12-27 16:20:39,082]\u001b[0m Trial 56 finished with value: 0.328959574747927 and parameters: {'lambda_l1': 9.66225618713991, 'lambda_l2': 0.0002189866430406789}. Best is trial 50 with value: 0.3229516160736119.\u001b[0m\n",
      "regularization_factors, val_score: 0.322952:  75%|###########################7         | 15/20 [00:01<00:00,  8.02it/s]\u001b[32m[I 2021-12-27 16:20:39,194]\u001b[0m Trial 57 finished with value: 0.327065417981989 and parameters: {'lambda_l1': 0.10440763623990526, 'lambda_l2': 0.05752246269132168}. Best is trial 50 with value: 0.3229516160736119.\u001b[0m\n",
      "regularization_factors, val_score: 0.322952:  75%|###########################7         | 15/20 [00:01<00:00,  8.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.173119\tTest's rmse: 0.32896\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000619 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.16736\tTest's rmse: 0.327065\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000719 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.322952:  80%|#############################6       | 16/20 [00:01<00:00,  7.82it/s]\u001b[32m[I 2021-12-27 16:20:39,345]\u001b[0m Trial 58 finished with value: 0.3274520732417425 and parameters: {'lambda_l1': 0.0012748430410988458, 'lambda_l2': 0.0006161183435490257}. Best is trial 50 with value: 0.3229516160736119.\u001b[0m\n",
      "regularization_factors, val_score: 0.322952:  80%|#############################6       | 16/20 [00:01<00:00,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.167441\tTest's rmse: 0.327452\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000704 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.322952:  85%|###############################4     | 17/20 [00:02<00:00,  7.56it/s]\u001b[32m[I 2021-12-27 16:20:39,476]\u001b[0m Trial 59 finished with value: 0.3268328956979148 and parameters: {'lambda_l1': 1.150240733190338e-08, 'lambda_l2': 0.8420174951084961}. Best is trial 50 with value: 0.3229516160736119.\u001b[0m\n",
      "regularization_factors, val_score: 0.322628:  90%|#################################3   | 18/20 [00:02<00:00,  7.55it/s]\u001b[32m[I 2021-12-27 16:20:39,609]\u001b[0m Trial 60 finished with value: 0.3226279187129132 and parameters: {'lambda_l1': 0.5979675737925565, 'lambda_l2': 4.0320649492928434e-05}. Best is trial 60 with value: 0.3226279187129132.\u001b[0m\n",
      "regularization_factors, val_score: 0.322628:  90%|#################################3   | 18/20 [00:02<00:00,  7.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.167795\tTest's rmse: 0.326833\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.162345\tTest's rmse: 0.322628\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000843 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.322628:  95%|###################################1 | 19/20 [00:02<00:00,  7.68it/s]\u001b[32m[I 2021-12-27 16:20:39,736]\u001b[0m Trial 61 finished with value: 0.32531220201774536 and parameters: {'lambda_l1': 1.1223037460907082, 'lambda_l2': 5.8438013913143355e-05}. Best is trial 60 with value: 0.3226279187129132.\u001b[0m\n",
      "regularization_factors, val_score: 0.322628:  95%|###################################1 | 19/20 [00:02<00:00,  7.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.167581\tTest's rmse: 0.325312\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002001 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.167958\tTest's rmse: 0.327011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.322628: 100%|#####################################| 20/20 [00:02<00:00,  7.64it/s]\u001b[32m[I 2021-12-27 16:20:39,866]\u001b[0m Trial 62 finished with value: 0.32701052116475565 and parameters: {'lambda_l1': 0.28587322313719876, 'lambda_l2': 2.6815625304748917e-07}. Best is trial 60 with value: 0.3226279187129132.\u001b[0m\n",
      "regularization_factors, val_score: 0.322628: 100%|#####################################| 20/20 [00:02<00:00,  8.04it/s]\n",
      "min_data_in_leaf, val_score: 0.322628:  20%|#########                                    | 1/5 [00:00<00:00,  8.00it/s]\u001b[32m[I 2021-12-27 16:20:40,000]\u001b[0m Trial 63 finished with value: 0.3312626607891085 and parameters: {'min_child_samples': 5}. Best is trial 63 with value: 0.3312626607891085.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.322628:  20%|#########                                    | 1/5 [00:00<00:00,  8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.150148\tTest's rmse: 0.331263\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001982 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.161525\tTest's rmse: 0.325574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.322628:  40%|##################                           | 2/5 [00:00<00:00,  8.49it/s]\u001b[32m[I 2021-12-27 16:20:40,112]\u001b[0m Trial 64 finished with value: 0.3255736804460715 and parameters: {'min_child_samples': 10}. Best is trial 64 with value: 0.3255736804460715.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.322628:  60%|###########################                  | 3/5 [00:00<00:00,  9.07it/s]\u001b[32m[I 2021-12-27 16:20:40,210]\u001b[0m Trial 65 finished with value: 0.32263616696569575 and parameters: {'min_child_samples': 25}. Best is trial 65 with value: 0.32263616696569575.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.322628:  80%|####################################         | 4/5 [00:00<00:00,  9.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.166022\tTest's rmse: 0.322636\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000742 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.228156\tTest's rmse: 0.380617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:20:40,312]\u001b[0m Trial 66 finished with value: 0.38061705462333517 and parameters: {'min_child_samples': 50}. Best is trial 65 with value: 0.32263616696569575.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.322628: 100%|#############################################| 5/5 [00:00<00:00,  9.04it/s]\u001b[32m[I 2021-12-27 16:20:40,438]\u001b[0m Trial 67 finished with value: 0.41009486462154426 and parameters: {'min_child_samples': 100}. Best is trial 65 with value: 0.32263616696569575.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.322628: 100%|#############################################| 5/5 [00:00<00:00,  8.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000675 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.263675\tTest's rmse: 0.410095\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:20:40,622]\u001b[0m A new study created in memory with name: no-name-192fd3f1-19cd-43f4-901e-78a19fe30427\u001b[0m\n",
      "feature_fraction, val_score: inf:   0%|                                                          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000608 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.103132:  14%|######4                                      | 1/7 [00:00<00:01,  3.70it/s]\u001b[32m[I 2021-12-27 16:20:40,896]\u001b[0m Trial 0 finished with value: 0.10313165674393071 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 0.10313165674393071.\u001b[0m\n",
      "feature_fraction, val_score: 0.103132:  14%|######4                                      | 1/7 [00:00<00:01,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.133798\tTest's rmse: 0.103132\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000682 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.103132:  29%|############8                                | 2/7 [00:00<00:01,  3.59it/s]\u001b[32m[I 2021-12-27 16:20:41,184]\u001b[0m Trial 1 finished with value: 0.12250201339158852 and parameters: {'feature_fraction': 0.5}. Best is trial 0 with value: 0.10313165674393071.\u001b[0m\n",
      "feature_fraction, val_score: 0.103132:  29%|############8                                | 2/7 [00:00<00:01,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.131693\tTest's rmse: 0.122502\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000711 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.103132:  43%|###################2                         | 3/7 [00:00<00:01,  3.58it/s]\u001b[32m[I 2021-12-27 16:20:41,461]\u001b[0m Trial 2 finished with value: 0.11199663372018692 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 0.10313165674393071.\u001b[0m\n",
      "feature_fraction, val_score: 0.103132:  43%|###################2                         | 3/7 [00:00<00:01,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.148628\tTest's rmse: 0.111997\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002416 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.103132:  57%|#########################7                   | 4/7 [00:01<00:00,  3.56it/s]\u001b[32m[I 2021-12-27 16:20:41,745]\u001b[0m Trial 3 finished with value: 0.10522738562850059 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 0.10313165674393071.\u001b[0m\n",
      "feature_fraction, val_score: 0.103132:  57%|#########################7                   | 4/7 [00:01<00:00,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.144067\tTest's rmse: 0.105227\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000477 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.103132:  71%|################################1            | 5/7 [00:01<00:00,  3.49it/s]\u001b[32m[I 2021-12-27 16:20:42,055]\u001b[0m Trial 4 finished with value: 0.13184108603175235 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 0.10313165674393071.\u001b[0m\n",
      "feature_fraction, val_score: 0.103132:  71%|################################1            | 5/7 [00:01<00:00,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.136538\tTest's rmse: 0.131841\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002469 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.103132:  86%|######################################5      | 6/7 [00:01<00:00,  3.26it/s]\u001b[32m[I 2021-12-27 16:20:42,388]\u001b[0m Trial 5 finished with value: 0.10804926853338176 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 0.10313165674393071.\u001b[0m\n",
      "feature_fraction, val_score: 0.103132:  86%|######################################5      | 6/7 [00:01<00:00,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.134845\tTest's rmse: 0.108049\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001947 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.103132: 100%|#############################################| 7/7 [00:02<00:00,  3.44it/s]\u001b[32m[I 2021-12-27 16:20:42,650]\u001b[0m Trial 6 finished with value: 0.11941999345239779 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.10313165674393071.\u001b[0m\n",
      "feature_fraction, val_score: 0.103132: 100%|#############################################| 7/7 [00:02<00:00,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.130288\tTest's rmse: 0.11942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.103132:   0%|                                                          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000554 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.103132:   5%|##5                                               | 1/20 [00:00<00:06,  2.83it/s]\u001b[32m[I 2021-12-27 16:20:43,022]\u001b[0m Trial 7 finished with value: 0.10567045859028944 and parameters: {'num_leaves': 50}. Best is trial 7 with value: 0.10567045859028944.\u001b[0m\n",
      "num_leaves, val_score: 0.103132:   5%|##5                                               | 1/20 [00:00<00:06,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.137776\tTest's rmse: 0.10567\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001968 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.103132:  10%|#####                                             | 2/20 [00:01<00:14,  1.22it/s]\u001b[32m[I 2021-12-27 16:20:44,159]\u001b[0m Trial 8 finished with value: 0.1162953908822503 and parameters: {'num_leaves': 251}. Best is trial 7 with value: 0.10567045859028944.\u001b[0m\n",
      "num_leaves, val_score: 0.103132:  10%|#####                                             | 2/20 [00:01<00:14,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.13701\tTest's rmse: 0.116295\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.103132:  15%|#######5                                          | 3/20 [00:02<00:11,  1.47it/s]\u001b[32m[I 2021-12-27 16:20:44,690]\u001b[0m Trial 9 finished with value: 0.10949973248889339 and parameters: {'num_leaves': 112}. Best is trial 7 with value: 0.10567045859028944.\u001b[0m\n",
      "num_leaves, val_score: 0.103132:  15%|#######5                                          | 3/20 [00:02<00:11,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.136798\tTest's rmse: 0.1095\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001626 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.103132:  20%|##########                                        | 4/20 [00:02<00:09,  1.73it/s]\u001b[32m[I 2021-12-27 16:20:45,100]\u001b[0m Trial 10 finished with value: 0.1095026706670363 and parameters: {'num_leaves': 63}. Best is trial 7 with value: 0.10567045859028944.\u001b[0m\n",
      "num_leaves, val_score: 0.103132:  20%|##########                                        | 4/20 [00:02<00:09,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.136747\tTest's rmse: 0.109503\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000659 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.103132:  25%|############5                                     | 5/20 [00:03<00:11,  1.29it/s]\u001b[32m[I 2021-12-27 16:20:46,216]\u001b[0m Trial 11 finished with value: 0.11550286311829142 and parameters: {'num_leaves': 253}. Best is trial 7 with value: 0.10567045859028944.\u001b[0m\n",
      "num_leaves, val_score: 0.103132:  25%|############5                                     | 5/20 [00:03<00:11,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.137173\tTest's rmse: 0.115503\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.103132:  30%|###############                                   | 6/20 [00:04<00:10,  1.28it/s]\u001b[32m[I 2021-12-27 16:20:47,011]\u001b[0m Trial 12 finished with value: 0.11342893530789282 and parameters: {'num_leaves': 182}. Best is trial 7 with value: 0.10567045859028944.\u001b[0m\n",
      "num_leaves, val_score: 0.103132:  30%|###############                                   | 6/20 [00:04<00:10,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.136528\tTest's rmse: 0.113429\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002734 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.103132:  35%|#################5                                | 7/20 [00:04<00:08,  1.48it/s]\u001b[32m[I 2021-12-27 16:20:47,468]\u001b[0m Trial 13 finished with value: 0.10702044757183964 and parameters: {'num_leaves': 84}. Best is trial 7 with value: 0.10567045859028944.\u001b[0m\n",
      "num_leaves, val_score: 0.103132:  35%|#################5                                | 7/20 [00:04<00:08,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.138735\tTest's rmse: 0.10702\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001594 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.103132:  40%|####################                              | 8/20 [00:05<00:08,  1.36it/s]\u001b[32m[I 2021-12-27 16:20:48,331]\u001b[0m Trial 14 finished with value: 0.11240743406216137 and parameters: {'num_leaves': 180}. Best is trial 7 with value: 0.10567045859028944.\u001b[0m\n",
      "num_leaves, val_score: 0.103132:  40%|####################                              | 8/20 [00:05<00:08,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.134788\tTest's rmse: 0.112407\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000680 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.103132:  45%|######################5                           | 9/20 [00:06<00:08,  1.26it/s]\u001b[32m[I 2021-12-27 16:20:49,257]\u001b[0m Trial 15 finished with value: 0.11462522022858053 and parameters: {'num_leaves': 191}. Best is trial 7 with value: 0.10567045859028944.\u001b[0m\n",
      "num_leaves, val_score: 0.103132:  45%|######################5                           | 9/20 [00:06<00:08,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.139012\tTest's rmse: 0.114625\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.103132:  50%|########################5                        | 10/20 [00:07<00:08,  1.14it/s]\u001b[32m[I 2021-12-27 16:20:50,328]\u001b[0m Trial 16 finished with value: 0.11569457842575841 and parameters: {'num_leaves': 203}. Best is trial 7 with value: 0.10567045859028944.\u001b[0m\n",
      "num_leaves, val_score: 0.103132:  50%|########################5                        | 10/20 [00:07<00:08,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.137024\tTest's rmse: 0.115695\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000702 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.151599\tTest's rmse: 0.104847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.103132:  55%|##########################9                      | 11/20 [00:07<00:05,  1.53it/s]\u001b[32m[I 2021-12-27 16:20:50,475]\u001b[0m Trial 17 finished with value: 0.10484681078742782 and parameters: {'num_leaves': 6}. Best is trial 17 with value: 0.10484681078742782.\u001b[0m\n",
      "num_leaves, val_score: 0.103132:  60%|#############################4                   | 12/20 [00:07<00:03,  2.05it/s]\u001b[32m[I 2021-12-27 16:20:50,577]\u001b[0m Trial 18 finished with value: 0.11788942523603016 and parameters: {'num_leaves': 3}. Best is trial 17 with value: 0.10484681078742782.\u001b[0m\n",
      "num_leaves, val_score: 0.103132:  60%|#############################4                   | 12/20 [00:07<00:03,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000623 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.202714\tTest's rmse: 0.117889\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001811 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.103132:  65%|###############################8                 | 13/20 [00:08<00:02,  2.56it/s]\u001b[32m[I 2021-12-27 16:20:50,761]\u001b[0m Trial 19 finished with value: 0.10623267966783013 and parameters: {'num_leaves': 10}. Best is trial 17 with value: 0.10484681078742782.\u001b[0m\n",
      "num_leaves, val_score: 0.103132:  65%|###############################8                 | 13/20 [00:08<00:02,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.135522\tTest's rmse: 0.106233\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001856 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.103132:  70%|##################################3              | 14/20 [00:08<00:02,  2.62it/s]\u001b[32m[I 2021-12-27 16:20:51,106]\u001b[0m Trial 20 finished with value: 0.10528601761724943 and parameters: {'num_leaves': 45}. Best is trial 17 with value: 0.10484681078742782.\u001b[0m\n",
      "num_leaves, val_score: 0.103132:  70%|##################################3              | 14/20 [00:08<00:02,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.136667\tTest's rmse: 0.105286\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000622 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.101914:  75%|####################################7            | 15/20 [00:08<00:01,  2.75it/s]\u001b[32m[I 2021-12-27 16:20:51,426]\u001b[0m Trial 21 finished with value: 0.10191386412909666 and parameters: {'num_leaves': 38}. Best is trial 21 with value: 0.10191386412909666.\u001b[0m\n",
      "num_leaves, val_score: 0.101914:  75%|####################################7            | 15/20 [00:08<00:01,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.138896\tTest's rmse: 0.101914\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002023 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.101914:  80%|#######################################2         | 16/20 [00:09<00:01,  3.02it/s]\u001b[32m[I 2021-12-27 16:20:51,684]\u001b[0m Trial 22 finished with value: 0.10236785304466993 and parameters: {'num_leaves': 26}. Best is trial 21 with value: 0.10191386412909666.\u001b[0m\n",
      "num_leaves, val_score: 0.101914:  80%|#######################################2         | 16/20 [00:09<00:01,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.139447\tTest's rmse: 0.102368\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000604 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.101914:  85%|#########################################6       | 17/20 [00:09<00:01,  2.24it/s]\u001b[32m[I 2021-12-27 16:20:52,407]\u001b[0m Trial 23 finished with value: 0.11396132716706993 and parameters: {'num_leaves': 128}. Best is trial 21 with value: 0.10191386412909666.\u001b[0m\n",
      "num_leaves, val_score: 0.101914:  85%|#########################################6       | 17/20 [00:09<00:01,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.137256\tTest's rmse: 0.113961\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002720 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.101914:  90%|############################################1    | 18/20 [00:10<00:00,  2.19it/s]\u001b[32m[I 2021-12-27 16:20:52,875]\u001b[0m Trial 24 finished with value: 0.10818231402364091 and parameters: {'num_leaves': 90}. Best is trial 21 with value: 0.10191386412909666.\u001b[0m\n",
      "num_leaves, val_score: 0.101914:  90%|############################################1    | 18/20 [00:10<00:00,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.137381\tTest's rmse: 0.108182\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002070 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.101914:  95%|##############################################5  | 19/20 [00:10<00:00,  2.55it/s]\u001b[32m[I 2021-12-27 16:20:53,120]\u001b[0m Trial 25 finished with value: 0.10313165674393071 and parameters: {'num_leaves': 31}. Best is trial 21 with value: 0.10191386412909666.\u001b[0m\n",
      "num_leaves, val_score: 0.101914:  95%|##############################################5  | 19/20 [00:10<00:00,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.133798\tTest's rmse: 0.103132\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000559 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.101914: 100%|#################################################| 20/20 [00:10<00:00,  2.43it/s]\u001b[32m[I 2021-12-27 16:20:53,577]\u001b[0m Trial 26 finished with value: 0.10796325298975074 and parameters: {'num_leaves': 80}. Best is trial 21 with value: 0.10191386412909666.\u001b[0m\n",
      "num_leaves, val_score: 0.101914: 100%|#################################################| 20/20 [00:10<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.136906\tTest's rmse: 0.107963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.101914:   0%|                                                             | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001933 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.101914:  10%|#####3                                               | 1/10 [00:00<00:02,  3.44it/s]\u001b[32m[I 2021-12-27 16:20:53,875]\u001b[0m Trial 27 finished with value: 0.11424164426643743 and parameters: {'bagging_fraction': 0.8060766483699963, 'bagging_freq': 3}. Best is trial 27 with value: 0.11424164426643743.\u001b[0m\n",
      "bagging, val_score: 0.101914:  10%|#####3                                               | 1/10 [00:00<00:02,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.161851\tTest's rmse: 0.114242\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000575 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.101914:  20%|##########6                                          | 2/10 [00:00<00:02,  3.32it/s]\u001b[32m[I 2021-12-27 16:20:54,184]\u001b[0m Trial 28 finished with value: 0.12180325851985131 and parameters: {'bagging_fraction': 0.559039938023513, 'bagging_freq': 6}. Best is trial 27 with value: 0.11424164426643743.\u001b[0m\n",
      "bagging, val_score: 0.101914:  20%|##########6                                          | 2/10 [00:00<00:02,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[98]\tTrain's rmse: 0.183919\tTest's rmse: 0.121803\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001767 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.101914:  30%|###############9                                     | 3/10 [00:00<00:02,  3.44it/s]\u001b[32m[I 2021-12-27 16:20:54,463]\u001b[0m Trial 29 finished with value: 0.11702143816444632 and parameters: {'bagging_fraction': 0.8490590354617817, 'bagging_freq': 7}. Best is trial 27 with value: 0.11424164426643743.\u001b[0m\n",
      "bagging, val_score: 0.101914:  30%|###############9                                     | 3/10 [00:00<00:02,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.152838\tTest's rmse: 0.117021\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000525 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.101914:  40%|#####################2                               | 4/10 [00:01<00:01,  3.26it/s]\u001b[32m[I 2021-12-27 16:20:54,799]\u001b[0m Trial 30 finished with value: 0.1205453483088245 and parameters: {'bagging_fraction': 0.6555894700359264, 'bagging_freq': 5}. Best is trial 27 with value: 0.11424164426643743.\u001b[0m\n",
      "bagging, val_score: 0.101914:  40%|#####################2                               | 4/10 [00:01<00:01,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.17009\tTest's rmse: 0.120545\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003050 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.101914:  50%|##########################5                          | 5/10 [00:01<00:01,  2.96it/s]\u001b[32m[I 2021-12-27 16:20:55,186]\u001b[0m Trial 31 finished with value: 0.11967113057605971 and parameters: {'bagging_fraction': 0.9011102617739063, 'bagging_freq': 5}. Best is trial 27 with value: 0.11424164426643743.\u001b[0m\n",
      "bagging, val_score: 0.101914:  50%|##########################5                          | 5/10 [00:01<00:01,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.150503\tTest's rmse: 0.119671\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000582 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.101914:  60%|###############################8                     | 6/10 [00:01<00:01,  2.88it/s]\u001b[32m[I 2021-12-27 16:20:55,552]\u001b[0m Trial 32 finished with value: 0.12018677294147154 and parameters: {'bagging_fraction': 0.5519852960405702, 'bagging_freq': 3}. Best is trial 27 with value: 0.11424164426643743.\u001b[0m\n",
      "bagging, val_score: 0.101914:  60%|###############################8                     | 6/10 [00:01<00:01,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.182071\tTest's rmse: 0.120187\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000950 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.101914:  70%|#####################################                | 7/10 [00:02<00:01,  2.92it/s]\u001b[32m[I 2021-12-27 16:20:55,883]\u001b[0m Trial 33 finished with value: 0.1232199198060603 and parameters: {'bagging_fraction': 0.5362778842059845, 'bagging_freq': 1}. Best is trial 27 with value: 0.11424164426643743.\u001b[0m\n",
      "bagging, val_score: 0.101914:  70%|#####################################                | 7/10 [00:02<00:01,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.178963\tTest's rmse: 0.12322\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.101914:  80%|##########################################4          | 8/10 [00:02<00:00,  2.96it/s]\u001b[32m[I 2021-12-27 16:20:56,211]\u001b[0m Trial 34 finished with value: 0.1135774315708728 and parameters: {'bagging_fraction': 0.661083484711139, 'bagging_freq': 2}. Best is trial 34 with value: 0.1135774315708728.\u001b[0m\n",
      "bagging, val_score: 0.101914:  80%|##########################################4          | 8/10 [00:02<00:00,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.173951\tTest's rmse: 0.113577\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001901 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.101914:  90%|###############################################7     | 9/10 [00:02<00:00,  3.11it/s]\u001b[32m[I 2021-12-27 16:20:56,499]\u001b[0m Trial 35 finished with value: 0.11307816121697835 and parameters: {'bagging_fraction': 0.6349337479479721, 'bagging_freq': 6}. Best is trial 35 with value: 0.11307816121697835.\u001b[0m\n",
      "bagging, val_score: 0.101914:  90%|###############################################7     | 9/10 [00:02<00:00,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[98]\tTrain's rmse: 0.183378\tTest's rmse: 0.113078\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002462 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.101914: 100%|####################################################| 10/10 [00:03<00:00,  3.22it/s]\u001b[32m[I 2021-12-27 16:20:56,783]\u001b[0m Trial 36 finished with value: 0.11971721943056923 and parameters: {'bagging_fraction': 0.5703730539929766, 'bagging_freq': 7}. Best is trial 35 with value: 0.11307816121697835.\u001b[0m\n",
      "bagging, val_score: 0.101914: 100%|####################################################| 10/10 [00:03<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.178942\tTest's rmse: 0.119717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.101914:   0%|                                              | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001878 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.101914:  17%|######3                               | 1/6 [00:00<00:01,  3.14it/s]\u001b[32m[I 2021-12-27 16:20:57,108]\u001b[0m Trial 37 finished with value: 0.1077574625933869 and parameters: {'feature_fraction': 0.7200000000000001}. Best is trial 37 with value: 0.1077574625933869.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.101914:  17%|######3                               | 1/6 [00:00<00:01,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.134807\tTest's rmse: 0.107757\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001627 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.101914:  33%|############6                         | 2/6 [00:00<00:01,  3.26it/s]\u001b[32m[I 2021-12-27 16:20:57,406]\u001b[0m Trial 38 finished with value: 0.10720595556020089 and parameters: {'feature_fraction': 0.784}. Best is trial 38 with value: 0.10720595556020089.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.101914:  33%|############6                         | 2/6 [00:00<00:01,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.137358\tTest's rmse: 0.107206\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000564 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.101914:  50%|###################                   | 3/6 [00:00<00:00,  3.25it/s]\u001b[32m[I 2021-12-27 16:20:57,718]\u001b[0m Trial 39 finished with value: 0.10532000788144741 and parameters: {'feature_fraction': 0.88}. Best is trial 39 with value: 0.10532000788144741.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.101914:  50%|###################                   | 3/6 [00:00<00:00,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.14095\tTest's rmse: 0.10532\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018008 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.101914:  67%|#########################3            | 4/6 [00:01<00:00,  2.71it/s]\u001b[32m[I 2021-12-27 16:20:58,178]\u001b[0m Trial 40 finished with value: 0.10191386412909666 and parameters: {'feature_fraction': 0.8160000000000001}. Best is trial 40 with value: 0.10191386412909666.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.101914:  67%|#########################3            | 4/6 [00:01<00:00,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.138896\tTest's rmse: 0.101914\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000603 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.101914:  83%|###############################6      | 5/6 [00:01<00:00,  2.99it/s]\u001b[32m[I 2021-12-27 16:20:58,450]\u001b[0m Trial 41 finished with value: 0.10532000788144741 and parameters: {'feature_fraction': 0.8480000000000001}. Best is trial 40 with value: 0.10191386412909666.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.101914:  83%|###############################6      | 5/6 [00:01<00:00,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.14095\tTest's rmse: 0.10532\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000651 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.101914: 100%|######################################| 6/6 [00:01<00:00,  3.29it/s]\u001b[32m[I 2021-12-27 16:20:58,693]\u001b[0m Trial 42 finished with value: 0.10720595556020089 and parameters: {'feature_fraction': 0.7520000000000001}. Best is trial 40 with value: 0.10191386412909666.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.101914: 100%|######################################| 6/6 [00:01<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.137358\tTest's rmse: 0.107206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.101914:   0%|                                              | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.101914:   5%|#9                                    | 1/20 [00:00<00:05,  3.47it/s]\u001b[32m[I 2021-12-27 16:20:59,003]\u001b[0m Trial 43 finished with value: 0.10574865927762851 and parameters: {'lambda_l1': 0.16187682545323606, 'lambda_l2': 1.3861107472568934e-07}. Best is trial 43 with value: 0.10574865927762851.\u001b[0m\n",
      "regularization_factors, val_score: 0.101914:   5%|#9                                    | 1/20 [00:00<00:05,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.136301\tTest's rmse: 0.105749\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.101914:  10%|###8                                  | 2/20 [00:00<00:05,  3.44it/s]\u001b[32m[I 2021-12-27 16:20:59,292]\u001b[0m Trial 44 finished with value: 0.10209055833322767 and parameters: {'lambda_l1': 2.171736101336239e-06, 'lambda_l2': 5.819733156790513e-08}. Best is trial 44 with value: 0.10209055833322767.\u001b[0m\n",
      "regularization_factors, val_score: 0.101914:  10%|###8                                  | 2/20 [00:00<00:05,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.138774\tTest's rmse: 0.102091\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000616 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.101914:  15%|#####7                                | 3/20 [00:00<00:05,  3.22it/s]\u001b[32m[I 2021-12-27 16:20:59,626]\u001b[0m Trial 45 finished with value: 0.10225357306029753 and parameters: {'lambda_l1': 0.0008113199858924656, 'lambda_l2': 0.00014316974533713973}. Best is trial 44 with value: 0.10209055833322767.\u001b[0m\n",
      "regularization_factors, val_score: 0.101914:  15%|#####7                                | 3/20 [00:00<00:05,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.135285\tTest's rmse: 0.102254\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001825 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.101914:  20%|#######6                              | 4/20 [00:01<00:05,  3.11it/s]\u001b[32m[I 2021-12-27 16:20:59,965]\u001b[0m Trial 46 finished with value: 0.10209055792161768 and parameters: {'lambda_l1': 1.7756360527084428e-06, 'lambda_l2': 4.910694038993939e-06}. Best is trial 46 with value: 0.10209055792161768.\u001b[0m\n",
      "regularization_factors, val_score: 0.101914:  20%|#######6                              | 4/20 [00:01<00:05,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.138774\tTest's rmse: 0.102091\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000613 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.101914:  25%|#########5                            | 5/20 [00:01<00:04,  3.06it/s]\u001b[32m[I 2021-12-27 16:21:00,302]\u001b[0m Trial 47 finished with value: 0.1046133129187288 and parameters: {'lambda_l1': 0.021927814388492832, 'lambda_l2': 0.24869418725226072}. Best is trial 46 with value: 0.10209055792161768.\u001b[0m\n",
      "regularization_factors, val_score: 0.101914:  25%|#########5                            | 5/20 [00:01<00:04,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.137916\tTest's rmse: 0.104613\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000554 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.101914:  30%|###########4                          | 6/20 [00:01<00:04,  2.97it/s]\u001b[32m[I 2021-12-27 16:21:00,662]\u001b[0m Trial 48 finished with value: 0.10209055757716616 and parameters: {'lambda_l1': 1.6732201558149248e-06, 'lambda_l2': 1.1657693000748768e-08}. Best is trial 48 with value: 0.10209055757716616.\u001b[0m\n",
      "regularization_factors, val_score: 0.101914:  30%|###########4                          | 6/20 [00:01<00:04,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.138774\tTest's rmse: 0.102091\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000565 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.101914:  35%|#############3                        | 7/20 [00:02<00:04,  2.89it/s]\u001b[32m[I 2021-12-27 16:21:01,025]\u001b[0m Trial 49 finished with value: 0.10754398922602874 and parameters: {'lambda_l1': 0.00032266376860468077, 'lambda_l2': 1.3511533504886075}. Best is trial 48 with value: 0.10209055757716616.\u001b[0m\n",
      "regularization_factors, val_score: 0.101914:  35%|#############3                        | 7/20 [00:02<00:04,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.139969\tTest's rmse: 0.107544\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000565 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.101914:  40%|###############2                      | 8/20 [00:02<00:04,  2.83it/s]\u001b[32m[I 2021-12-27 16:21:01,395]\u001b[0m Trial 50 finished with value: 0.11281104202851322 and parameters: {'lambda_l1': 0.0052064080867593844, 'lambda_l2': 2.9478956950287447}. Best is trial 48 with value: 0.10209055757716616.\u001b[0m\n",
      "regularization_factors, val_score: 0.101914:  40%|###############2                      | 8/20 [00:02<00:04,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.141619\tTest's rmse: 0.112811\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000590 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.101447:  45%|#################1                    | 9/20 [00:03<00:03,  2.79it/s]\u001b[32m[I 2021-12-27 16:21:01,765]\u001b[0m Trial 51 finished with value: 0.10144739172351346 and parameters: {'lambda_l1': 0.00015750358671791226, 'lambda_l2': 1.960049802072028e-08}. Best is trial 51 with value: 0.10144739172351346.\u001b[0m\n",
      "regularization_factors, val_score: 0.101447:  45%|#################1                    | 9/20 [00:03<00:03,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.138027\tTest's rmse: 0.101447\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.101447:  50%|##################5                  | 10/20 [00:03<00:03,  2.76it/s]\u001b[32m[I 2021-12-27 16:21:02,136]\u001b[0m Trial 52 finished with value: 0.10635746738259617 and parameters: {'lambda_l1': 0.13325324572415176, 'lambda_l2': 1.6903753881858288}. Best is trial 51 with value: 0.10144739172351346.\u001b[0m\n",
      "regularization_factors, val_score: 0.101447:  50%|##################5                  | 10/20 [00:03<00:03,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.13911\tTest's rmse: 0.106357\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.101447:  55%|####################3                | 11/20 [00:03<00:02,  3.02it/s]\u001b[32m[I 2021-12-27 16:21:02,396]\u001b[0m Trial 53 finished with value: 0.11231489154037132 and parameters: {'lambda_l1': 9.530670448971247, 'lambda_l2': 0.003877577708411709}. Best is trial 51 with value: 0.10144739172351346.\u001b[0m\n",
      "regularization_factors, val_score: 0.101447:  55%|####################3                | 11/20 [00:03<00:02,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.165777\tTest's rmse: 0.112315\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010035 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.101447:  60%|######################2              | 12/20 [00:04<00:03,  2.59it/s]\u001b[32m[I 2021-12-27 16:21:02,907]\u001b[0m Trial 54 finished with value: 0.10191386426088359 and parameters: {'lambda_l1': 4.5941761834028466e-08, 'lambda_l2': 1.1104369883542293e-06}. Best is trial 51 with value: 0.10144739172351346.\u001b[0m\n",
      "regularization_factors, val_score: 0.101447:  60%|######################2              | 12/20 [00:04<00:03,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.138896\tTest's rmse: 0.101914\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002668 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.101447:  65%|########################             | 13/20 [00:04<00:02,  2.44it/s]\u001b[32m[I 2021-12-27 16:21:03,370]\u001b[0m Trial 55 finished with value: 0.10191386469812168 and parameters: {'lambda_l1': 5.478558812947808e-08, 'lambda_l2': 2.5077903000190522e-06}. Best is trial 51 with value: 0.10144739172351346.\u001b[0m\n",
      "regularization_factors, val_score: 0.101447:  65%|########################             | 13/20 [00:04<00:02,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.138896\tTest's rmse: 0.101914\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000595 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.101447:  70%|#########################9           | 14/20 [00:05<00:02,  2.50it/s]\u001b[32m[I 2021-12-27 16:21:03,751]\u001b[0m Trial 56 finished with value: 0.10191386454842102 and parameters: {'lambda_l1': 7.450540609063073e-08, 'lambda_l2': 1.852048850489283e-06}. Best is trial 51 with value: 0.10144739172351346.\u001b[0m\n",
      "regularization_factors, val_score: 0.101447:  70%|#########################9           | 14/20 [00:05<00:02,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.138896\tTest's rmse: 0.101914\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000744 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.101447:  75%|###########################7         | 15/20 [00:05<00:02,  2.50it/s]\u001b[32m[I 2021-12-27 16:21:04,151]\u001b[0m Trial 57 finished with value: 0.10209057484522024 and parameters: {'lambda_l1': 7.355661528389046e-06, 'lambda_l2': 9.165397734835341e-05}. Best is trial 51 with value: 0.10144739172351346.\u001b[0m\n",
      "regularization_factors, val_score: 0.101447:  75%|###########################7         | 15/20 [00:05<00:02,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.138774\tTest's rmse: 0.102091\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000553 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.101447:  80%|#############################6       | 16/20 [00:05<00:01,  2.53it/s]\u001b[32m[I 2021-12-27 16:21:04,536]\u001b[0m Trial 58 finished with value: 0.10191386414282821 and parameters: {'lambda_l1': 1.0006141434089098e-08, 'lambda_l2': 3.244642926688625e-07}. Best is trial 51 with value: 0.10144739172351346.\u001b[0m\n",
      "regularization_factors, val_score: 0.101447:  80%|#############################6       | 16/20 [00:05<00:01,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.138896\tTest's rmse: 0.101914\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000733 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.101447:  85%|###############################4     | 17/20 [00:06<00:01,  2.47it/s]\u001b[32m[I 2021-12-27 16:21:04,961]\u001b[0m Trial 59 finished with value: 0.1020905830175589 and parameters: {'lambda_l1': 2.0930791086763694e-05, 'lambda_l2': 1.3922925077311767e-08}. Best is trial 51 with value: 0.10144739172351346.\u001b[0m\n",
      "regularization_factors, val_score: 0.101447:  85%|###############################4     | 17/20 [00:06<00:01,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.138774\tTest's rmse: 0.102091\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000652 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.101447:  90%|#################################3   | 18/20 [00:06<00:00,  2.40it/s]\u001b[32m[I 2021-12-27 16:21:05,409]\u001b[0m Trial 60 finished with value: 0.1053741971845168 and parameters: {'lambda_l1': 5.920501265288836e-05, 'lambda_l2': 0.0033575989400338496}. Best is trial 51 with value: 0.10144739172351346.\u001b[0m\n",
      "regularization_factors, val_score: 0.101447:  90%|#################################3   | 18/20 [00:06<00:00,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.138224\tTest's rmse: 0.105374\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002828 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.101447:  95%|###################################1 | 19/20 [00:07<00:00,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.139008\tTest's rmse: 0.112142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:21:05,758]\u001b[0m Trial 61 finished with value: 0.1121421926077409 and parameters: {'lambda_l1': 3.617109297656081, 'lambda_l2': 2.1457568431527286e-07}. Best is trial 51 with value: 0.10144739172351346.\u001b[0m\n",
      "regularization_factors, val_score: 0.101447:  95%|###################################1 | 19/20 [00:07<00:00,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000632 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.101447: 100%|#####################################| 20/20 [00:07<00:00,  2.30it/s]\u001b[32m[I 2021-12-27 16:21:06,281]\u001b[0m Trial 62 finished with value: 0.1019138663079509 and parameters: {'lambda_l1': 1.2528622151108265e-08, 'lambda_l2': 1.8206540688370434e-05}. Best is trial 51 with value: 0.10144739172351346.\u001b[0m\n",
      "regularization_factors, val_score: 0.101447: 100%|#####################################| 20/20 [00:07<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.138896\tTest's rmse: 0.101914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.101447:   0%|                                                     | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000844 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.101447:  20%|#########                                    | 1/5 [00:00<00:02,  1.99it/s]\u001b[32m[I 2021-12-27 16:21:06,792]\u001b[0m Trial 63 finished with value: 0.11870017998961553 and parameters: {'min_child_samples': 10}. Best is trial 63 with value: 0.11870017998961553.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.101447:  20%|#########                                    | 1/5 [00:00<00:02,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.0680976\tTest's rmse: 0.1187\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000584 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.101447:  40%|##################                           | 2/5 [00:00<00:01,  2.14it/s]\u001b[32m[I 2021-12-27 16:21:07,236]\u001b[0m Trial 64 finished with value: 0.18707665827211667 and parameters: {'min_child_samples': 50}. Best is trial 63 with value: 0.11870017998961553.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.101447:  40%|##################                           | 2/5 [00:00<00:01,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.239282\tTest's rmse: 0.187077\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000552 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.101447:  60%|###########################                  | 3/5 [00:01<00:00,  2.35it/s]\u001b[32m[I 2021-12-27 16:21:07,609]\u001b[0m Trial 65 finished with value: 0.1293142714181589 and parameters: {'min_child_samples': 5}. Best is trial 63 with value: 0.11870017998961553.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.101447:  60%|###########################                  | 3/5 [00:01<00:00,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.0269096\tTest's rmse: 0.129314\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000605 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.101447:  80%|####################################         | 4/5 [00:01<00:00,  2.53it/s]\u001b[32m[I 2021-12-27 16:21:07,959]\u001b[0m Trial 66 finished with value: 0.11507831050932288 and parameters: {'min_child_samples': 25}. Best is trial 66 with value: 0.11507831050932288.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.101447:  80%|####################################         | 4/5 [00:01<00:00,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.15918\tTest's rmse: 0.115078\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000678 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.101447: 100%|#############################################| 5/5 [00:01<00:00,  2.78it/s]\u001b[32m[I 2021-12-27 16:21:08,255]\u001b[0m Trial 67 finished with value: 0.2323161449899112 and parameters: {'min_child_samples': 100}. Best is trial 66 with value: 0.11507831050932288.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.101447: 100%|#############################################| 5/5 [00:01<00:00,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[29]\tTrain's rmse: 0.329682\tTest's rmse: 0.232316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:21:08,438]\u001b[0m A new study created in memory with name: no-name-adeacb69-2200-4e1a-9537-2913216e4194\u001b[0m\n",
      "feature_fraction, val_score: inf:   0%|                                                          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001638 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.169026:  14%|######4                                      | 1/7 [00:00<00:01,  3.89it/s]\u001b[32m[I 2021-12-27 16:21:08,699]\u001b[0m Trial 0 finished with value: 0.16902597277644246 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 0.16902597277644246.\u001b[0m\n",
      "feature_fraction, val_score: 0.169026:  14%|######4                                      | 1/7 [00:00<00:01,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.134967\tTest's rmse: 0.169026\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001725 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.149363:  29%|############8                                | 2/7 [00:00<00:01,  3.73it/s]\u001b[32m[I 2021-12-27 16:21:08,973]\u001b[0m Trial 1 finished with value: 0.14936328917663394 and parameters: {'feature_fraction': 0.7}. Best is trial 1 with value: 0.14936328917663394.\u001b[0m\n",
      "feature_fraction, val_score: 0.149363:  29%|############8                                | 2/7 [00:00<00:01,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.12905\tTest's rmse: 0.149363\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.139906:  43%|###################2                         | 3/7 [00:00<00:01,  3.96it/s]\u001b[32m[I 2021-12-27 16:21:09,207]\u001b[0m Trial 2 finished with value: 0.1399063359860016 and parameters: {'feature_fraction': 0.8}. Best is trial 2 with value: 0.1399063359860016.\u001b[0m\n",
      "feature_fraction, val_score: 0.139906:  43%|###################2                         | 3/7 [00:00<00:01,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.14443\tTest's rmse: 0.139906\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001072 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.139906:  57%|#########################7                   | 4/7 [00:01<00:00,  4.00it/s]\u001b[32m[I 2021-12-27 16:21:09,456]\u001b[0m Trial 3 finished with value: 0.14031536940373338 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 2 with value: 0.1399063359860016.\u001b[0m\n",
      "feature_fraction, val_score: 0.139906:  57%|#########################7                   | 4/7 [00:01<00:00,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.155903\tTest's rmse: 0.140315\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.129464\tTest's rmse: 0.160576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.139906:  71%|################################1            | 5/7 [00:01<00:00,  4.29it/s]\u001b[32m[I 2021-12-27 16:21:09,656]\u001b[0m Trial 4 finished with value: 0.16057600609609454 and parameters: {'feature_fraction': 0.5}. Best is trial 2 with value: 0.1399063359860016.\u001b[0m\n",
      "feature_fraction, val_score: 0.139906:  71%|################################1            | 5/7 [00:01<00:00,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.146988\tTest's rmse: 0.141503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.139906:  86%|######################################5      | 6/7 [00:01<00:00,  4.30it/s]\u001b[32m[I 2021-12-27 16:21:09,887]\u001b[0m Trial 5 finished with value: 0.1415026234343981 and parameters: {'feature_fraction': 1.0}. Best is trial 2 with value: 0.1399063359860016.\u001b[0m\n",
      "feature_fraction, val_score: 0.139906: 100%|#############################################| 7/7 [00:01<00:00,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001339 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.128939\tTest's rmse: 0.159312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:21:10,106]\u001b[0m Trial 6 finished with value: 0.1593121386019105 and parameters: {'feature_fraction': 0.6}. Best is trial 2 with value: 0.1399063359860016.\u001b[0m\n",
      "feature_fraction, val_score: 0.139906: 100%|#############################################| 7/7 [00:01<00:00,  4.20it/s]\n",
      "num_leaves, val_score: 0.139906:   0%|                                                          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002738 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.139906:   5%|##5                                               | 1/20 [00:00<00:12,  1.56it/s]\u001b[32m[I 2021-12-27 16:21:10,756]\u001b[0m Trial 7 finished with value: 0.14594579147715137 and parameters: {'num_leaves': 135}. Best is trial 7 with value: 0.14594579147715137.\u001b[0m\n",
      "num_leaves, val_score: 0.139906:   5%|##5                                               | 1/20 [00:00<00:12,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.145545\tTest's rmse: 0.145946\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002164 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.139906:  10%|#####                                             | 2/20 [00:01<00:09,  1.82it/s]\u001b[32m[I 2021-12-27 16:21:11,239]\u001b[0m Trial 8 finished with value: 0.14311977694032388 and parameters: {'num_leaves': 95}. Best is trial 8 with value: 0.14311977694032388.\u001b[0m\n",
      "num_leaves, val_score: 0.139906:  15%|#######5                                          | 3/20 [00:01<00:05,  2.85it/s]\u001b[32m[I 2021-12-27 16:21:11,357]\u001b[0m Trial 9 finished with value: 0.1645584075952096 and parameters: {'num_leaves': 3}. Best is trial 8 with value: 0.14311977694032388.\u001b[0m\n",
      "num_leaves, val_score: 0.139906:  15%|#######5                                          | 3/20 [00:01<00:05,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.143997\tTest's rmse: 0.14312\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002235 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.196966\tTest's rmse: 0.164558\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001226 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.139906:  20%|##########                                        | 4/20 [00:02<00:09,  1.68it/s]\u001b[32m[I 2021-12-27 16:21:12,321]\u001b[0m Trial 10 finished with value: 0.145637193328109 and parameters: {'num_leaves': 214}. Best is trial 8 with value: 0.14311977694032388.\u001b[0m\n",
      "num_leaves, val_score: 0.139906:  20%|##########                                        | 4/20 [00:02<00:09,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.144101\tTest's rmse: 0.145637\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001530 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.139906:  25%|############5                                     | 5/20 [00:02<00:08,  1.77it/s]\u001b[32m[I 2021-12-27 16:21:12,837]\u001b[0m Trial 11 finished with value: 0.14071153879278125 and parameters: {'num_leaves': 106}. Best is trial 11 with value: 0.14071153879278125.\u001b[0m\n",
      "num_leaves, val_score: 0.139906:  25%|############5                                     | 5/20 [00:02<00:08,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.143325\tTest's rmse: 0.140712\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.139645:  30%|###############                                   | 6/20 [00:03<00:07,  1.95it/s]\u001b[32m[I 2021-12-27 16:21:13,247]\u001b[0m Trial 12 finished with value: 0.1396451097306012 and parameters: {'num_leaves': 81}. Best is trial 12 with value: 0.1396451097306012.\u001b[0m\n",
      "num_leaves, val_score: 0.139645:  30%|###############                                   | 6/20 [00:03<00:07,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.143468\tTest's rmse: 0.139645\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001504 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.139645:  35%|#################5                                | 7/20 [00:03<00:07,  1.81it/s]\u001b[32m[I 2021-12-27 16:21:13,884]\u001b[0m Trial 13 finished with value: 0.14407172605921373 and parameters: {'num_leaves': 133}. Best is trial 12 with value: 0.1396451097306012.\u001b[0m\n",
      "num_leaves, val_score: 0.139645:  35%|#################5                                | 7/20 [00:03<00:07,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.146713\tTest's rmse: 0.144072\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001950 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.139645:  40%|####################                              | 8/20 [00:04<00:05,  2.03it/s]\u001b[32m[I 2021-12-27 16:21:14,244]\u001b[0m Trial 14 finished with value: 0.14095601489030385 and parameters: {'num_leaves': 46}. Best is trial 12 with value: 0.1396451097306012.\u001b[0m\n",
      "num_leaves, val_score: 0.139645:  40%|####################                              | 8/20 [00:04<00:05,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.139921\tTest's rmse: 0.140956\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000482 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.139645:  45%|######################5                           | 9/20 [00:04<00:05,  1.95it/s]\u001b[32m[I 2021-12-27 16:21:14,806]\u001b[0m Trial 15 finished with value: 0.14311977694032388 and parameters: {'num_leaves': 95}. Best is trial 12 with value: 0.1396451097306012.\u001b[0m\n",
      "num_leaves, val_score: 0.139645:  45%|######################5                           | 9/20 [00:04<00:05,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.143997\tTest's rmse: 0.14312\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001688 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.139645:  50%|########################5                        | 10/20 [00:05<00:06,  1.59it/s]\u001b[32m[I 2021-12-27 16:21:15,693]\u001b[0m Trial 16 finished with value: 0.14360992029304295 and parameters: {'num_leaves': 205}. Best is trial 12 with value: 0.1396451097306012.\u001b[0m\n",
      "num_leaves, val_score: 0.139645:  50%|########################5                        | 10/20 [00:05<00:06,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.142824\tTest's rmse: 0.14361\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.139645:  55%|##########################9                      | 11/20 [00:06<00:06,  1.44it/s]\u001b[32m[I 2021-12-27 16:21:16,535]\u001b[0m Trial 17 finished with value: 0.14118424459645865 and parameters: {'num_leaves': 169}. Best is trial 12 with value: 0.1396451097306012.\u001b[0m\n",
      "num_leaves, val_score: 0.139645:  55%|##########################9                      | 11/20 [00:06<00:06,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.138981\tTest's rmse: 0.141184\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.139645:  60%|#############################4                   | 12/20 [00:06<00:04,  1.61it/s]\u001b[32m[I 2021-12-27 16:21:16,987]\u001b[0m Trial 18 finished with value: 0.14102427525783684 and parameters: {'num_leaves': 71}. Best is trial 12 with value: 0.1396451097306012.\u001b[0m\n",
      "num_leaves, val_score: 0.139645:  60%|#############################4                   | 12/20 [00:06<00:04,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.145515\tTest's rmse: 0.141024\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001369 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.139226:  65%|###############################8                 | 13/20 [00:07<00:03,  1.97it/s]\u001b[32m[I 2021-12-27 16:21:17,236]\u001b[0m Trial 19 finished with value: 0.13922569217350136 and parameters: {'num_leaves': 37}. Best is trial 19 with value: 0.13922569217350136.\u001b[0m\n",
      "num_leaves, val_score: 0.139226:  65%|###############################8                 | 13/20 [00:07<00:03,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.137652\tTest's rmse: 0.139226\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001850 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.138997:  70%|##################################3              | 14/20 [00:07<00:02,  2.34it/s]\u001b[32m[I 2021-12-27 16:21:17,475]\u001b[0m Trial 20 finished with value: 0.13899676369006556 and parameters: {'num_leaves': 24}. Best is trial 20 with value: 0.13899676369006556.\u001b[0m\n",
      "num_leaves, val_score: 0.138997:  75%|####################################7            | 15/20 [00:07<00:01,  3.01it/s]\u001b[32m[I 2021-12-27 16:21:17,589]\u001b[0m Trial 21 finished with value: 0.15101032941010567 and parameters: {'num_leaves': 5}. Best is trial 20 with value: 0.13899676369006556.\u001b[0m\n",
      "num_leaves, val_score: 0.138997:  75%|####################################7            | 15/20 [00:07<00:01,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.137575\tTest's rmse: 0.138997\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000542 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.161555\tTest's rmse: 0.15101\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.138997:  80%|#######################################2         | 16/20 [00:07<00:01,  3.02it/s]\u001b[32m[I 2021-12-27 16:21:17,920]\u001b[0m Trial 22 finished with value: 0.14095601489030385 and parameters: {'num_leaves': 46}. Best is trial 20 with value: 0.13899676369006556.\u001b[0m\n",
      "num_leaves, val_score: 0.138997:  80%|#######################################2         | 16/20 [00:07<00:01,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.139921\tTest's rmse: 0.140956\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001820 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.138997:  85%|#########################################6       | 17/20 [00:08<00:00,  3.03it/s]\u001b[32m[I 2021-12-27 16:21:18,247]\u001b[0m Trial 23 finished with value: 0.14156738492472565 and parameters: {'num_leaves': 39}. Best is trial 20 with value: 0.13899676369006556.\u001b[0m\n",
      "num_leaves, val_score: 0.138997:  85%|#########################################6       | 17/20 [00:08<00:00,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.143788\tTest's rmse: 0.141567\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001579 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.138997:  90%|############################################1    | 18/20 [00:09<00:01,  1.77it/s]\u001b[32m[I 2021-12-27 16:21:19,353]\u001b[0m Trial 24 finished with value: 0.14362464120108245 and parameters: {'num_leaves': 248}. Best is trial 20 with value: 0.13899676369006556.\u001b[0m\n",
      "num_leaves, val_score: 0.138997:  90%|############################################1    | 18/20 [00:09<00:01,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.144507\tTest's rmse: 0.143625\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001762 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.138532:  95%|##############################################5  | 19/20 [00:09<00:00,  2.20it/s]\u001b[32m[I 2021-12-27 16:21:19,552]\u001b[0m Trial 25 finished with value: 0.13853218890024574 and parameters: {'num_leaves': 15}. Best is trial 25 with value: 0.13853218890024574.\u001b[0m\n",
      "num_leaves, val_score: 0.138532:  95%|##############################################5  | 19/20 [00:09<00:00,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.14426\tTest's rmse: 0.138532\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.14334\tTest's rmse: 0.140903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.138532: 100%|#################################################| 20/20 [00:09<00:00,  2.68it/s]\u001b[32m[I 2021-12-27 16:21:19,738]\u001b[0m Trial 26 finished with value: 0.14090348453270315 and parameters: {'num_leaves': 18}. Best is trial 25 with value: 0.13853218890024574.\u001b[0m\n",
      "num_leaves, val_score: 0.138532: 100%|#################################################| 20/20 [00:09<00:00,  2.08it/s]\n",
      "bagging, val_score: 0.138532:  10%|#####3                                               | 1/10 [00:00<00:01,  5.35it/s]\u001b[32m[I 2021-12-27 16:21:19,934]\u001b[0m Trial 27 finished with value: 0.1543006898501231 and parameters: {'bagging_fraction': 0.7083491336251715, 'bagging_freq': 6}. Best is trial 27 with value: 0.1543006898501231.\u001b[0m\n",
      "bagging, val_score: 0.138532:  10%|#####3                                               | 1/10 [00:00<00:01,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001904 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.175456\tTest's rmse: 0.154301\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.138532:  20%|##########6                                          | 2/10 [00:00<00:01,  5.35it/s]\u001b[32m[I 2021-12-27 16:21:20,122]\u001b[0m Trial 28 finished with value: 0.1540057827007851 and parameters: {'bagging_fraction': 0.589740639522571, 'bagging_freq': 1}. Best is trial 28 with value: 0.1540057827007851.\u001b[0m\n",
      "bagging, val_score: 0.138532:  20%|##########6                                          | 2/10 [00:00<00:01,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.168779\tTest's rmse: 0.154006\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001370 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.138532:  30%|###############9                                     | 3/10 [00:00<00:01,  5.47it/s]\u001b[32m[I 2021-12-27 16:21:20,297]\u001b[0m Trial 29 finished with value: 0.14636409794746363 and parameters: {'bagging_fraction': 0.6024587474795289, 'bagging_freq': 2}. Best is trial 29 with value: 0.14636409794746363.\u001b[0m\n",
      "bagging, val_score: 0.138532:  30%|###############9                                     | 3/10 [00:00<00:01,  5.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.170643\tTest's rmse: 0.146364\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001739 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.138532:  40%|#####################2                               | 4/10 [00:00<00:01,  5.23it/s]\u001b[32m[I 2021-12-27 16:21:20,504]\u001b[0m Trial 30 finished with value: 0.15889226925238803 and parameters: {'bagging_fraction': 0.539014001132226, 'bagging_freq': 5}. Best is trial 29 with value: 0.14636409794746363.\u001b[0m\n",
      "bagging, val_score: 0.138532:  40%|#####################2                               | 4/10 [00:00<00:01,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.17976\tTest's rmse: 0.158892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.138532:  50%|##########################5                          | 5/10 [00:00<00:00,  5.15it/s]\u001b[32m[I 2021-12-27 16:21:20,703]\u001b[0m Trial 31 finished with value: 0.1604980704148269 and parameters: {'bagging_fraction': 0.5307438708628166, 'bagging_freq': 3}. Best is trial 29 with value: 0.14636409794746363.\u001b[0m\n",
      "bagging, val_score: 0.138532:  50%|##########################5                          | 5/10 [00:00<00:00,  5.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.180179\tTest's rmse: 0.160498\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001641 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.138532:  60%|###############################8                     | 6/10 [00:01<00:00,  5.13it/s]\u001b[32m[I 2021-12-27 16:21:20,899]\u001b[0m Trial 32 finished with value: 0.14638322827346176 and parameters: {'bagging_fraction': 0.8781973150862501, 'bagging_freq': 4}. Best is trial 29 with value: 0.14636409794746363.\u001b[0m\n",
      "bagging, val_score: 0.138532:  60%|###############################8                     | 6/10 [00:01<00:00,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.149135\tTest's rmse: 0.146383\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.138532:  70%|#####################################                | 7/10 [00:01<00:00,  5.12it/s]\u001b[32m[I 2021-12-27 16:21:21,095]\u001b[0m Trial 33 finished with value: 0.14798865851241794 and parameters: {'bagging_fraction': 0.8144049620516955, 'bagging_freq': 5}. Best is trial 29 with value: 0.14636409794746363.\u001b[0m\n",
      "bagging, val_score: 0.138532:  70%|#####################################                | 7/10 [00:01<00:00,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.15887\tTest's rmse: 0.147989\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001307 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.138532:  80%|##########################################4          | 8/10 [00:01<00:00,  5.44it/s]\u001b[32m[I 2021-12-27 16:21:21,255]\u001b[0m Trial 34 finished with value: 0.16330229304814428 and parameters: {'bagging_fraction': 0.4201753184952023, 'bagging_freq': 6}. Best is trial 29 with value: 0.14636409794746363.\u001b[0m\n",
      "bagging, val_score: 0.138532:  80%|##########################################4          | 8/10 [00:01<00:00,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.180715\tTest's rmse: 0.163302\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001002 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.138532:  90%|###############################################7     | 9/10 [00:01<00:00,  5.38it/s]\u001b[32m[I 2021-12-27 16:21:21,444]\u001b[0m Trial 35 finished with value: 0.15264591569646543 and parameters: {'bagging_fraction': 0.7990434156925725, 'bagging_freq': 5}. Best is trial 29 with value: 0.14636409794746363.\u001b[0m\n",
      "bagging, val_score: 0.138532:  90%|###############################################7     | 9/10 [00:01<00:00,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.168998\tTest's rmse: 0.152646\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001396 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.143884\tTest's rmse: 0.142381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.138532: 100%|####################################################| 10/10 [00:01<00:00,  5.38it/s]\u001b[32m[I 2021-12-27 16:21:21,631]\u001b[0m Trial 36 finished with value: 0.1423813080876264 and parameters: {'bagging_fraction': 0.9084738480207944, 'bagging_freq': 3}. Best is trial 36 with value: 0.1423813080876264.\u001b[0m\n",
      "bagging, val_score: 0.138532: 100%|####################################################| 10/10 [00:01<00:00,  5.30it/s]\n",
      "feature_fraction_stage2, val_score: 0.138532:  17%|######3                               | 1/6 [00:00<00:00,  5.99it/s]\u001b[32m[I 2021-12-27 16:21:21,806]\u001b[0m Trial 37 finished with value: 0.13853218890024574 and parameters: {'feature_fraction': 0.8160000000000001}. Best is trial 37 with value: 0.13853218890024574.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.138532:  17%|######3                               | 1/6 [00:00<00:00,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001115 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.14426\tTest's rmse: 0.138532\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001036 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.138532:  33%|############6                         | 2/6 [00:00<00:00,  6.00it/s]\u001b[32m[I 2021-12-27 16:21:21,970]\u001b[0m Trial 38 finished with value: 0.1462183960715439 and parameters: {'feature_fraction': 0.7200000000000001}. Best is trial 37 with value: 0.13853218890024574.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.138532:  33%|############6                         | 2/6 [00:00<00:00,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.128812\tTest's rmse: 0.146218\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001346 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.138532:  50%|###################                   | 3/6 [00:00<00:00,  5.76it/s]\u001b[32m[I 2021-12-27 16:21:22,153]\u001b[0m Trial 39 finished with value: 0.14076829984559736 and parameters: {'feature_fraction': 0.8480000000000001}. Best is trial 37 with value: 0.13853218890024574.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.138532:  50%|###################                   | 3/6 [00:00<00:00,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.140806\tTest's rmse: 0.140768\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000723 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.140806\tTest's rmse: 0.140768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.138532:  67%|#########################3            | 4/6 [00:00<00:00,  5.65it/s]\u001b[32m[I 2021-12-27 16:21:22,336]\u001b[0m Trial 40 finished with value: 0.14076829984559736 and parameters: {'feature_fraction': 0.88}. Best is trial 37 with value: 0.13853218890024574.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.136961:  83%|###############################6      | 5/6 [00:00<00:00,  5.29it/s]\u001b[32m[I 2021-12-27 16:21:22,546]\u001b[0m Trial 41 finished with value: 0.13696087913852567 and parameters: {'feature_fraction': 0.784}. Best is trial 41 with value: 0.13696087913852567.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.136961:  83%|###############################6      | 5/6 [00:00<00:00,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001804 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.136004\tTest's rmse: 0.136961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.136961: 100%|######################################| 6/6 [00:01<00:00,  5.15it/s]\u001b[32m[I 2021-12-27 16:21:22,751]\u001b[0m Trial 42 finished with value: 0.13696087913852567 and parameters: {'feature_fraction': 0.7520000000000001}. Best is trial 41 with value: 0.13696087913852567.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.136961: 100%|######################################| 6/6 [00:01<00:00,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000759 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.136004\tTest's rmse: 0.136961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "regularization_factors, val_score: 0.136961:   5%|#9                                    | 1/20 [00:00<00:03,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001905 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.136004\tTest's rmse: 0.136961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:21:22,977]\u001b[0m Trial 43 finished with value: 0.13696094662703157 and parameters: {'lambda_l1': 1.0296645206178409e-07, 'lambda_l2': 0.00011602551513388137}. Best is trial 43 with value: 0.13696094662703157.\u001b[0m\n",
      "regularization_factors, val_score: 0.136961:  10%|###8                                  | 2/20 [00:00<00:03,  4.69it/s]\u001b[32m[I 2021-12-27 16:21:23,183]\u001b[0m Trial 44 finished with value: 0.13696186034149607 and parameters: {'lambda_l1': 6.127324569603203e-06, 'lambda_l2': 0.0016798673195348615}. Best is trial 43 with value: 0.13696094662703157.\u001b[0m\n",
      "regularization_factors, val_score: 0.136961:  10%|###8                                  | 2/20 [00:00<00:03,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002234 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.136006\tTest's rmse: 0.136962\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000701 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.136961:  15%|#####7                                | 3/20 [00:00<00:03,  4.85it/s]\u001b[32m[I 2021-12-27 16:21:23,381]\u001b[0m Trial 45 finished with value: 0.13873842182268087 and parameters: {'lambda_l1': 0.0006604716498407003, 'lambda_l2': 0.001653238584042396}. Best is trial 43 with value: 0.13696094662703157.\u001b[0m\n",
      "regularization_factors, val_score: 0.136961:  15%|#####7                                | 3/20 [00:00<00:03,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.138549\tTest's rmse: 0.138738\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001938 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.13321\tTest's rmse: 0.139333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.136961:  20%|#######6                              | 4/20 [00:00<00:03,  4.67it/s]\u001b[32m[I 2021-12-27 16:21:23,609]\u001b[0m Trial 46 finished with value: 0.1393327533654595 and parameters: {'lambda_l1': 0.02822520573165317, 'lambda_l2': 0.03889373583460385}. Best is trial 43 with value: 0.13696094662703157.\u001b[0m\n",
      "regularization_factors, val_score: 0.136961:  25%|#########5                            | 5/20 [00:01<00:03,  4.82it/s]\u001b[32m[I 2021-12-27 16:21:23,802]\u001b[0m Trial 47 finished with value: 0.13696088318009442 and parameters: {'lambda_l1': 7.75366576100558e-07, 'lambda_l2': 4.629865876725104e-06}. Best is trial 47 with value: 0.13696088318009442.\u001b[0m\n",
      "regularization_factors, val_score: 0.136961:  25%|#########5                            | 5/20 [00:01<00:03,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.136004\tTest's rmse: 0.136961\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001309 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.136961:  30%|###########4                          | 6/20 [00:01<00:02,  5.11it/s]\u001b[32m[I 2021-12-27 16:21:23,975]\u001b[0m Trial 48 finished with value: 0.13696087919896247 and parameters: {'lambda_l1': 2.455464920900959e-08, 'lambda_l2': 6.870317017393404e-08}. Best is trial 48 with value: 0.13696087919896247.\u001b[0m\n",
      "regularization_factors, val_score: 0.136961:  30%|###########4                          | 6/20 [00:01<00:02,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.136004\tTest's rmse: 0.136961\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001870 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.136961:  35%|#############3                        | 7/20 [00:01<00:02,  5.39it/s]\u001b[32m[I 2021-12-27 16:21:24,140]\u001b[0m Trial 49 finished with value: 0.13937969643261283 and parameters: {'lambda_l1': 1.2023471337604908e-06, 'lambda_l2': 0.04024202968173741}. Best is trial 48 with value: 0.13696087919896247.\u001b[0m\n",
      "regularization_factors, val_score: 0.136961:  35%|#############3                        | 7/20 [00:01<00:02,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.133285\tTest's rmse: 0.13938\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001318 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.136961:  40%|###############2                      | 8/20 [00:01<00:02,  5.51it/s]\u001b[32m[I 2021-12-27 16:21:24,313]\u001b[0m Trial 50 finished with value: 0.13696231915524168 and parameters: {'lambda_l1': 9.266759333301157e-07, 'lambda_l2': 0.002485651020138733}. Best is trial 48 with value: 0.13696087919896247.\u001b[0m\n",
      "regularization_factors, val_score: 0.136961:  40%|###############2                      | 8/20 [00:01<00:02,  5.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.136007\tTest's rmse: 0.136962\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001310 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.13923\tTest's rmse: 0.1461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.136961:  45%|#################1                    | 9/20 [00:01<00:01,  5.54it/s]\u001b[32m[I 2021-12-27 16:21:24,492]\u001b[0m Trial 51 finished with value: 0.14609986656226756 and parameters: {'lambda_l1': 1.8722605372554877e-06, 'lambda_l2': 1.635564094838647}. Best is trial 48 with value: 0.13696087919896247.\u001b[0m\n",
      "regularization_factors, val_score: 0.136961:  50%|##################5                  | 10/20 [00:01<00:01,  5.58it/s]\u001b[32m[I 2021-12-27 16:21:24,684]\u001b[0m Trial 52 finished with value: 0.14380520643208097 and parameters: {'lambda_l1': 1.4001183696946355, 'lambda_l2': 0.16196134542063204}. Best is trial 48 with value: 0.13696087919896247.\u001b[0m\n",
      "regularization_factors, val_score: 0.136961:  50%|##################5                  | 10/20 [00:01<00:01,  5.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000477 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.131515\tTest's rmse: 0.143805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.136961:  55%|####################3                | 11/20 [00:02<00:01,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003010 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.136004\tTest's rmse: 0.136961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:21:24,910]\u001b[0m Trial 53 finished with value: 0.1369608791675667 and parameters: {'lambda_l1': 1.802594471604389e-08, 'lambda_l2': 1.2761749722977749e-08}. Best is trial 53 with value: 0.1369608791675667.\u001b[0m\n",
      "regularization_factors, val_score: 0.136961:  60%|######################2              | 12/20 [00:02<00:01,  4.95it/s]\u001b[32m[I 2021-12-27 16:21:25,119]\u001b[0m Trial 54 finished with value: 0.13696087916325173 and parameters: {'lambda_l1': 1.0313332045501703e-08, 'lambda_l2': 1.284448324260443e-08}. Best is trial 54 with value: 0.13696087916325173.\u001b[0m\n",
      "regularization_factors, val_score: 0.136961:  60%|######################2              | 12/20 [00:02<00:01,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001783 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.136004\tTest's rmse: 0.136961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.136961:  65%|########################             | 13/20 [00:02<00:01,  4.88it/s]\u001b[32m[I 2021-12-27 16:21:25,331]\u001b[0m Trial 55 finished with value: 0.13873662615521834 and parameters: {'lambda_l1': 6.116851238338521e-05, 'lambda_l2': 1.0643237087921175e-08}. Best is trial 54 with value: 0.13696087916325173.\u001b[0m\n",
      "regularization_factors, val_score: 0.136961:  65%|########################             | 13/20 [00:02<00:01,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001610 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.138545\tTest's rmse: 0.138737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.136961:  70%|#########################9           | 14/20 [00:02<00:01,  4.73it/s]\u001b[32m[I 2021-12-27 16:21:25,558]\u001b[0m Trial 56 finished with value: 0.13696087947416916 and parameters: {'lambda_l1': 1.3502327963931553e-08, 'lambda_l2': 5.088219899818821e-07}. Best is trial 54 with value: 0.13696087916325173.\u001b[0m\n",
      "regularization_factors, val_score: 0.136961:  70%|#########################9           | 14/20 [00:02<00:01,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001611 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.136004\tTest's rmse: 0.136961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.136961:  75%|###########################7         | 15/20 [00:03<00:01,  4.69it/s]\u001b[32m[I 2021-12-27 16:21:25,775]\u001b[0m Trial 57 finished with value: 0.13873701850497192 and parameters: {'lambda_l1': 0.0003229675028259236, 'lambda_l2': 1.4362674893741852e-05}. Best is trial 54 with value: 0.13696087916325173.\u001b[0m\n",
      "regularization_factors, val_score: 0.136961:  75%|###########################7         | 15/20 [00:03<00:01,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001893 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.138546\tTest's rmse: 0.138737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.136961:  80%|#############################6       | 16/20 [00:03<00:00,  4.68it/s]\u001b[32m[I 2021-12-27 16:21:25,992]\u001b[0m Trial 58 finished with value: 0.13696087917943384 and parameters: {'lambda_l1': 1.250044841762211e-08, 'lambda_l2': 1.2534974623943914e-08}. Best is trial 54 with value: 0.13696087916325173.\u001b[0m\n",
      "regularization_factors, val_score: 0.136961:  80%|#############################6       | 16/20 [00:03<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000624 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.136004\tTest's rmse: 0.136961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.136961:  85%|###############################4     | 17/20 [00:03<00:00,  4.72it/s]\u001b[32m[I 2021-12-27 16:21:26,198]\u001b[0m Trial 59 finished with value: 0.138816598691121 and parameters: {'lambda_l1': 0.008748568489057966, 'lambda_l2': 9.223352145100599e-07}. Best is trial 54 with value: 0.13696087916325173.\u001b[0m\n",
      "regularization_factors, val_score: 0.136961:  85%|###############################4     | 17/20 [00:03<00:00,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001580 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.138164\tTest's rmse: 0.138817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.136961:  90%|#################################3   | 18/20 [00:03<00:00,  4.90it/s]\u001b[32m[I 2021-12-27 16:21:26,399]\u001b[0m Trial 60 finished with value: 0.1369608794617533 and parameters: {'lambda_l1': 1.401621742005574e-07, 'lambda_l2': 1.6584972285295777e-07}. Best is trial 54 with value: 0.13696087916325173.\u001b[0m\n",
      "regularization_factors, val_score: 0.136961:  90%|#################################3   | 18/20 [00:03<00:00,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001939 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.136004\tTest's rmse: 0.136961\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.136961:  95%|###################################1 | 19/20 [00:03<00:00,  4.92it/s]\u001b[32m[I 2021-12-27 16:21:26,584]\u001b[0m Trial 61 finished with value: 0.13696092611328844 and parameters: {'lambda_l1': 2.6283143971211382e-05, 'lambda_l2': 1.4682789777996319e-05}. Best is trial 54 with value: 0.13696087916325173.\u001b[0m\n",
      "regularization_factors, val_score: 0.136961:  95%|###################################1 | 19/20 [00:03<00:00,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.136004\tTest's rmse: 0.136961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.136961: 100%|#####################################| 20/20 [00:04<00:00,  4.75it/s]\u001b[32m[I 2021-12-27 16:21:26,813]\u001b[0m Trial 62 finished with value: 0.13696087943062632 and parameters: {'lambda_l1': 1.9095284057498246e-07, 'lambda_l2': 8.093764926727998e-08}. Best is trial 54 with value: 0.13696087916325173.\u001b[0m\n",
      "regularization_factors, val_score: 0.136961: 100%|#####################################| 20/20 [00:04<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001775 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.136004\tTest's rmse: 0.136961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.136961:  20%|#########                                    | 1/5 [00:00<00:00,  6.25it/s]\u001b[32m[I 2021-12-27 16:21:26,973]\u001b[0m Trial 63 finished with value: 0.15491747452330878 and parameters: {'min_child_samples': 5}. Best is trial 63 with value: 0.15491747452330878.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.136961:  20%|#########                                    | 1/5 [00:00<00:00,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001966 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.0402285\tTest's rmse: 0.154917\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.136961:  40%|##################                           | 2/5 [00:00<00:00,  6.15it/s]\u001b[32m[I 2021-12-27 16:21:27,137]\u001b[0m Trial 64 finished with value: 0.1548241042499743 and parameters: {'min_child_samples': 10}. Best is trial 64 with value: 0.1548241042499743.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.136961:  40%|##################                           | 2/5 [00:00<00:00,  6.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[48]\tTrain's rmse: 0.117658\tTest's rmse: 0.154824\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001787 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.284769\tTest's rmse: 0.195085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.136961:  60%|###########################                  | 3/5 [00:00<00:00,  5.73it/s]\u001b[32m[I 2021-12-27 16:21:27,326]\u001b[0m Trial 65 finished with value: 0.19508496804185863 and parameters: {'min_child_samples': 100}. Best is trial 64 with value: 0.1548241042499743.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.136961:  60%|###########################                  | 3/5 [00:00<00:00,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001898 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.147657\tTest's rmse: 0.151099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.136961:  80%|####################################         | 4/5 [00:00<00:00,  5.20it/s]\u001b[32m[I 2021-12-27 16:21:27,548]\u001b[0m Trial 66 finished with value: 0.15109944657701987 and parameters: {'min_child_samples': 25}. Best is trial 66 with value: 0.15109944657701987.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.136961:  80%|####################################         | 4/5 [00:00<00:00,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000717 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.136961: 100%|#############################################| 5/5 [00:00<00:00,  4.80it/s]\u001b[32m[I 2021-12-27 16:21:27,784]\u001b[0m Trial 67 finished with value: 0.17486187978056406 and parameters: {'min_child_samples': 50}. Best is trial 66 with value: 0.15109944657701987.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.136961: 100%|#############################################| 5/5 [00:00<00:00,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.224713\tTest's rmse: 0.174862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:21:27,980]\u001b[0m A new study created in memory with name: no-name-3dc4259e-feec-4f79-a1fe-81b09c480922\u001b[0m\n",
      "feature_fraction, val_score: inf:   0%|                                                          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000523 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.093056:  14%|######4                                      | 1/7 [00:00<00:01,  3.13it/s]\u001b[32m[I 2021-12-27 16:21:28,307]\u001b[0m Trial 0 finished with value: 0.09305587411644023 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 0.09305587411644023.\u001b[0m\n",
      "feature_fraction, val_score: 0.093056:  14%|######4                                      | 1/7 [00:00<00:01,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.136853\tTest's rmse: 0.0930559\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002266 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.090146:  29%|############8                                | 2/7 [00:00<00:01,  3.18it/s]\u001b[32m[I 2021-12-27 16:21:28,615]\u001b[0m Trial 1 finished with value: 0.09014609510889711 and parameters: {'feature_fraction': 0.6}. Best is trial 1 with value: 0.09014609510889711.\u001b[0m\n",
      "feature_fraction, val_score: 0.090146:  29%|############8                                | 2/7 [00:00<00:01,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.126647\tTest's rmse: 0.0901461\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002079 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.083066:  43%|###################2                         | 3/7 [00:00<00:01,  3.32it/s]\u001b[32m[I 2021-12-27 16:21:28,903]\u001b[0m Trial 2 finished with value: 0.0830657271294555 and parameters: {'feature_fraction': 0.5}. Best is trial 2 with value: 0.0830657271294555.\u001b[0m\n",
      "feature_fraction, val_score: 0.083066:  43%|###################2                         | 3/7 [00:00<00:01,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.133355\tTest's rmse: 0.0830657\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000619 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.021773:  57%|#########################7                   | 4/7 [00:01<00:00,  3.41it/s]\u001b[32m[I 2021-12-27 16:21:29,184]\u001b[0m Trial 3 finished with value: 0.021772541083253553 and parameters: {'feature_fraction': 1.0}. Best is trial 3 with value: 0.021772541083253553.\u001b[0m\n",
      "feature_fraction, val_score: 0.021773:  57%|#########################7                   | 4/7 [00:01<00:00,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[43]\tTrain's rmse: 0.165773\tTest's rmse: 0.0217725\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001853 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.021773:  71%|################################1            | 5/7 [00:01<00:00,  3.01it/s]\u001b[32m[I 2021-12-27 16:21:29,587]\u001b[0m Trial 4 finished with value: 0.05415092072554367 and parameters: {'feature_fraction': 0.8}. Best is trial 3 with value: 0.021772541083253553.\u001b[0m\n",
      "feature_fraction, val_score: 0.021773:  71%|################################1            | 5/7 [00:01<00:00,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.144156\tTest's rmse: 0.0541509\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002486 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.021773:  86%|######################################5      | 6/7 [00:01<00:00,  2.95it/s]\u001b[32m[I 2021-12-27 16:21:29,936]\u001b[0m Trial 5 finished with value: 0.04017005974914526 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 3 with value: 0.021772541083253553.\u001b[0m\n",
      "feature_fraction, val_score: 0.021773:  86%|######################################5      | 6/7 [00:01<00:00,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.150344\tTest's rmse: 0.0401701\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000588 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.021773: 100%|#############################################| 7/7 [00:02<00:00,  2.89it/s]\u001b[32m[I 2021-12-27 16:21:30,296]\u001b[0m Trial 6 finished with value: 0.08032294115549551 and parameters: {'feature_fraction': 0.7}. Best is trial 3 with value: 0.021772541083253553.\u001b[0m\n",
      "feature_fraction, val_score: 0.021773: 100%|#############################################| 7/7 [00:02<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.129613\tTest's rmse: 0.0803229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.021773:   0%|                                                          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001887 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.021773:   5%|##5                                               | 1/20 [00:00<00:14,  1.29it/s]\u001b[32m[I 2021-12-27 16:21:31,081]\u001b[0m Trial 7 finished with value: 0.02190792524823022 and parameters: {'num_leaves': 114}. Best is trial 7 with value: 0.02190792524823022.\u001b[0m\n",
      "num_leaves, val_score: 0.021677:   5%|##5                                               | 1/20 [00:00<00:14,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[42]\tTrain's rmse: 0.167365\tTest's rmse: 0.0219079\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\tTrain's rmse: 0.16391\tTest's rmse: 0.0216766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.021677:  10%|#####                                             | 2/20 [00:00<00:07,  2.45it/s]\u001b[32m[I 2021-12-27 16:21:31,245]\u001b[0m Trial 8 finished with value: 0.021676607732049248 and parameters: {'num_leaves': 9}. Best is trial 8 with value: 0.021676607732049248.\u001b[0m\n",
      "num_leaves, val_score: 0.021677:  15%|#######5                                          | 3/20 [00:01<00:04,  3.59it/s]\u001b[32m[I 2021-12-27 16:21:31,362]\u001b[0m Trial 9 finished with value: 0.04035813977004706 and parameters: {'num_leaves': 3}. Best is trial 8 with value: 0.021676607732049248.\u001b[0m\n",
      "num_leaves, val_score: 0.021677:  15%|#######5                                          | 3/20 [00:01<00:04,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000567 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.192896\tTest's rmse: 0.0403581\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.021677:  20%|##########                                        | 4/20 [00:02<00:09,  1.77it/s]\u001b[32m[I 2021-12-27 16:21:32,359]\u001b[0m Trial 10 finished with value: 0.022148789220955988 and parameters: {'num_leaves': 195}. Best is trial 8 with value: 0.021676607732049248.\u001b[0m\n",
      "num_leaves, val_score: 0.021677:  20%|##########                                        | 4/20 [00:02<00:09,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\tTrain's rmse: 0.165305\tTest's rmse: 0.0221488\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002348 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.021677:  25%|############5                                     | 5/20 [00:03<00:12,  1.17it/s]\u001b[32m[I 2021-12-27 16:21:33,726]\u001b[0m Trial 11 finished with value: 0.022159568760522143 and parameters: {'num_leaves': 253}. Best is trial 8 with value: 0.021676607732049248.\u001b[0m\n",
      "num_leaves, val_score: 0.021677:  25%|############5                                     | 5/20 [00:03<00:12,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\tTrain's rmse: 0.165303\tTest's rmse: 0.0221596\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002188 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.021677:  30%|###############                                   | 6/20 [00:04<00:11,  1.19it/s]\u001b[32m[I 2021-12-27 16:21:34,546]\u001b[0m Trial 12 finished with value: 0.022146945111498367 and parameters: {'num_leaves': 136}. Best is trial 8 with value: 0.021676607732049248.\u001b[0m\n",
      "num_leaves, val_score: 0.021677:  35%|#################5                                | 7/20 [00:04<00:07,  1.65it/s]\u001b[32m[I 2021-12-27 16:21:34,667]\u001b[0m Trial 13 finished with value: 0.023956176440021636 and parameters: {'num_leaves': 6}. Best is trial 8 with value: 0.021676607732049248.\u001b[0m\n",
      "num_leaves, val_score: 0.021677:  35%|#################5                                | 7/20 [00:04<00:07,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\tTrain's rmse: 0.165307\tTest's rmse: 0.0221469\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002213 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.157789\tTest's rmse: 0.0239562\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001992 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.021677:  40%|####################                              | 8/20 [00:04<00:07,  1.69it/s]\u001b[32m[I 2021-12-27 16:21:35,226]\u001b[0m Trial 14 finished with value: 0.022262803195299333 and parameters: {'num_leaves': 99}. Best is trial 8 with value: 0.021676607732049248.\u001b[0m\n",
      "num_leaves, val_score: 0.021677:  40%|####################                              | 8/20 [00:04<00:07,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[42]\tTrain's rmse: 0.167403\tTest's rmse: 0.0222628\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000661 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.021677:  45%|######################5                           | 9/20 [00:05<00:06,  1.60it/s]\u001b[32m[I 2021-12-27 16:21:35,927]\u001b[0m Trial 15 finished with value: 0.021974852540338083 and parameters: {'num_leaves': 123}. Best is trial 8 with value: 0.021676607732049248.\u001b[0m\n",
      "num_leaves, val_score: 0.021677:  45%|######################5                           | 9/20 [00:05<00:06,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\tTrain's rmse: 0.165361\tTest's rmse: 0.0219749\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.021605:  50%|########################5                        | 10/20 [00:05<00:05,  1.83it/s]\u001b[32m[I 2021-12-27 16:21:36,296]\u001b[0m Trial 16 finished with value: 0.02160486112831631 and parameters: {'num_leaves': 53}. Best is trial 16 with value: 0.02160486112831631.\u001b[0m\n",
      "num_leaves, val_score: 0.021605:  50%|########################5                        | 10/20 [00:05<00:05,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[43]\tTrain's rmse: 0.165782\tTest's rmse: 0.0216049\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000554 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.021605:  55%|##########################9                      | 11/20 [00:06<00:04,  1.94it/s]\u001b[32m[I 2021-12-27 16:21:36,738]\u001b[0m Trial 17 finished with value: 0.030337564041551766 and parameters: {'num_leaves': 63}. Best is trial 16 with value: 0.02160486112831631.\u001b[0m\n",
      "num_leaves, val_score: 0.021605:  55%|##########################9                      | 11/20 [00:06<00:04,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.147646\tTest's rmse: 0.0303376\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000568 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.021178:  60%|#############################4                   | 12/20 [00:06<00:03,  2.14it/s]\u001b[32m[I 2021-12-27 16:21:37,102]\u001b[0m Trial 18 finished with value: 0.02117833974609108 and parameters: {'num_leaves': 45}. Best is trial 18 with value: 0.02117833974609108.\u001b[0m\n",
      "num_leaves, val_score: 0.021178:  60%|#############################4                   | 12/20 [00:06<00:03,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[49]\tTrain's rmse: 0.164443\tTest's rmse: 0.0211783\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000696 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.021178:  65%|###############################8                 | 13/20 [00:07<00:03,  2.20it/s]\u001b[32m[I 2021-12-27 16:21:37,523]\u001b[0m Trial 19 finished with value: 0.022505835688598073 and parameters: {'num_leaves': 60}. Best is trial 18 with value: 0.02117833974609108.\u001b[0m\n",
      "num_leaves, val_score: 0.021178:  65%|###############################8                 | 13/20 [00:07<00:03,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[49]\tTrain's rmse: 0.161886\tTest's rmse: 0.0225058\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001766 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.021178:  70%|##################################3              | 14/20 [00:07<00:02,  2.28it/s]\u001b[32m[I 2021-12-27 16:21:37,924]\u001b[0m Trial 20 finished with value: 0.021604895430245474 and parameters: {'num_leaves': 52}. Best is trial 18 with value: 0.02117833974609108.\u001b[0m\n",
      "num_leaves, val_score: 0.021178:  70%|##################################3              | 14/20 [00:07<00:02,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[43]\tTrain's rmse: 0.165788\tTest's rmse: 0.0216049\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001973 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.021178:  75%|####################################7            | 15/20 [00:08<00:02,  2.18it/s]\u001b[32m[I 2021-12-27 16:21:38,432]\u001b[0m Trial 21 finished with value: 0.021917786418386778 and parameters: {'num_leaves': 80}. Best is trial 18 with value: 0.02117833974609108.\u001b[0m\n",
      "num_leaves, val_score: 0.021178:  75%|####################################7            | 15/20 [00:08<00:02,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\tTrain's rmse: 0.165386\tTest's rmse: 0.0219178\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000730 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.021178:  80%|#######################################2         | 16/20 [00:08<00:02,  1.76it/s]\u001b[32m[I 2021-12-27 16:21:39,249]\u001b[0m Trial 22 finished with value: 0.02212966392452899 and parameters: {'num_leaves': 153}. Best is trial 18 with value: 0.02117833974609108.\u001b[0m\n",
      "num_leaves, val_score: 0.021178:  80%|#######################################2         | 16/20 [00:08<00:02,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[47]\tTrain's rmse: 0.16481\tTest's rmse: 0.0221297\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000546 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.021178:  85%|#########################################6       | 17/20 [00:09<00:01,  2.01it/s]\u001b[32m[I 2021-12-27 16:21:39,587]\u001b[0m Trial 23 finished with value: 0.021769474951035057 and parameters: {'num_leaves': 34}. Best is trial 18 with value: 0.02117833974609108.\u001b[0m\n",
      "num_leaves, val_score: 0.021178:  85%|#########################################6       | 17/20 [00:09<00:01,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[43]\tTrain's rmse: 0.166059\tTest's rmse: 0.0217695\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000617 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.021178:  90%|############################################1    | 18/20 [00:10<00:01,  1.73it/s]\u001b[32m[I 2021-12-27 16:21:40,354]\u001b[0m Trial 24 finished with value: 0.022072227839772595 and parameters: {'num_leaves': 163}. Best is trial 18 with value: 0.02117833974609108.\u001b[0m\n",
      "num_leaves, val_score: 0.021178:  90%|############################################1    | 18/20 [00:10<00:01,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[47]\tTrain's rmse: 0.164186\tTest's rmse: 0.0220722\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001414 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.021178:  95%|##############################################5  | 19/20 [00:10<00:00,  2.09it/s]\u001b[32m[I 2021-12-27 16:21:40,598]\u001b[0m Trial 25 finished with value: 0.022010538567510264 and parameters: {'num_leaves': 32}. Best is trial 18 with value: 0.02117833974609108.\u001b[0m\n",
      "num_leaves, val_score: 0.021178:  95%|##############################################5  | 19/20 [00:10<00:00,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[48]\tTrain's rmse: 0.165566\tTest's rmse: 0.0220105\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.021178: 100%|#################################################| 20/20 [00:10<00:00,  2.11it/s]\u001b[32m[I 2021-12-27 16:21:41,063]\u001b[0m Trial 26 finished with value: 0.021883500715414308 and parameters: {'num_leaves': 89}. Best is trial 18 with value: 0.02117833974609108.\u001b[0m\n",
      "num_leaves, val_score: 0.021178: 100%|#################################################| 20/20 [00:10<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[42]\tTrain's rmse: 0.167427\tTest's rmse: 0.0218835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.021178:   0%|                                                             | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001930 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.021178:  10%|#####3                                               | 1/10 [00:00<00:03,  2.88it/s]\u001b[32m[I 2021-12-27 16:21:41,430]\u001b[0m Trial 27 finished with value: 0.026632371194522345 and parameters: {'bagging_fraction': 0.7133671551021523, 'bagging_freq': 3}. Best is trial 27 with value: 0.026632371194522345.\u001b[0m\n",
      "bagging, val_score: 0.021178:  10%|#####3                                               | 1/10 [00:00<00:03,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[90]\tTrain's rmse: 0.173757\tTest's rmse: 0.0266324\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.021178:  20%|##########6                                          | 2/10 [00:00<00:02,  3.17it/s]\u001b[32m[I 2021-12-27 16:21:41,720]\u001b[0m Trial 28 finished with value: 0.027432629594961868 and parameters: {'bagging_fraction': 0.7144437554942662, 'bagging_freq': 4}. Best is trial 27 with value: 0.026632371194522345.\u001b[0m\n",
      "bagging, val_score: 0.021178:  20%|##########6                                          | 2/10 [00:00<00:02,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.168857\tTest's rmse: 0.0274326\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.021178:  30%|###############9                                     | 3/10 [00:00<00:02,  3.24it/s]\u001b[32m[I 2021-12-27 16:21:42,024]\u001b[0m Trial 29 finished with value: 0.0363240229184634 and parameters: {'bagging_fraction': 0.6163506401081773, 'bagging_freq': 7}. Best is trial 27 with value: 0.026632371194522345.\u001b[0m\n",
      "bagging, val_score: 0.021178:  30%|###############9                                     | 3/10 [00:00<00:02,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[93]\tTrain's rmse: 0.184001\tTest's rmse: 0.036324\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000544 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.021178:  40%|#####################2                               | 4/10 [00:01<00:01,  3.14it/s]\u001b[32m[I 2021-12-27 16:21:42,356]\u001b[0m Trial 30 finished with value: 0.03284128973631966 and parameters: {'bagging_fraction': 0.43114874517359963, 'bagging_freq': 4}. Best is trial 27 with value: 0.026632371194522345.\u001b[0m\n",
      "bagging, val_score: 0.021178:  40%|#####################2                               | 4/10 [00:01<00:01,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[48]\tTrain's rmse: 0.199006\tTest's rmse: 0.0328413\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000620 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.021178:  50%|##########################5                          | 5/10 [00:01<00:01,  3.16it/s]\u001b[32m[I 2021-12-27 16:21:42,669]\u001b[0m Trial 31 finished with value: 0.027774157563120593 and parameters: {'bagging_fraction': 0.9137798211502581, 'bagging_freq': 7}. Best is trial 27 with value: 0.026632371194522345.\u001b[0m\n",
      "bagging, val_score: 0.021178:  50%|##########################5                          | 5/10 [00:01<00:01,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.161506\tTest's rmse: 0.0277742\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000435 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.021178:  60%|###############################8                     | 6/10 [00:01<00:01,  3.03it/s]\u001b[32m[I 2021-12-27 16:21:43,026]\u001b[0m Trial 32 finished with value: 0.03133010466430888 and parameters: {'bagging_fraction': 0.9778476112521366, 'bagging_freq': 4}. Best is trial 27 with value: 0.026632371194522345.\u001b[0m\n",
      "bagging, val_score: 0.021178:  60%|###############################8                     | 6/10 [00:01<00:01,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.149834\tTest's rmse: 0.0313301\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000435 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.021178:  70%|#####################################                | 7/10 [00:02<00:01,  3.00it/s]\u001b[32m[I 2021-12-27 16:21:43,370]\u001b[0m Trial 33 finished with value: 0.031153529044483153 and parameters: {'bagging_fraction': 0.7581835005752393, 'bagging_freq': 5}. Best is trial 27 with value: 0.026632371194522345.\u001b[0m\n",
      "bagging, val_score: 0.021178:  70%|#####################################                | 7/10 [00:02<00:01,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.165287\tTest's rmse: 0.0311535\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000594 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.021178:  80%|##########################################4          | 8/10 [00:02<00:00,  3.06it/s]\u001b[32m[I 2021-12-27 16:21:43,680]\u001b[0m Trial 34 finished with value: 0.022793800528586875 and parameters: {'bagging_fraction': 0.964136058117807, 'bagging_freq': 5}. Best is trial 34 with value: 0.022793800528586875.\u001b[0m\n",
      "bagging, val_score: 0.021178:  80%|##########################################4          | 8/10 [00:02<00:00,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\tTrain's rmse: 0.165867\tTest's rmse: 0.0227938\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001848 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.021178:  90%|###############################################7     | 9/10 [00:02<00:00,  3.14it/s]\u001b[32m[I 2021-12-27 16:21:43,977]\u001b[0m Trial 35 finished with value: 0.03181378042693511 and parameters: {'bagging_fraction': 0.43642335561341283, 'bagging_freq': 4}. Best is trial 34 with value: 0.022793800528586875.\u001b[0m\n",
      "bagging, val_score: 0.021178:  90%|###############################################7     | 9/10 [00:02<00:00,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[44]\tTrain's rmse: 0.202208\tTest's rmse: 0.0318138\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000447 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.021178: 100%|####################################################| 10/10 [00:03<00:00,  3.19it/s]\u001b[32m[I 2021-12-27 16:21:44,280]\u001b[0m Trial 36 finished with value: 0.03391710849174656 and parameters: {'bagging_fraction': 0.7378747549988215, 'bagging_freq': 7}. Best is trial 34 with value: 0.022793800528586875.\u001b[0m\n",
      "bagging, val_score: 0.021178: 100%|####################################################| 10/10 [00:03<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.17061\tTest's rmse: 0.0339171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.021178:   0%|                                              | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000445 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.021178:  33%|############6                         | 1/3 [00:00<00:00,  3.35it/s]\u001b[32m[I 2021-12-27 16:21:44,594]\u001b[0m Trial 37 finished with value: 0.04663285452107976 and parameters: {'feature_fraction': 0.92}. Best is trial 37 with value: 0.04663285452107976.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.021178:  33%|############6                         | 1/3 [00:00<00:00,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.147733\tTest's rmse: 0.0466329\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000437 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.021178:  67%|#########################3            | 2/3 [00:00<00:00,  3.24it/s]\u001b[32m[I 2021-12-27 16:21:44,897]\u001b[0m Trial 38 finished with value: 0.02117833974609108 and parameters: {'feature_fraction': 0.9840000000000001}. Best is trial 38 with value: 0.02117833974609108.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.021178:  67%|#########################3            | 2/3 [00:00<00:00,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[49]\tTrain's rmse: 0.164443\tTest's rmse: 0.0211783\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000456 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.021178: 100%|######################################| 3/3 [00:00<00:00,  3.09it/s]\u001b[32m[I 2021-12-27 16:21:45,237]\u001b[0m Trial 39 finished with value: 0.04675301105384073 and parameters: {'feature_fraction': 0.9520000000000001}. Best is trial 38 with value: 0.02117833974609108.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.021178: 100%|######################################| 3/3 [00:00<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.147238\tTest's rmse: 0.046753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.021178:   0%|                                              | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[47]\tTrain's rmse: 0.164016\tTest's rmse: 0.0210054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.021005:   5%|#9                                    | 1/20 [00:00<00:06,  2.85it/s]\u001b[32m[I 2021-12-27 16:21:45,598]\u001b[0m Trial 40 finished with value: 0.021005388263311303 and parameters: {'lambda_l1': 0.08600897814422022, 'lambda_l2': 5.448462597064399e-08}. Best is trial 40 with value: 0.021005388263311303.\u001b[0m\n",
      "regularization_factors, val_score: 0.021005:   5%|#9                                    | 1/20 [00:00<00:06,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000440 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.020732:  10%|###8                                  | 2/20 [00:00<00:06,  2.76it/s]\u001b[32m[I 2021-12-27 16:21:45,969]\u001b[0m Trial 41 finished with value: 0.020731638574737924 and parameters: {'lambda_l1': 2.1863089012122197e-08, 'lambda_l2': 0.06427385401914651}. Best is trial 41 with value: 0.020731638574737924.\u001b[0m\n",
      "regularization_factors, val_score: 0.020732:  10%|###8                                  | 2/20 [00:00<00:06,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[47]\tTrain's rmse: 0.163892\tTest's rmse: 0.0207316\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000694 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.020732:  15%|#####7                                | 3/20 [00:00<00:05,  3.37it/s]\u001b[32m[I 2021-12-27 16:21:46,188]\u001b[0m Trial 42 finished with value: 0.030548414267267173 and parameters: {'lambda_l1': 5.907339791406612, 'lambda_l2': 0.08826024016501374}. Best is trial 41 with value: 0.020731638574737924.\u001b[0m\n",
      "regularization_factors, val_score: 0.020732:  15%|#####7                                | 3/20 [00:00<00:05,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.142858\tTest's rmse: 0.0305484\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[45]\tTrain's rmse: 0.168158\tTest's rmse: 0.0203061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.020306:  20%|#######6                              | 4/20 [00:01<00:05,  3.17it/s]\u001b[32m[I 2021-12-27 16:21:46,533]\u001b[0m Trial 43 finished with value: 0.020306125086250203 and parameters: {'lambda_l1': 0.12740189362447799, 'lambda_l2': 1.0436997979331249e-05}. Best is trial 43 with value: 0.020306125086250203.\u001b[0m\n",
      "regularization_factors, val_score: 0.020306:  20%|#######6                              | 4/20 [00:01<00:05,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000512 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.020306:  25%|#########5                            | 5/20 [00:01<00:04,  3.55it/s]\u001b[32m[I 2021-12-27 16:21:46,751]\u001b[0m Trial 44 finished with value: 0.025291071460064724 and parameters: {'lambda_l1': 2.14704488638682, 'lambda_l2': 0.009673882012053188}. Best is trial 43 with value: 0.020306125086250203.\u001b[0m\n",
      "regularization_factors, val_score: 0.020306:  25%|#########5                            | 5/20 [00:01<00:04,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.143616\tTest's rmse: 0.0252911\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000605 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.020306:  30%|###########4                          | 6/20 [00:01<00:04,  3.18it/s]\u001b[32m[I 2021-12-27 16:21:47,130]\u001b[0m Trial 45 finished with value: 0.021178339790915567 and parameters: {'lambda_l1': 2.365357136876506e-08, 'lambda_l2': 1.5594417423742848e-08}. Best is trial 43 with value: 0.020306125086250203.\u001b[0m\n",
      "regularization_factors, val_score: 0.020306:  30%|###########4                          | 6/20 [00:01<00:04,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[49]\tTrain's rmse: 0.164443\tTest's rmse: 0.0211783\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.020306:  35%|#############3                        | 7/20 [00:02<00:04,  3.07it/s]\u001b[32m[I 2021-12-27 16:21:47,478]\u001b[0m Trial 46 finished with value: 0.020969738686387043 and parameters: {'lambda_l1': 0.002091076252852904, 'lambda_l2': 0.20389619684060037}. Best is trial 43 with value: 0.020306125086250203.\u001b[0m\n",
      "regularization_factors, val_score: 0.020306:  35%|#############3                        | 7/20 [00:02<00:04,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[48]\tTrain's rmse: 0.165645\tTest's rmse: 0.0209697\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001863 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.020306:  40%|###############2                      | 8/20 [00:02<00:04,  2.99it/s]\u001b[32m[I 2021-12-27 16:21:47,834]\u001b[0m Trial 47 finished with value: 0.021466966953886283 and parameters: {'lambda_l1': 5.0213373445897034e-08, 'lambda_l2': 0.007088327110937651}. Best is trial 43 with value: 0.020306125086250203.\u001b[0m\n",
      "regularization_factors, val_score: 0.020306:  40%|###############2                      | 8/20 [00:02<00:04,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[47]\tTrain's rmse: 0.164104\tTest's rmse: 0.021467\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000447 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.020306:  45%|#################1                    | 9/20 [00:02<00:03,  2.94it/s]\u001b[32m[I 2021-12-27 16:21:48,186]\u001b[0m Trial 48 finished with value: 0.02130644637822368 and parameters: {'lambda_l1': 0.00028814629673231724, 'lambda_l2': 0.2678424104611399}. Best is trial 43 with value: 0.020306125086250203.\u001b[0m\n",
      "regularization_factors, val_score: 0.020306:  45%|#################1                    | 9/20 [00:02<00:03,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[44]\tTrain's rmse: 0.165306\tTest's rmse: 0.0213064\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000498 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.020306:  50%|##################5                  | 10/20 [00:03<00:03,  3.02it/s]\u001b[32m[I 2021-12-27 16:21:48,496]\u001b[0m Trial 49 finished with value: 0.021087263132799752 and parameters: {'lambda_l1': 0.09285739500888668, 'lambda_l2': 0.0001388910208641189}. Best is trial 43 with value: 0.020306125086250203.\u001b[0m\n",
      "regularization_factors, val_score: 0.020306:  50%|##################5                  | 10/20 [00:03<00:03,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[46]\tTrain's rmse: 0.165888\tTest's rmse: 0.0210873\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000443 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.020306:  55%|####################3                | 11/20 [00:03<00:03,  2.92it/s]\u001b[32m[I 2021-12-27 16:21:48,878]\u001b[0m Trial 50 finished with value: 0.02117834526746708 and parameters: {'lambda_l1': 1.7955407008632113e-05, 'lambda_l2': 4.5696887000708185e-06}. Best is trial 43 with value: 0.020306125086250203.\u001b[0m\n",
      "regularization_factors, val_score: 0.020306:  55%|####################3                | 11/20 [00:03<00:03,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[49]\tTrain's rmse: 0.164443\tTest's rmse: 0.0211783\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.020306:  60%|######################2              | 12/20 [00:03<00:02,  3.00it/s]\u001b[32m[I 2021-12-27 16:21:49,177]\u001b[0m Trial 51 finished with value: 0.02519297862350493 and parameters: {'lambda_l1': 1.2022180598917155e-06, 'lambda_l2': 9.342367229182084}. Best is trial 43 with value: 0.020306125086250203.\u001b[0m\n",
      "regularization_factors, val_score: 0.020306:  60%|######################2              | 12/20 [00:03<00:02,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.15905\tTest's rmse: 0.025193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.020306:  65%|########################             | 13/20 [00:04<00:02,  3.07it/s]\u001b[32m[I 2021-12-27 16:21:49,498]\u001b[0m Trial 52 finished with value: 0.02051367163966543 and parameters: {'lambda_l1': 0.0031951028183427525, 'lambda_l2': 6.616149749230744e-06}. Best is trial 43 with value: 0.020306125086250203.\u001b[0m\n",
      "regularization_factors, val_score: 0.020306:  65%|########################             | 13/20 [00:04<00:02,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[44]\tTrain's rmse: 0.166032\tTest's rmse: 0.0205137\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000440 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.020306:  70%|#########################9           | 14/20 [00:04<00:02,  2.97it/s]\u001b[32m[I 2021-12-27 16:21:49,849]\u001b[0m Trial 53 finished with value: 0.021036118495999293 and parameters: {'lambda_l1': 0.01591747291047537, 'lambda_l2': 4.8880464645283e-06}. Best is trial 43 with value: 0.020306125086250203.\u001b[0m\n",
      "regularization_factors, val_score: 0.020306:  70%|#########################9           | 14/20 [00:04<00:02,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[48]\tTrain's rmse: 0.163262\tTest's rmse: 0.0210361\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.020306:  75%|###########################7         | 15/20 [00:04<00:01,  2.93it/s]\u001b[32m[I 2021-12-27 16:21:50,200]\u001b[0m Trial 54 finished with value: 0.02160561606384025 and parameters: {'lambda_l1': 0.00029413095990262427, 'lambda_l2': 4.373561316782247e-06}. Best is trial 43 with value: 0.020306125086250203.\u001b[0m\n",
      "regularization_factors, val_score: 0.020306:  75%|###########################7         | 15/20 [00:04<00:01,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[43]\tTrain's rmse: 0.165782\tTest's rmse: 0.0216056\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000532 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.020306:  80%|#############################6       | 16/20 [00:05<00:01,  3.04it/s]\u001b[32m[I 2021-12-27 16:21:50,500]\u001b[0m Trial 55 finished with value: 0.020588868764409865 and parameters: {'lambda_l1': 0.3112001117427718, 'lambda_l2': 0.00011622350283607832}. Best is trial 43 with value: 0.020306125086250203.\u001b[0m\n",
      "regularization_factors, val_score: 0.020306:  80%|#############################6       | 16/20 [00:05<00:01,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[44]\tTrain's rmse: 0.16429\tTest's rmse: 0.0205889\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000432 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.020306:  85%|###############################4     | 17/20 [00:05<00:00,  3.03it/s]\u001b[32m[I 2021-12-27 16:21:50,831]\u001b[0m Trial 56 finished with value: 0.021379002939547878 and parameters: {'lambda_l1': 0.004218263990031276, 'lambda_l2': 4.123994460114885e-07}. Best is trial 43 with value: 0.020306125086250203.\u001b[0m\n",
      "regularization_factors, val_score: 0.020306:  85%|###############################4     | 17/20 [00:05<00:00,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[44]\tTrain's rmse: 0.166252\tTest's rmse: 0.021379\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.020306:  90%|#################################3   | 18/20 [00:05<00:00,  2.92it/s]\u001b[32m[I 2021-12-27 16:21:51,203]\u001b[0m Trial 57 finished with value: 0.021178344516033266 and parameters: {'lambda_l1': 2.6076674932490528e-05, 'lambda_l2': 3.782992917398345e-05}. Best is trial 43 with value: 0.020306125086250203.\u001b[0m\n",
      "regularization_factors, val_score: 0.020306:  90%|#################################3   | 18/20 [00:05<00:00,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[49]\tTrain's rmse: 0.164443\tTest's rmse: 0.0211783\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000497 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.020306:  95%|###################################1 | 19/20 [00:06<00:00,  3.20it/s]\u001b[32m[I 2021-12-27 16:21:51,448]\u001b[0m Trial 58 finished with value: 0.026375256317014602 and parameters: {'lambda_l1': 1.0960708951047389, 'lambda_l2': 4.674488272247537e-07}. Best is trial 43 with value: 0.020306125086250203.\u001b[0m\n",
      "regularization_factors, val_score: 0.020306:  95%|###################################1 | 19/20 [00:06<00:00,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.142039\tTest's rmse: 0.0263753\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001481 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.020306: 100%|#####################################| 20/20 [00:06<00:00,  3.09it/s]\u001b[32m[I 2021-12-27 16:21:51,797]\u001b[0m Trial 59 finished with value: 0.02089500304326861 and parameters: {'lambda_l1': 0.010233721324676323, 'lambda_l2': 0.0008148649002002555}. Best is trial 43 with value: 0.020306125086250203.\u001b[0m\n",
      "regularization_factors, val_score: 0.020306: 100%|#####################################| 20/20 [00:06<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[47]\tTrain's rmse: 0.164913\tTest's rmse: 0.020895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.020306:   0%|                                                     | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.020306:  20%|#########                                    | 1/5 [00:00<00:01,  3.03it/s]\u001b[32m[I 2021-12-27 16:21:52,132]\u001b[0m Trial 60 finished with value: 0.025217702261935242 and parameters: {'min_child_samples': 10}. Best is trial 60 with value: 0.025217702261935242.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.020306:  20%|#########                                    | 1/5 [00:00<00:01,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[40]\tTrain's rmse: 0.113838\tTest's rmse: 0.0252177\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000446 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.020306:  40%|##################                           | 2/5 [00:00<00:00,  3.38it/s]\u001b[32m[I 2021-12-27 16:21:52,407]\u001b[0m Trial 61 finished with value: 0.05575813837057872 and parameters: {'min_child_samples': 50}. Best is trial 60 with value: 0.025217702261935242.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.020306:  40%|##################                           | 2/5 [00:00<00:00,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[38]\tTrain's rmse: 0.255992\tTest's rmse: 0.0557581\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.020306:  60%|###########################                  | 3/5 [00:00<00:00,  4.02it/s]\u001b[32m[I 2021-12-27 16:21:52,598]\u001b[0m Trial 62 finished with value: 0.08973595584447372 and parameters: {'min_child_samples': 100}. Best is trial 60 with value: 0.025217702261935242.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.020306:  60%|###########################                  | 3/5 [00:00<00:00,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[29]\tTrain's rmse: 0.31873\tTest's rmse: 0.089736\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000558 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.0159168\tTest's rmse: 0.0313739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.020306:  80%|####################################         | 4/5 [00:01<00:00,  3.70it/s]\u001b[32m[I 2021-12-27 16:21:52,902]\u001b[0m Trial 63 finished with value: 0.031373886649840844 and parameters: {'min_child_samples': 5}. Best is trial 60 with value: 0.025217702261935242.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.020306:  80%|####################################         | 4/5 [00:01<00:00,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000506 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.020306: 100%|#############################################| 5/5 [00:01<00:00,  3.58it/s]\u001b[32m[I 2021-12-27 16:21:53,198]\u001b[0m Trial 64 finished with value: 0.027143891411677692 and parameters: {'min_child_samples': 25}. Best is trial 60 with value: 0.025217702261935242.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.020306: 100%|#############################################| 5/5 [00:01<00:00,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[49]\tTrain's rmse: 0.1743\tTest's rmse: 0.0271439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:21:53,380]\u001b[0m A new study created in memory with name: no-name-0fb0f0ab-8801-40f6-917f-7069ae343397\u001b[0m\n",
      "feature_fraction, val_score: inf:   0%|                                                          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\tTrain's rmse: 0.154665\tTest's rmse: 0.391274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.391274:  14%|######4                                      | 1/7 [00:00<00:01,  4.67it/s]\u001b[32m[I 2021-12-27 16:21:53,600]\u001b[0m Trial 0 finished with value: 0.3912741168845798 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 0.3912741168845798.\u001b[0m\n",
      "feature_fraction, val_score: 0.373033:  29%|############8                                | 2/7 [00:00<00:01,  4.86it/s]\u001b[32m[I 2021-12-27 16:21:53,798]\u001b[0m Trial 1 finished with value: 0.3730328037776354 and parameters: {'feature_fraction': 1.0}. Best is trial 1 with value: 0.3730328037776354.\u001b[0m\n",
      "feature_fraction, val_score: 0.373033:  29%|############8                                | 2/7 [00:00<00:01,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000599 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\tTrain's rmse: 0.15906\tTest's rmse: 0.373033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.373033:  43%|###################2                         | 3/7 [00:00<00:00,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.121956\tTest's rmse: 0.418672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:21:54,031]\u001b[0m Trial 2 finished with value: 0.41867181945067966 and parameters: {'feature_fraction': 0.5}. Best is trial 1 with value: 0.3730328037776354.\u001b[0m\n",
      "feature_fraction, val_score: 0.373033:  43%|###################2                         | 3/7 [00:00<00:00,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001391 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.121667\tTest's rmse: 0.411929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.373033:  57%|#########################7                   | 4/7 [00:00<00:00,  4.49it/s]\u001b[32m[I 2021-12-27 16:21:54,256]\u001b[0m Trial 3 finished with value: 0.41192885012396424 and parameters: {'feature_fraction': 0.6}. Best is trial 1 with value: 0.3730328037776354.\u001b[0m\n",
      "feature_fraction, val_score: 0.373033:  57%|#########################7                   | 4/7 [00:00<00:00,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001922 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.373033:  71%|################################1            | 5/7 [00:01<00:00,  4.37it/s]\u001b[32m[I 2021-12-27 16:21:54,511]\u001b[0m Trial 4 finished with value: 0.4177141650444445 and parameters: {'feature_fraction': 0.7}. Best is trial 1 with value: 0.3730328037776354.\u001b[0m\n",
      "feature_fraction, val_score: 0.373033:  71%|################################1            | 5/7 [00:01<00:00,  4.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.122753\tTest's rmse: 0.417714\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.373033:  86%|######################################5      | 6/7 [00:01<00:00,  4.18it/s]\u001b[32m[I 2021-12-27 16:21:54,759]\u001b[0m Trial 5 finished with value: 0.3786815048787219 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 1 with value: 0.3730328037776354.\u001b[0m\n",
      "feature_fraction, val_score: 0.373033:  86%|######################################5      | 6/7 [00:01<00:00,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[37]\tTrain's rmse: 0.15737\tTest's rmse: 0.378682\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000736 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.373033: 100%|#############################################| 7/7 [00:01<00:00,  3.18it/s]\u001b[32m[I 2021-12-27 16:21:55,228]\u001b[0m Trial 6 finished with value: 0.4174154758767119 and parameters: {'feature_fraction': 0.4}. Best is trial 1 with value: 0.3730328037776354.\u001b[0m\n",
      "feature_fraction, val_score: 0.373033: 100%|#############################################| 7/7 [00:01<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.120118\tTest's rmse: 0.417415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.373033:   0%|                                                          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003819 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.373033:   5%|##5                                               | 1/20 [00:01<00:19,  1.02s/it]\u001b[32m[I 2021-12-27 16:21:56,253]\u001b[0m Trial 7 finished with value: 0.37576799754743406 and parameters: {'num_leaves': 212}. Best is trial 7 with value: 0.37576799754743406.\u001b[0m\n",
      "num_leaves, val_score: 0.373033:   5%|##5                                               | 1/20 [00:01<00:19,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[39]\tTrain's rmse: 0.153026\tTest's rmse: 0.375768\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.373033:  10%|#####                                             | 2/20 [00:01<00:17,  1.01it/s]\u001b[32m[I 2021-12-27 16:21:57,222]\u001b[0m Trial 8 finished with value: 0.3757680509645226 and parameters: {'num_leaves': 252}. Best is trial 7 with value: 0.37576799754743406.\u001b[0m\n",
      "num_leaves, val_score: 0.373033:  10%|#####                                             | 2/20 [00:01<00:17,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[39]\tTrain's rmse: 0.153025\tTest's rmse: 0.375768\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000567 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.373033:  15%|#######5                                          | 3/20 [00:02<00:16,  1.02it/s]\u001b[32m[I 2021-12-27 16:21:58,186]\u001b[0m Trial 9 finished with value: 0.37576802599688053 and parameters: {'num_leaves': 211}. Best is trial 7 with value: 0.37576799754743406.\u001b[0m\n",
      "num_leaves, val_score: 0.373033:  15%|#######5                                          | 3/20 [00:02<00:16,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[39]\tTrain's rmse: 0.153026\tTest's rmse: 0.375768\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000847 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.373033:  20%|##########                                        | 4/20 [00:03<00:15,  1.06it/s]\u001b[32m[I 2021-12-27 16:21:59,071]\u001b[0m Trial 10 finished with value: 0.3760640809363393 and parameters: {'num_leaves': 232}. Best is trial 7 with value: 0.37576799754743406.\u001b[0m\n",
      "num_leaves, val_score: 0.373033:  20%|##########                                        | 4/20 [00:03<00:15,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[32]\tTrain's rmse: 0.15918\tTest's rmse: 0.376064\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000589 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.373033:  25%|############5                                     | 5/20 [00:04<00:13,  1.15it/s]\u001b[32m[I 2021-12-27 16:21:59,811]\u001b[0m Trial 11 finished with value: 0.3757671221534982 and parameters: {'num_leaves': 157}. Best is trial 11 with value: 0.3757671221534982.\u001b[0m\n",
      "num_leaves, val_score: 0.373033:  25%|############5                                     | 5/20 [00:04<00:13,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[39]\tTrain's rmse: 0.153027\tTest's rmse: 0.375767\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001800 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.373033:  30%|###############                                   | 6/20 [00:05<00:10,  1.34it/s]\u001b[32m[I 2021-12-27 16:22:00,326]\u001b[0m Trial 12 finished with value: 0.37606536703168325 and parameters: {'num_leaves': 112}. Best is trial 11 with value: 0.3757671221534982.\u001b[0m\n",
      "num_leaves, val_score: 0.373033:  30%|###############                                   | 6/20 [00:05<00:10,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[32]\tTrain's rmse: 0.159186\tTest's rmse: 0.376065\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000641 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.373033:  35%|#################5                                | 7/20 [00:05<00:09,  1.38it/s]\u001b[32m[I 2021-12-27 16:22:01,000]\u001b[0m Trial 13 finished with value: 0.3760705209127 and parameters: {'num_leaves': 160}. Best is trial 11 with value: 0.3757671221534982.\u001b[0m\n",
      "num_leaves, val_score: 0.373033:  35%|#################5                                | 7/20 [00:05<00:09,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[32]\tTrain's rmse: 0.159186\tTest's rmse: 0.376071\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.373033:  40%|####################                              | 8/20 [00:06<00:07,  1.68it/s]\u001b[32m[I 2021-12-27 16:22:01,323]\u001b[0m Trial 14 finished with value: 0.3760988100107242 and parameters: {'num_leaves': 59}. Best is trial 11 with value: 0.3757671221534982.\u001b[0m\n",
      "num_leaves, val_score: 0.373033:  40%|####################                              | 8/20 [00:06<00:07,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[32]\tTrain's rmse: 0.15923\tTest's rmse: 0.376099\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000555 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\tTrain's rmse: 0.159223\tTest's rmse: 0.371918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.371918:  45%|######################5                           | 9/20 [00:06<00:05,  2.13it/s]\u001b[32m[I 2021-12-27 16:22:01,512]\u001b[0m Trial 15 finished with value: 0.3719178612237343 and parameters: {'num_leaves': 29}. Best is trial 15 with value: 0.3719178612237343.\u001b[0m\n",
      "num_leaves, val_score: 0.371918:  45%|######################5                           | 9/20 [00:06<00:05,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.371918:  50%|########################5                        | 10/20 [00:07<00:05,  1.81it/s]\u001b[32m[I 2021-12-27 16:22:02,255]\u001b[0m Trial 16 finished with value: 0.37576796278782715 and parameters: {'num_leaves': 192}. Best is trial 15 with value: 0.3719178612237343.\u001b[0m\n",
      "num_leaves, val_score: 0.371375:  55%|##########################9                      | 11/20 [00:07<00:03,  2.37it/s]\u001b[32m[I 2021-12-27 16:22:02,381]\u001b[0m Trial 17 finished with value: 0.3713748707011561 and parameters: {'num_leaves': 12}. Best is trial 17 with value: 0.3713748707011561.\u001b[0m\n",
      "num_leaves, val_score: 0.371375:  55%|##########################9                      | 11/20 [00:07<00:03,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[39]\tTrain's rmse: 0.153026\tTest's rmse: 0.375768\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000578 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\tTrain's rmse: 0.158799\tTest's rmse: 0.371375\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000459 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.371375:  60%|#############################4                   | 12/20 [00:07<00:02,  2.96it/s]\u001b[32m[I 2021-12-27 16:22:02,539]\u001b[0m Trial 18 finished with value: 0.37210844239304375 and parameters: {'num_leaves': 19}. Best is trial 17 with value: 0.3713748707011561.\u001b[0m\n",
      "num_leaves, val_score: 0.371375:  60%|#############################4                   | 12/20 [00:07<00:02,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\tTrain's rmse: 0.159614\tTest's rmse: 0.372108\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000471 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.354284:  65%|###############################8                 | 13/20 [00:07<00:01,  3.70it/s]\u001b[32m[I 2021-12-27 16:22:02,638]\u001b[0m Trial 19 finished with value: 0.3542835198785773 and parameters: {'num_leaves': 6}. Best is trial 19 with value: 0.3542835198785773.\u001b[0m\n",
      "num_leaves, val_score: 0.354284:  65%|###############################8                 | 13/20 [00:07<00:01,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[40]\tTrain's rmse: 0.155086\tTest's rmse: 0.354284\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000473 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.354284:  70%|##################################3              | 14/20 [00:07<00:01,  3.32it/s]\u001b[32m[I 2021-12-27 16:22:03,013]\u001b[0m Trial 20 finished with value: 0.3760850042073257 and parameters: {'num_leaves': 80}. Best is trial 19 with value: 0.3542835198785773.\u001b[0m\n",
      "num_leaves, val_score: 0.348219:  70%|##################################3              | 14/20 [00:07<00:01,  3.32it/s]\u001b[32m[I 2021-12-27 16:22:03,113]\u001b[0m Trial 21 finished with value: 0.3482186462388829 and parameters: {'num_leaves': 5}. Best is trial 21 with value: 0.3482186462388829.\u001b[0m\n",
      "num_leaves, val_score: 0.348219:  75%|####################################7            | 15/20 [00:07<00:01,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[32]\tTrain's rmse: 0.159203\tTest's rmse: 0.376085\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000530 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\tTrain's rmse: 0.166868\tTest's rmse: 0.348219\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000538 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.348219:  80%|#######################################2         | 16/20 [00:08<00:01,  3.72it/s]\u001b[32m[I 2021-12-27 16:22:03,477]\u001b[0m Trial 22 finished with value: 0.37574967787929525 and parameters: {'num_leaves': 60}. Best is trial 21 with value: 0.3482186462388829.\u001b[0m\n",
      "num_leaves, val_score: 0.348219:  80%|#######################################2         | 16/20 [00:08<00:01,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[39]\tTrain's rmse: 0.153058\tTest's rmse: 0.37575\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001124 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.348219:  85%|#########################################6       | 17/20 [00:08<00:01,  2.77it/s]\u001b[32m[I 2021-12-27 16:22:04,115]\u001b[0m Trial 23 finished with value: 0.37606542493764594 and parameters: {'num_leaves': 104}. Best is trial 21 with value: 0.3482186462388829.\u001b[0m\n",
      "num_leaves, val_score: 0.348219:  85%|#########################################6       | 17/20 [00:08<00:01,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[32]\tTrain's rmse: 0.159187\tTest's rmse: 0.376065\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000666 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.348219:  90%|############################################1    | 18/20 [00:09<00:00,  2.94it/s]\u001b[32m[I 2021-12-27 16:22:04,411]\u001b[0m Trial 24 finished with value: 0.37607655517199734 and parameters: {'num_leaves': 51}. Best is trial 21 with value: 0.3482186462388829.\u001b[0m\n",
      "num_leaves, val_score: 0.348219:  90%|############################################1    | 18/20 [00:09<00:00,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[32]\tTrain's rmse: 0.159209\tTest's rmse: 0.376077\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000454 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.348219:  95%|##############################################5  | 19/20 [00:09<00:00,  3.14it/s]\u001b[32m[I 2021-12-27 16:22:04,660]\u001b[0m Trial 25 finished with value: 0.37614593179128786 and parameters: {'num_leaves': 41}. Best is trial 21 with value: 0.3482186462388829.\u001b[0m\n",
      "num_leaves, val_score: 0.337830:  95%|##############################################5  | 19/20 [00:09<00:00,  3.14it/s]\u001b[32m[I 2021-12-27 16:22:04,756]\u001b[0m Trial 26 finished with value: 0.33782957159900123 and parameters: {'num_leaves': 2}. Best is trial 26 with value: 0.33782957159900123.\u001b[0m\n",
      "num_leaves, val_score: 0.337830: 100%|#################################################| 20/20 [00:09<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[31]\tTrain's rmse: 0.159713\tTest's rmse: 0.376146\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000650 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.196657\tTest's rmse: 0.33783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.337830:   0%|                                                             | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.331660:  10%|#####3                                               | 1/10 [00:00<00:00,  9.09it/s]\u001b[32m[I 2021-12-27 16:22:04,874]\u001b[0m Trial 27 finished with value: 0.33165956008395164 and parameters: {'bagging_fraction': 0.8276741138444597, 'bagging_freq': 1}. Best is trial 27 with value: 0.33165956008395164.\u001b[0m\n",
      "bagging, val_score: 0.331660:  10%|#####3                                               | 1/10 [00:00<00:00,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.196215\tTest's rmse: 0.33166\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001479 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.197474\tTest's rmse: 0.331642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.331642:  20%|##########6                                          | 2/10 [00:00<00:00,  9.04it/s]\u001b[32m[I 2021-12-27 16:22:04,985]\u001b[0m Trial 28 finished with value: 0.33164233746148847 and parameters: {'bagging_fraction': 0.48754864111624796, 'bagging_freq': 1}. Best is trial 28 with value: 0.33164233746148847.\u001b[0m\n",
      "bagging, val_score: 0.331642:  20%|##########6                                          | 2/10 [00:00<00:00,  9.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000584 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.196717\tTest's rmse: 0.337489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.331642:  20%|##########6                                          | 2/10 [00:00<00:00,  9.04it/s]\u001b[32m[I 2021-12-27 16:22:05,074]\u001b[0m Trial 29 finished with value: 0.33748854091815245 and parameters: {'bagging_fraction': 0.7494103695873683, 'bagging_freq': 5}. Best is trial 28 with value: 0.33164233746148847.\u001b[0m\n",
      "bagging, val_score: 0.330351:  40%|#####################2                               | 4/10 [00:00<00:00, 10.30it/s]\u001b[32m[I 2021-12-27 16:22:05,161]\u001b[0m Trial 30 finished with value: 0.3303507570762704 and parameters: {'bagging_fraction': 0.883946404752339, 'bagging_freq': 4}. Best is trial 30 with value: 0.3303507570762704.\u001b[0m\n",
      "bagging, val_score: 0.330351:  40%|#####################2                               | 4/10 [00:00<00:00, 10.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000488 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.19629\tTest's rmse: 0.330351\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001382 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.330351:  40%|#####################2                               | 4/10 [00:00<00:00, 10.30it/s]\u001b[32m[I 2021-12-27 16:22:05,263]\u001b[0m Trial 31 finished with value: 0.33552742518060535 and parameters: {'bagging_fraction': 0.9762589869040033, 'bagging_freq': 6}. Best is trial 30 with value: 0.3303507570762704.\u001b[0m\n",
      "bagging, val_score: 0.330351:  50%|##########################5                          | 5/10 [00:00<00:00, 10.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.196523\tTest's rmse: 0.335527\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001023 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\tTrain's rmse: 0.196505\tTest's rmse: 0.333595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.330351:  60%|###############################8                     | 6/10 [00:00<00:00,  9.30it/s]\u001b[32m[I 2021-12-27 16:22:05,404]\u001b[0m Trial 32 finished with value: 0.3335950012226874 and parameters: {'bagging_fraction': 0.8702924766120824, 'bagging_freq': 3}. Best is trial 30 with value: 0.3303507570762704.\u001b[0m\n",
      "bagging, val_score: 0.330351:  60%|###############################8                     | 6/10 [00:00<00:00,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000638 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.330351:  70%|#####################################                | 7/10 [00:00<00:00,  7.73it/s]\u001b[32m[I 2021-12-27 16:22:05,596]\u001b[0m Trial 33 finished with value: 0.3331084844766479 and parameters: {'bagging_fraction': 0.9259160841825815, 'bagging_freq': 2}. Best is trial 30 with value: 0.3303507570762704.\u001b[0m\n",
      "bagging, val_score: 0.330351:  70%|#####################################                | 7/10 [00:00<00:00,  7.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.196339\tTest's rmse: 0.333108\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001275 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.330351:  80%|##########################################4          | 8/10 [00:00<00:00,  7.79it/s]\u001b[32m[I 2021-12-27 16:22:05,722]\u001b[0m Trial 34 finished with value: 0.3330263539857713 and parameters: {'bagging_fraction': 0.710614482608463, 'bagging_freq': 1}. Best is trial 30 with value: 0.3303507570762704.\u001b[0m\n",
      "bagging, val_score: 0.330351:  80%|##########################################4          | 8/10 [00:00<00:00,  7.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.196337\tTest's rmse: 0.333026\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000756 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.196266\tTest's rmse: 0.334161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.330351:  90%|###############################################7     | 9/10 [00:01<00:00,  7.98it/s]\u001b[32m[I 2021-12-27 16:22:05,839]\u001b[0m Trial 35 finished with value: 0.3341612566442498 and parameters: {'bagging_fraction': 0.9240416852789539, 'bagging_freq': 1}. Best is trial 30 with value: 0.3303507570762704.\u001b[0m\n",
      "bagging, val_score: 0.330351: 100%|####################################################| 10/10 [00:01<00:00,  8.13it/s]\u001b[32m[I 2021-12-27 16:22:05,956]\u001b[0m Trial 36 finished with value: 0.3354403078133615 and parameters: {'bagging_fraction': 0.9559556531239792, 'bagging_freq': 1}. Best is trial 30 with value: 0.3303507570762704.\u001b[0m\n",
      "bagging, val_score: 0.330351: 100%|####################################################| 10/10 [00:01<00:00,  8.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000715 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.196401\tTest's rmse: 0.33544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "feature_fraction_stage2, val_score: 0.330351:   0%|                                              | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001082 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.330351:  33%|############6                         | 1/3 [00:00<00:00,  8.33it/s]\u001b[32m[I 2021-12-27 16:22:06,084]\u001b[0m Trial 37 finished with value: 0.3303507570762704 and parameters: {'feature_fraction': 0.9840000000000001}. Best is trial 37 with value: 0.3303507570762704.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.330351:  33%|############6                         | 1/3 [00:00<00:00,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.19629\tTest's rmse: 0.330351\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001312 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.330351:  67%|#########################3            | 2/3 [00:00<00:00,  7.62it/s]\u001b[32m[I 2021-12-27 16:22:06,223]\u001b[0m Trial 38 finished with value: 0.3310648457868353 and parameters: {'feature_fraction': 0.92}. Best is trial 37 with value: 0.3303507570762704.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.330351:  67%|#########################3            | 2/3 [00:00<00:00,  7.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.196663\tTest's rmse: 0.331065\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000730 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.330351: 100%|######################################| 3/3 [00:00<00:00,  7.87it/s]\u001b[32m[I 2021-12-27 16:22:06,346]\u001b[0m Trial 39 finished with value: 0.3313953643740202 and parameters: {'feature_fraction': 0.9520000000000001}. Best is trial 37 with value: 0.3303507570762704.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.330351: 100%|######################################| 3/3 [00:00<00:00,  7.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.196516\tTest's rmse: 0.331395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.330351:   0%|                                              | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002895 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.330351:   5%|#9                                    | 1/20 [00:00<00:02,  7.19it/s]\u001b[32m[I 2021-12-27 16:22:06,494]\u001b[0m Trial 40 finished with value: 0.3312844514513337 and parameters: {'lambda_l1': 1.2341633495173412e-06, 'lambda_l2': 2.2218675214421006}. Best is trial 40 with value: 0.3312844514513337.\u001b[0m\n",
      "regularization_factors, val_score: 0.330351:   5%|#9                                    | 1/20 [00:00<00:02,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.196476\tTest's rmse: 0.331284\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000463 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.196291\tTest's rmse: 0.330352"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.330351:  10%|###8                                  | 2/20 [00:00<00:02,  8.53it/s]\u001b[32m[I 2021-12-27 16:22:06,596]\u001b[0m Trial 41 finished with value: 0.3303523913028332 and parameters: {'lambda_l1': 0.0018806008512804355, 'lambda_l2': 0.00022790571782412426}. Best is trial 41 with value: 0.3303523913028332.\u001b[0m\n",
      "regularization_factors, val_score: 0.330351:  10%|###8                                  | 2/20 [00:00<00:02,  8.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000540 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.330351:  15%|#####7                                | 3/20 [00:00<00:01,  8.96it/s]\u001b[32m[I 2021-12-27 16:22:06,700]\u001b[0m Trial 42 finished with value: 0.3314344873937436 and parameters: {'lambda_l1': 1.0414042764226965, 'lambda_l2': 0.0002582032475962752}. Best is trial 41 with value: 0.3303523913028332.\u001b[0m\n",
      "regularization_factors, val_score: 0.330351:  15%|#####7                                | 3/20 [00:00<00:01,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.196485\tTest's rmse: 0.331434\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000635 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.197122\tTest's rmse: 0.334701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.330351:  15%|#####7                                | 3/20 [00:00<00:01,  8.96it/s]\u001b[32m[I 2021-12-27 16:22:06,799]\u001b[0m Trial 43 finished with value: 0.3347012502433274 and parameters: {'lambda_l1': 6.076455125001269, 'lambda_l2': 3.5459216065870195e-07}. Best is trial 41 with value: 0.3303523913028332.\u001b[0m\n",
      "regularization_factors, val_score: 0.330351:  20%|#######6                              | 4/20 [00:00<00:01,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000468 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.196433\tTest's rmse: 0.330625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.330351:  25%|#########5                            | 5/20 [00:00<00:01,  9.65it/s]\u001b[32m[I 2021-12-27 16:22:06,895]\u001b[0m Trial 44 finished with value: 0.330624966868934 and parameters: {'lambda_l1': 1.4572343059477145e-06, 'lambda_l2': 0.35100661719222703}. Best is trial 41 with value: 0.3303523913028332.\u001b[0m\n",
      "regularization_factors, val_score: 0.330351:  25%|#########5                            | 5/20 [00:00<00:01,  9.65it/s]\u001b[32m[I 2021-12-27 16:22:06,995]\u001b[0m Trial 45 finished with value: 0.3307405232545072 and parameters: {'lambda_l1': 3.0016272183899507e-06, 'lambda_l2': 0.09610275297096389}. Best is trial 41 with value: 0.3303523913028332.\u001b[0m\n",
      "regularization_factors, val_score: 0.330351:  30%|###########4                          | 6/20 [00:00<00:01,  9.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000494 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.196405\tTest's rmse: 0.330741\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000505 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.330351:  35%|#############3                        | 7/20 [00:00<00:01,  9.96it/s]\u001b[32m[I 2021-12-27 16:22:07,089]\u001b[0m Trial 46 finished with value: 0.33076766044425626 and parameters: {'lambda_l1': 3.26833648534968e-05, 'lambda_l2': 0.1322448790802543}. Best is trial 41 with value: 0.3303523913028332.\u001b[0m\n",
      "regularization_factors, val_score: 0.330351:  35%|#############3                        | 7/20 [00:00<00:01,  9.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.196404\tTest's rmse: 0.330768\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000505 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.330351:  35%|#############3                        | 7/20 [00:00<00:01,  9.96it/s]\u001b[32m[I 2021-12-27 16:22:07,182]\u001b[0m Trial 47 finished with value: 0.33035126706634677 and parameters: {'lambda_l1': 6.454938880380169e-05, 'lambda_l2': 0.0006316745642016862}. Best is trial 47 with value: 0.33035126706634677.\u001b[0m\n",
      "regularization_factors, val_score: 0.330351:  40%|###############2                      | 8/20 [00:00<00:01,  9.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.19629\tTest's rmse: 0.330351\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000588 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.330351:  45%|#################1                    | 9/20 [00:00<00:01, 10.13it/s]\u001b[32m[I 2021-12-27 16:22:07,278]\u001b[0m Trial 48 finished with value: 0.3325296320811784 and parameters: {'lambda_l1': 2.377634022276116, 'lambda_l2': 4.572065480093012e-07}. Best is trial 47 with value: 0.33035126706634677.\u001b[0m\n",
      "regularization_factors, val_score: 0.330351:  45%|#################1                    | 9/20 [00:00<00:01, 10.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.196547\tTest's rmse: 0.33253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.330351:  45%|#################1                    | 9/20 [00:01<00:01, 10.13it/s]\u001b[32m[I 2021-12-27 16:22:07,389]\u001b[0m Trial 49 finished with value: 0.33035213129789354 and parameters: {'lambda_l1': 0.0017597678249971767, 'lambda_l2': 5.8768706102710845e-08}. Best is trial 47 with value: 0.33035126706634677.\u001b[0m\n",
      "regularization_factors, val_score: 0.330351:  50%|##################5                  | 10/20 [00:01<00:00, 10.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.196291\tTest's rmse: 0.330352\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000596 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.19629\tTest's rmse: 0.330351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.330351:  55%|####################3                | 11/20 [00:01<00:00,  9.73it/s]\u001b[32m[I 2021-12-27 16:22:07,501]\u001b[0m Trial 50 finished with value: 0.33035077116330824 and parameters: {'lambda_l1': 1.1739144160952608e-08, 'lambda_l2': 1.9448903850000745e-05}. Best is trial 50 with value: 0.33035077116330824.\u001b[0m\n",
      "regularization_factors, val_score: 0.330351:  55%|####################3                | 11/20 [00:01<00:00,  9.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.19629\tTest's rmse: 0.330351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.330351:  60%|######################2              | 12/20 [00:01<00:00,  9.41it/s]\u001b[32m[I 2021-12-27 16:22:07,621]\u001b[0m Trial 51 finished with value: 0.330350771076837 and parameters: {'lambda_l1': 3.568159544564379e-08, 'lambda_l2': 1.922406873923033e-05}. Best is trial 51 with value: 0.330350771076837.\u001b[0m\n",
      "regularization_factors, val_score: 0.330351:  60%|######################2              | 12/20 [00:01<00:00,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.19629\tTest's rmse: 0.330351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.330351:  65%|########################             | 13/20 [00:01<00:00,  8.98it/s]\u001b[32m[I 2021-12-27 16:22:07,755]\u001b[0m Trial 52 finished with value: 0.3303507639519218 and parameters: {'lambda_l1': 2.2824198922419657e-08, 'lambda_l2': 8.791846283289084e-06}. Best is trial 52 with value: 0.3303507639519218.\u001b[0m\n",
      "regularization_factors, val_score: 0.330351:  65%|########################             | 13/20 [00:01<00:00,  8.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000487 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.19629\tTest's rmse: 0.330351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.330351:  70%|#########################9           | 14/20 [00:01<00:00,  8.79it/s]\u001b[32m[I 2021-12-27 16:22:07,871]\u001b[0m Trial 53 finished with value: 0.33035076296535315 and parameters: {'lambda_l1': 1.2249706398758266e-08, 'lambda_l2': 7.4685444499972105e-06}. Best is trial 53 with value: 0.33035076296535315.\u001b[0m\n",
      "regularization_factors, val_score: 0.330351:  75%|###########################7         | 15/20 [00:01<00:00,  8.81it/s]\u001b[32m[I 2021-12-27 16:22:07,983]\u001b[0m Trial 54 finished with value: 0.3303507613025548 and parameters: {'lambda_l1': 4.8702265607209084e-08, 'lambda_l2': 5.448509545706746e-06}. Best is trial 54 with value: 0.3303507613025548.\u001b[0m\n",
      "regularization_factors, val_score: 0.330351:  75%|###########################7         | 15/20 [00:01<00:00,  8.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000464 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.19629\tTest's rmse: 0.330351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.330351:  80%|#############################6       | 16/20 [00:01<00:00,  8.86it/s]\u001b[32m[I 2021-12-27 16:22:08,095]\u001b[0m Trial 55 finished with value: 0.3303507574034319 and parameters: {'lambda_l1': 2.710978183837125e-07, 'lambda_l2': 1.085617662029721e-08}. Best is trial 55 with value: 0.3303507574034319.\u001b[0m\n",
      "regularization_factors, val_score: 0.330351:  80%|#############################6       | 16/20 [00:01<00:00,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000490 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.19629\tTest's rmse: 0.330351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.330351:  85%|###############################4     | 17/20 [00:01<00:00,  8.95it/s]\u001b[32m[I 2021-12-27 16:22:08,204]\u001b[0m Trial 56 finished with value: 0.3303507574079722 and parameters: {'lambda_l1': 2.61753841724166e-07, 'lambda_l2': 2.1545882972756256e-08}. Best is trial 55 with value: 0.3303507574034319.\u001b[0m\n",
      "regularization_factors, val_score: 0.330351:  85%|###############################4     | 17/20 [00:01<00:00,  8.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000464 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.19629\tTest's rmse: 0.330351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.329948:  90%|#################################3   | 18/20 [00:01<00:00,  9.01it/s]\u001b[32m[I 2021-12-27 16:22:08,312]\u001b[0m Trial 57 finished with value: 0.32994804135152506 and parameters: {'lambda_l1': 0.072850610417757, 'lambda_l2': 1.0400646657716467e-08}. Best is trial 57 with value: 0.32994804135152506.\u001b[0m\n",
      "regularization_factors, val_score: 0.329948:  90%|#################################3   | 18/20 [00:01<00:00,  9.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.196311\tTest's rmse: 0.329948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.329948:  95%|###################################1 | 19/20 [00:02<00:00,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000653 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.196293\tTest's rmse: 0.330393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:08,425]\u001b[0m Trial 58 finished with value: 0.3303934296710763 and parameters: {'lambda_l1': 0.054616509039495706, 'lambda_l2': 1.7369668668336414e-08}. Best is trial 57 with value: 0.32994804135152506.\u001b[0m\n",
      "regularization_factors, val_score: 0.329948: 100%|#####################################| 20/20 [00:02<00:00,  8.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000473 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.196292\tTest's rmse: 0.330373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:08,537]\u001b[0m Trial 59 finished with value: 0.3303727130187044 and parameters: {'lambda_l1': 0.0281085049968261, 'lambda_l2': 3.413273720415162e-07}. Best is trial 57 with value: 0.32994804135152506.\u001b[0m\n",
      "regularization_factors, val_score: 0.329948: 100%|#####################################| 20/20 [00:02<00:00,  9.15it/s]\n",
      "min_data_in_leaf, val_score: 0.329948:   0%|                                                     | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000586 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.196599\tTest's rmse: 0.330269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.329948:  20%|#########                                    | 1/5 [00:00<00:00,  9.52it/s]\u001b[32m[I 2021-12-27 16:22:08,649]\u001b[0m Trial 60 finished with value: 0.3302689331437947 and parameters: {'min_child_samples': 5}. Best is trial 60 with value: 0.3302689331437947.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.329948:  20%|#########                                    | 1/5 [00:00<00:00,  9.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000622 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.196313\tTest's rmse: 0.329944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.329944:  40%|##################                           | 2/5 [00:00<00:00,  8.58it/s]\u001b[32m[I 2021-12-27 16:22:08,775]\u001b[0m Trial 61 finished with value: 0.3299439778591297 and parameters: {'min_child_samples': 25}. Best is trial 61 with value: 0.3299439778591297.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.329944:  40%|##################                           | 2/5 [00:00<00:00,  8.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001507 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.329944:  60%|###########################                  | 3/5 [00:00<00:00,  8.63it/s]\u001b[32m[I 2021-12-27 16:22:08,890]\u001b[0m Trial 62 finished with value: 0.3302689331437947 and parameters: {'min_child_samples': 10}. Best is trial 61 with value: 0.3299439778591297.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.329944:  80%|####################################         | 4/5 [00:00<00:00,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.196599\tTest's rmse: 0.330269\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.265226\tTest's rmse: 0.477702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:08,990]\u001b[0m Trial 63 finished with value: 0.4777019897455321 and parameters: {'min_child_samples': 100}. Best is trial 61 with value: 0.3299439778591297.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.329944:  80%|####################################         | 4/5 [00:00<00:00,  9.09it/s]\u001b[32m[I 2021-12-27 16:22:09,078]\u001b[0m Trial 64 finished with value: 0.42818865016846486 and parameters: {'min_child_samples': 50}. Best is trial 61 with value: 0.3299439778591297.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000475 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.236694\tTest's rmse: 0.428189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.329944: 100%|#############################################| 5/5 [00:00<00:00,  9.33it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: [0.32262792863385437, 0.10144739233251607, 0.13696088206701426, 0.02030612378098113, 0.3299439781659125]\n",
      "RMSE: 0.1822572609960557\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train.reset_index(drop=True)\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "groups = X_train_ce[\"Genre\"]\n",
    "\n",
    "params = {\n",
    "          'task': 'train',              # タスクを訓練に設定\n",
    "          'boosting_type': 'gbdt',      # GBDTを指定\n",
    "          'objective': 'regression',    # 回帰を指定\n",
    "          'metric': 'rmse',             # 回帰の損失（誤差）\n",
    "          'learning_rate': 0.1,         # 学習率\n",
    "          'seed': SEED                   # シード値\n",
    "          }\n",
    "\n",
    "best_params, history = {}, []\n",
    "\n",
    "cv_result_opt = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(gkf.split(X_train_ce, y_train, groups)):\n",
    "    X_train_gkf, X_test_gkf = X_train_ce.iloc[train_index], X_train_ce.iloc[test_index]\n",
    "    y_train_gkf, y_test_gkf = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "    # 学習、推論\n",
    "    lgb_train = opt_lgb.Dataset(X_train_gkf, y_train_gkf)\n",
    "    lgb_test = opt_lgb.Dataset(X_test_gkf, y_test_gkf, reference=lgb_train)\n",
    "\n",
    "    lgb_results = {}                                    # 学習の履歴を入れる入物\n",
    "\n",
    "    model = opt_lgb.train(\n",
    "                    params,                           # ハイパーパラメータをセット\n",
    "                    lgb_train,                        # 訓練データを訓練用にセット\n",
    "                    valid_sets=[lgb_train, lgb_test], # 訓練データとテストデータをセット\n",
    "                    valid_names=['Train', 'Test'],    # データセットの名前をそれぞれ設定\n",
    "                    num_boost_round=100,              # 計算回数\n",
    "                    early_stopping_rounds=50,         # アーリーストッピング設定\n",
    "                    evals_result=lgb_results,\n",
    "                    verbose_eval=-1,                  # ログを最後の1つだけ表示\n",
    "                    )  \n",
    "    \n",
    "    best_params = model.params\n",
    "\n",
    "    # 損失推移を表示\n",
    "    loss_train = lgb_results['Train']['rmse']\n",
    "    loss_test = lgb_results['Test']['rmse']   \n",
    "    \n",
    "    fig = plt.figure()\n",
    "    \n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('logloss')\n",
    "\n",
    "    plt.title(f\"fold:{fold}\")\n",
    "    plt.plot(loss_train, label='train loss')\n",
    "    plt.plot(loss_test, label='test loss')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # 推論\n",
    "    y_pred = model.predict(X_test_gkf, num_iteration=model.best_iteration)\n",
    "\n",
    "    # 評価\n",
    "    rmse = mean_squared_error(y_test_gkf, y_pred, squared=False)\n",
    "    cv_result_opt.append(rmse)\n",
    "\n",
    "print(\"RMSE:\", cv_result_opt)\n",
    "print(\"RMSE:\", np.mean(cv_result_opt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WIhzdczVEHBY"
   },
   "source": [
    "## Optuna によるハイパーパラメーターチューニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Q-MEp1_lEehR"
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    learning_rate = trial.suggest_uniform('learning_rate', 0.1, 1.0)\n",
    "    num_leaves =  trial.suggest_int(\"num_leaves\", 5, 50)\n",
    "    tree_learner = trial.suggest_categorical('tree_learner', [\"serial\", \"feature\", \"data\", \"voting\"])\n",
    "\n",
    "    params = {\n",
    "            'task': 'train',                 # タスクを訓練に設定\n",
    "            'boosting_type': 'gbdt',         # GBDTを指定\n",
    "            'objective': 'regression',       # 回帰を指定\n",
    "            'metric': {'rmse'},              # 回帰の損失（誤差）\n",
    "            'learning_rate': learning_rate,  # 学習率\n",
    "            'num_leaves': num_leaves,\n",
    "            'tree_learner': tree_learner,\n",
    "            'seed': SEED                     # シード値\n",
    "            }\n",
    "\n",
    "    model = lgb.train(\n",
    "                    params=params,                    # ハイパーパラメータをセット\n",
    "                    train_set=lgb_train,              # 訓練データを訓練用にセット\n",
    "                    valid_sets=[lgb_train, lgb_test], # 訓練データとテストデータをセット\n",
    "                    valid_names=['Train', 'Test'],    # データセットの名前をそれぞれ設定\n",
    "                    num_boost_round=100,              # 計算回数\n",
    "                    early_stopping_rounds=50,         # アーリーストッピング設定\n",
    "                    evals_result=lgb_results,\n",
    "                    verbose_eval=-1,                  # ログを最後の1つだけ表示\n",
    "                    )\n",
    "    \n",
    "    # 推論\n",
    "    y_pred = model.predict(X_test_gkf)\n",
    "\n",
    "    # 評価\n",
    "    rmse = mean_squared_error(y_test_gkf, y_pred, squared=False)\n",
    "\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "KRskOyAGEFcR",
    "outputId": "d67bf7f9-ebe3-48d0-a974-c5e9844dfbba"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:09,310]\u001b[0m A new study created in memory with name: no-name-fbb67571-5699-4c7f-a0d2-6c5015b31b89\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000834 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\tTrain's rmse: 0.122538\tTest's rmse: 0.344188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:09,546]\u001b[0m Trial 0 finished with value: 0.34418790326841464 and parameters: {'learning_rate': 0.365861781142683, 'num_leaves': 44, 'tree_learner': 'voting'}. Best is trial 0 with value: 0.34418790326841464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tTrain's rmse: 0.133032\tTest's rmse: 0.338182"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:09,725]\u001b[0m Trial 1 finished with value: 0.33818184482493474 and parameters: {'learning_rate': 0.4855046742983812, 'num_leaves': 38, 'tree_learner': 'serial'}. Best is trial 1 with value: 0.33818184482493474.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001350 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:09,814]\u001b[0m Trial 2 finished with value: 0.3512140056117329 and parameters: {'learning_rate': 0.26336054487817234, 'num_leaves': 17, 'tree_learner': 'feature'}. Best is trial 1 with value: 0.33818184482493474.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:09,872]\u001b[0m Trial 3 finished with value: 0.34622828322185556 and parameters: {'learning_rate': 0.614654134255239, 'num_leaves': 12, 'tree_learner': 'voting'}. Best is trial 1 with value: 0.33818184482493474.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[20]\tTrain's rmse: 0.132593\tTest's rmse: 0.351214\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tTrain's rmse: 0.171533\tTest's rmse: 0.346228\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001406 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tTrain's rmse: 0.136897\tTest's rmse: 0.334714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:10,006]\u001b[0m Trial 4 finished with value: 0.3347136144359734 and parameters: {'learning_rate': 0.49932914557142405, 'num_leaves': 32, 'tree_learner': 'serial'}. Best is trial 4 with value: 0.3347136144359734.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:10,102]\u001b[0m Trial 5 finished with value: 0.34307554506906657 and parameters: {'learning_rate': 0.16532741397772194, 'num_leaves': 9, 'tree_learner': 'voting'}. Best is trial 4 with value: 0.3347136144359734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001663 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tTrain's rmse: 0.145877\tTest's rmse: 0.343076\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tTrain's rmse: 0.15618\tTest's rmse: 0.348169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:10,207]\u001b[0m Trial 6 finished with value: 0.34816920601250556 and parameters: {'learning_rate': 0.5723287218586496, 'num_leaves': 19, 'tree_learner': 'data'}. Best is trial 4 with value: 0.3347136144359734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002022 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:10,464]\u001b[0m Trial 7 finished with value: 0.3459660526627928 and parameters: {'learning_rate': 0.6019213212109507, 'num_leaves': 39, 'tree_learner': 'data'}. Best is trial 4 with value: 0.3347136144359734.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:10,548]\u001b[0m Trial 8 finished with value: 0.34714659122032837 and parameters: {'learning_rate': 0.9592591786684295, 'num_leaves': 18, 'tree_learner': 'serial'}. Best is trial 4 with value: 0.3347136144359734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[3]\tTrain's rmse: 0.169917\tTest's rmse: 0.345966\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tTrain's rmse: 0.175923\tTest's rmse: 0.347147\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001611 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tTrain's rmse: 0.127001\tTest's rmse: 0.338243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:10,640]\u001b[0m Trial 9 finished with value: 0.33824259965497966 and parameters: {'learning_rate': 0.6053081556469473, 'num_leaves': 21, 'tree_learner': 'voting'}. Best is trial 4 with value: 0.3347136144359734.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:10,759]\u001b[0m Trial 10 finished with value: 0.33893494855757356 and parameters: {'learning_rate': 0.8362282173941291, 'num_leaves': 30, 'tree_learner': 'serial'}. Best is trial 4 with value: 0.3347136144359734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tTrain's rmse: 0.120926\tTest's rmse: 0.338935\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000859 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tTrain's rmse: 0.162926\tTest's rmse: 0.345477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:10,873]\u001b[0m Trial 11 finished with value: 0.3454767823275073 and parameters: {'learning_rate': 0.4045091948062055, 'num_leaves': 34, 'tree_learner': 'serial'}. Best is trial 4 with value: 0.3347136144359734.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:11,018]\u001b[0m Trial 12 finished with value: 0.34726390219183406 and parameters: {'learning_rate': 0.4380369352949889, 'num_leaves': 47, 'tree_learner': 'serial'}. Best is trial 4 with value: 0.3347136144359734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000855 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tTrain's rmse: 0.14596\tTest's rmse: 0.347264\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000878 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:11,144]\u001b[0m Trial 13 finished with value: 0.34441070166200366 and parameters: {'learning_rate': 0.7633403581866547, 'num_leaves': 37, 'tree_learner': 'serial'}. Best is trial 4 with value: 0.3347136144359734.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:11,237]\u001b[0m Trial 14 finished with value: 0.34000430820873434 and parameters: {'learning_rate': 0.47285122622798736, 'num_leaves': 27, 'tree_learner': 'feature'}. Best is trial 4 with value: 0.3347136144359734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[2]\tTrain's rmse: 0.170293\tTest's rmse: 0.344411\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000865 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tTrain's rmse: 0.159711\tTest's rmse: 0.340004\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:11,347]\u001b[0m Trial 15 finished with value: 0.34693415531354316 and parameters: {'learning_rate': 0.2630736176640436, 'num_leaves': 27, 'tree_learner': 'serial'}. Best is trial 4 with value: 0.3347136144359734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[16]\tTrain's rmse: 0.148636\tTest's rmse: 0.346934\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tTrain's rmse: 0.175558\tTest's rmse: 0.349063"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:11,537]\u001b[0m Trial 16 finished with value: 0.3490633553847698 and parameters: {'learning_rate': 0.719500958578655, 'num_leaves': 42, 'tree_learner': 'serial'}. Best is trial 4 with value: 0.3347136144359734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:11,972]\u001b[0m Trial 17 finished with value: 0.35332129886101304 and parameters: {'learning_rate': 0.3069840302397053, 'num_leaves': 50, 'tree_learner': 'serial'}. Best is trial 4 with value: 0.3347136144359734.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.103039\tTest's rmse: 0.353321\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tTrain's rmse: 0.134802\tTest's rmse: 0.333611"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:12,126]\u001b[0m Trial 18 finished with value: 0.3336105950939092 and parameters: {'learning_rate': 0.5054189615270691, 'num_leaves': 33, 'tree_learner': 'feature'}. Best is trial 18 with value: 0.3336105950939092.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001584 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:12,373]\u001b[0m Trial 19 finished with value: 0.34313800881853473 and parameters: {'learning_rate': 0.11110493022455153, 'num_leaves': 32, 'tree_learner': 'feature'}. Best is trial 18 with value: 0.3336105950939092.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:12,500]\u001b[0m Trial 20 finished with value: 0.3414396236254616 and parameters: {'learning_rate': 0.7017046513161349, 'num_leaves': 25, 'tree_learner': 'feature'}. Best is trial 18 with value: 0.3336105950939092.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[43]\tTrain's rmse: 0.14352\tTest's rmse: 0.343138\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000913 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tTrain's rmse: 0.163734\tTest's rmse: 0.34144\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001426 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:12,684]\u001b[0m Trial 21 finished with value: 0.33787434621694257 and parameters: {'learning_rate': 0.47946019398169704, 'num_leaves': 35, 'tree_learner': 'feature'}. Best is trial 18 with value: 0.3336105950939092.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:12,817]\u001b[0m Trial 22 finished with value: 0.33371591646917464 and parameters: {'learning_rate': 0.5214732689810356, 'num_leaves': 34, 'tree_learner': 'feature'}. Best is trial 18 with value: 0.3336105950939092.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[16]\tTrain's rmse: 0.134114\tTest's rmse: 0.337874\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001338 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tTrain's rmse: 0.138721\tTest's rmse: 0.333716\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000893 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:12,916]\u001b[0m Trial 23 finished with value: 0.3392591930194975 and parameters: {'learning_rate': 0.5101972682354633, 'num_leaves': 23, 'tree_learner': 'feature'}. Best is trial 18 with value: 0.3336105950939092.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[5]\tTrain's rmse: 0.158349\tTest's rmse: 0.339259\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001281 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:13,202]\u001b[0m Trial 24 finished with value: 0.3499644748820828 and parameters: {'learning_rate': 0.3483748779013355, 'num_leaves': 30, 'tree_learner': 'feature'}. Best is trial 18 with value: 0.3336105950939092.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:13,356]\u001b[0m Trial 25 finished with value: 0.3431844667367912 and parameters: {'learning_rate': 0.6461765173020895, 'num_leaves': 42, 'tree_learner': 'feature'}. Best is trial 18 with value: 0.3336105950939092.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.0986593\tTest's rmse: 0.349964\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tTrain's rmse: 0.165949\tTest's rmse: 0.343184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:13,489]\u001b[0m Trial 26 finished with value: 0.3353801560636247 and parameters: {'learning_rate': 0.5273915524303631, 'num_leaves': 33, 'tree_learner': 'data'}. Best is trial 18 with value: 0.3336105950939092.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000846 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tTrain's rmse: 0.145754\tTest's rmse: 0.33538\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:13,671]\u001b[0m Trial 27 finished with value: 0.34738940040690697 and parameters: {'learning_rate': 0.400927016816351, 'num_leaves': 30, 'tree_learner': 'feature'}. Best is trial 18 with value: 0.3336105950939092.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:13,813]\u001b[0m Trial 28 finished with value: 0.33950621952161664 and parameters: {'learning_rate': 0.8460597444845104, 'num_leaves': 37, 'tree_learner': 'feature'}. Best is trial 18 with value: 0.3336105950939092.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[27]\tTrain's rmse: 0.130248\tTest's rmse: 0.347389\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tTrain's rmse: 0.165669\tTest's rmse: 0.339506\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001020 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:14,011]\u001b[0m Trial 29 finished with value: 0.3442095550135473 and parameters: {'learning_rate': 0.342308526059727, 'num_leaves': 45, 'tree_learner': 'data'}. Best is trial 18 with value: 0.3336105950939092.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\tTrain's rmse: 0.123727\tTest's rmse: 0.34421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:14,140]\u001b[0m Trial 30 finished with value: 0.3550592573077228 and parameters: {'learning_rate': 0.6798546490993118, 'num_leaves': 41, 'tree_learner': 'voting'}. Best is trial 18 with value: 0.3336105950939092.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000969 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tTrain's rmse: 0.182808\tTest's rmse: 0.355059\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000866 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:14,277]\u001b[0m Trial 31 finished with value: 0.3506588909049196 and parameters: {'learning_rate': 0.5311375171194297, 'num_leaves': 34, 'tree_learner': 'data'}. Best is trial 18 with value: 0.3336105950939092.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:14,381]\u001b[0m Trial 32 finished with value: 0.35080327266471384 and parameters: {'learning_rate': 0.543348602149811, 'num_leaves': 32, 'tree_learner': 'data'}. Best is trial 18 with value: 0.3336105950939092.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[7]\tTrain's rmse: 0.149335\tTest's rmse: 0.350659\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tTrain's rmse: 0.148958\tTest's rmse: 0.350803\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000863 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:14,590]\u001b[0m Trial 33 finished with value: 0.3502547074772608 and parameters: {'learning_rate': 0.44130467336070145, 'num_leaves': 39, 'tree_learner': 'data'}. Best is trial 18 with value: 0.3336105950939092.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:14,698]\u001b[0m Trial 34 finished with value: 0.35085820845893195 and parameters: {'learning_rate': 0.5482342160685318, 'num_leaves': 28, 'tree_learner': 'data'}. Best is trial 18 with value: 0.3336105950939092.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.0879308\tTest's rmse: 0.350255\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000844 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tTrain's rmse: 0.149171\tTest's rmse: 0.350858\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000872 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:14,838]\u001b[0m Trial 35 finished with value: 0.33170109118543084 and parameters: {'learning_rate': 0.492502792909591, 'num_leaves': 35, 'tree_learner': 'feature'}. Best is trial 35 with value: 0.33170109118543084.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:14,973]\u001b[0m Trial 36 finished with value: 0.34868590083430157 and parameters: {'learning_rate': 0.24836450778814262, 'num_leaves': 36, 'tree_learner': 'feature'}. Best is trial 35 with value: 0.33170109118543084.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[10]\tTrain's rmse: 0.13496\tTest's rmse: 0.331701\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000841 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tTrain's rmse: 0.166115\tTest's rmse: 0.348686\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000870 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:15,069]\u001b[0m Trial 37 finished with value: 0.34109082483547765 and parameters: {'learning_rate': 0.4408063885966882, 'num_leaves': 24, 'tree_learner': 'feature'}. Best is trial 35 with value: 0.33170109118543084.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:15,176]\u001b[0m Trial 38 finished with value: 0.34597967698553855 and parameters: {'learning_rate': 0.6017500053478786, 'num_leaves': 39, 'tree_learner': 'feature'}. Best is trial 35 with value: 0.33170109118543084.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[5]\tTrain's rmse: 0.162446\tTest's rmse: 0.341091\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000871 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tTrain's rmse: 0.169937\tTest's rmse: 0.34598\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001463 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tTrain's rmse: 0.149793\tTest's rmse: 0.352035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:15,265]\u001b[0m Trial 39 finished with value: 0.3520352756101194 and parameters: {'learning_rate': 0.6519201854300846, 'num_leaves': 13, 'tree_learner': 'voting'}. Best is trial 35 with value: 0.33170109118543084.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:15,468]\u001b[0m Trial 40 finished with value: 0.34796612852903386 and parameters: {'learning_rate': 0.3892866077942547, 'num_leaves': 29, 'tree_learner': 'feature'}. Best is trial 35 with value: 0.33170109118543084.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000861 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.0879378\tTest's rmse: 0.347966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:15,592]\u001b[0m Trial 41 finished with value: 0.33375650893944164 and parameters: {'learning_rate': 0.5164449213939057, 'num_leaves': 32, 'tree_learner': 'data'}. Best is trial 35 with value: 0.33170109118543084.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001074 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tTrain's rmse: 0.138944\tTest's rmse: 0.333756\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001236 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:15,729]\u001b[0m Trial 42 finished with value: 0.3483636432659457 and parameters: {'learning_rate': 0.5761859069711294, 'num_leaves': 32, 'tree_learner': 'feature'}. Best is trial 35 with value: 0.33170109118543084.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:15,872]\u001b[0m Trial 43 finished with value: 0.34200355575344893 and parameters: {'learning_rate': 0.48262164055782947, 'num_leaves': 36, 'tree_learner': 'data'}. Best is trial 35 with value: 0.33170109118543084.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[3]\tTrain's rmse: 0.173376\tTest's rmse: 0.348364\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001799 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tTrain's rmse: 0.137055\tTest's rmse: 0.342004\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001116 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tTrain's rmse: 0.156377\tTest's rmse: 0.327817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:15,929]\u001b[0m Trial 44 finished with value: 0.3278165769044114 and parameters: {'learning_rate': 0.5057187337928578, 'num_leaves': 6, 'tree_learner': 'voting'}. Best is trial 44 with value: 0.3278165769044114.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:15,984]\u001b[0m Trial 45 finished with value: 0.3284657441779182 and parameters: {'learning_rate': 0.5667507854685649, 'num_leaves': 5, 'tree_learner': 'voting'}. Best is trial 44 with value: 0.3278165769044114.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:16,051]\u001b[0m Trial 46 finished with value: 0.3240212012186768 and parameters: {'learning_rate': 0.5766656488633808, 'num_leaves': 5, 'tree_learner': 'voting'}. Best is trial 46 with value: 0.3240212012186768.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:16,109]\u001b[0m Trial 47 finished with value: 0.3289552559846293 and parameters: {'learning_rate': 0.5799099085786137, 'num_leaves': 5, 'tree_learner': 'voting'}. Best is trial 46 with value: 0.3240212012186768.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000880 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tTrain's rmse: 0.173438\tTest's rmse: 0.328466\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000890 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\tTrain's rmse: 0.104661\tTest's rmse: 0.324021\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001302 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tTrain's rmse: 0.173677\tTest's rmse: 0.328955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:16,175]\u001b[0m Trial 48 finished with value: 0.3292984853652232 and parameters: {'learning_rate': 0.7823238199046769, 'num_leaves': 5, 'tree_learner': 'voting'}. Best is trial 46 with value: 0.3240212012186768.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:16,246]\u001b[0m Trial 49 finished with value: 0.3613881809591341 and parameters: {'learning_rate': 0.9799720960762262, 'num_leaves': 6, 'tree_learner': 'voting'}. Best is trial 46 with value: 0.3240212012186768.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:16,293]\u001b[0m Trial 50 finished with value: 0.32921156922829153 and parameters: {'learning_rate': 0.7630942047364111, 'num_leaves': 5, 'tree_learner': 'voting'}. Best is trial 46 with value: 0.3240212012186768.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000879 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tTrain's rmse: 0.124911\tTest's rmse: 0.329298\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001424 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tTrain's rmse: 0.167769\tTest's rmse: 0.361388\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001020 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tTrain's rmse: 0.168939\tTest's rmse: 0.329212\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000879 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:16,361]\u001b[0m Trial 51 finished with value: 0.32952438639171544 and parameters: {'learning_rate': 0.7735422074236302, 'num_leaves': 5, 'tree_learner': 'voting'}. Best is trial 46 with value: 0.3240212012186768.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:16,427]\u001b[0m Trial 52 finished with value: 0.3392891599688804 and parameters: {'learning_rate': 0.8062590813613819, 'num_leaves': 8, 'tree_learner': 'voting'}. Best is trial 46 with value: 0.3240212012186768.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:16,506]\u001b[0m Trial 53 finished with value: 0.3535479567389913 and parameters: {'learning_rate': 0.8718877606186736, 'num_leaves': 12, 'tree_learner': 'voting'}. Best is trial 46 with value: 0.3240212012186768.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[6]\tTrain's rmse: 0.169011\tTest's rmse: 0.329524\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000858 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tTrain's rmse: 0.18282\tTest's rmse: 0.339289\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000904 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tTrain's rmse: 0.130924\tTest's rmse: 0.353548\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000936 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:16,557]\u001b[0m Trial 54 finished with value: 0.32737066403822745 and parameters: {'learning_rate': 0.8998129511276862, 'num_leaves': 9, 'tree_learner': 'voting'}. Best is trial 46 with value: 0.3240212012186768.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:16,643]\u001b[0m Trial 55 finished with value: 0.35254766981425867 and parameters: {'learning_rate': 0.9231748814730887, 'num_leaves': 9, 'tree_learner': 'voting'}. Best is trial 46 with value: 0.3240212012186768.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:16,736]\u001b[0m Trial 56 finished with value: 0.34662520304066907 and parameters: {'learning_rate': 0.9204753545365868, 'num_leaves': 14, 'tree_learner': 'voting'}. Best is trial 46 with value: 0.3240212012186768.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[2]\tTrain's rmse: 0.178403\tTest's rmse: 0.327371\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000857 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\tTrain's rmse: 0.102892\tTest's rmse: 0.352548\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000864 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tTrain's rmse: 0.126582\tTest's rmse: 0.346625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:16,808]\u001b[0m Trial 57 finished with value: 0.3533733178238776 and parameters: {'learning_rate': 0.7346500562729055, 'num_leaves': 9, 'tree_learner': 'voting'}. Best is trial 46 with value: 0.3240212012186768.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:16,871]\u001b[0m Trial 58 finished with value: 0.3327068772033334 and parameters: {'learning_rate': 0.6318573532245535, 'num_leaves': 7, 'tree_learner': 'voting'}. Best is trial 46 with value: 0.3240212012186768.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:16,945]\u001b[0m Trial 59 finished with value: 0.3482091591935603 and parameters: {'learning_rate': 0.5816648272388742, 'num_leaves': 15, 'tree_learner': 'voting'}. Best is trial 46 with value: 0.3240212012186768.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001551 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tTrain's rmse: 0.185356\tTest's rmse: 0.353373\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000907 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tTrain's rmse: 0.160489\tTest's rmse: 0.332707\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tTrain's rmse: 0.174049\tTest's rmse: 0.348209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:17,007]\u001b[0m Trial 60 finished with value: 0.35572511707095233 and parameters: {'learning_rate': 0.7015866663075805, 'num_leaves': 10, 'tree_learner': 'voting'}. Best is trial 46 with value: 0.3240212012186768.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:17,079]\u001b[0m Trial 61 finished with value: 0.3456145618804242 and parameters: {'learning_rate': 0.7885405881232912, 'num_leaves': 11, 'tree_learner': 'voting'}. Best is trial 46 with value: 0.3240212012186768.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:17,140]\u001b[0m Trial 62 finished with value: 0.33703865732881433 and parameters: {'learning_rate': 0.8775526586765696, 'num_leaves': 5, 'tree_learner': 'voting'}. Best is trial 46 with value: 0.3240212012186768.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000859 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tTrain's rmse: 0.153924\tTest's rmse: 0.355725\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tTrain's rmse: 0.174705\tTest's rmse: 0.345615\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000854 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tTrain's rmse: 0.138324\tTest's rmse: 0.337039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:17,214]\u001b[0m Trial 63 finished with value: 0.3298410408420863 and parameters: {'learning_rate': 0.7377234037028284, 'num_leaves': 7, 'tree_learner': 'voting'}. Best is trial 46 with value: 0.3240212012186768.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:17,282]\u001b[0m Trial 64 finished with value: 0.3311244386617197 and parameters: {'learning_rate': 0.8192938899259918, 'num_leaves': 5, 'tree_learner': 'voting'}. Best is trial 46 with value: 0.3240212012186768.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:17,352]\u001b[0m Trial 65 finished with value: 0.3218883438826219 and parameters: {'learning_rate': 0.6724046804522255, 'num_leaves': 7, 'tree_learner': 'voting'}. Best is trial 65 with value: 0.3218883438826219.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tTrain's rmse: 0.194126\tTest's rmse: 0.329841\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001225 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tTrain's rmse: 0.191664\tTest's rmse: 0.331124\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000932 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\tTrain's rmse: 0.0914891\tTest's rmse: 0.321888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:17,422]\u001b[0m Trial 66 finished with value: 0.32541625084509074 and parameters: {'learning_rate': 0.6657285846363099, 'num_leaves': 7, 'tree_learner': 'voting'}. Best is trial 65 with value: 0.3218883438826219.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:17,488]\u001b[0m Trial 67 finished with value: 0.3327453328362737 and parameters: {'learning_rate': 0.6073612066429784, 'num_leaves': 7, 'tree_learner': 'voting'}. Best is trial 65 with value: 0.3218883438826219.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000925 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tTrain's rmse: 0.110853\tTest's rmse: 0.325416\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000882 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tTrain's rmse: 0.113471\tTest's rmse: 0.332745\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000913 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:17,574]\u001b[0m Trial 68 finished with value: 0.34736883556613335 and parameters: {'learning_rate': 0.6816891729087461, 'num_leaves': 16, 'tree_learner': 'voting'}. Best is trial 65 with value: 0.3218883438826219.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:17,655]\u001b[0m Trial 69 finished with value: 0.3484424527845376 and parameters: {'learning_rate': 0.5634198669544201, 'num_leaves': 11, 'tree_learner': 'voting'}. Best is trial 65 with value: 0.3218883438826219.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:17,745]\u001b[0m Trial 70 finished with value: 0.34365016201627646 and parameters: {'learning_rate': 0.6377655631733063, 'num_leaves': 20, 'tree_learner': 'voting'}. Best is trial 65 with value: 0.3218883438826219.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[6]\tTrain's rmse: 0.150224\tTest's rmse: 0.347369\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000907 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tTrain's rmse: 0.127462\tTest's rmse: 0.348442\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tTrain's rmse: 0.167356\tTest's rmse: 0.34365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:17,830]\u001b[0m Trial 71 finished with value: 0.31698956233652603 and parameters: {'learning_rate': 0.665382290414195, 'num_leaves': 8, 'tree_learner': 'voting'}. Best is trial 71 with value: 0.31698956233652603.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:17,946]\u001b[0m Trial 72 finished with value: 0.3174961434861899 and parameters: {'learning_rate': 0.6644835481752402, 'num_leaves': 8, 'tree_learner': 'voting'}. Best is trial 71 with value: 0.31698956233652603.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000872 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\tTrain's rmse: 0.0840241\tTest's rmse: 0.31699\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001310 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tTrain's rmse: 0.139076\tTest's rmse: 0.317496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:18,063]\u001b[0m Trial 73 finished with value: 0.32486715181358344 and parameters: {'learning_rate': 0.6874217052076658, 'num_leaves': 8, 'tree_learner': 'voting'}. Best is trial 71 with value: 0.31698956233652603.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tTrain's rmse: 0.136457\tTest's rmse: 0.324867\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001524 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:18,239]\u001b[0m Trial 74 finished with value: 0.3060021768681886 and parameters: {'learning_rate': 0.6667334354547906, 'num_leaves': 8, 'tree_learner': 'voting'}. Best is trial 74 with value: 0.3060021768681886.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:18,327]\u001b[0m Trial 75 finished with value: 0.35178639532802614 and parameters: {'learning_rate': 0.659108213943972, 'num_leaves': 10, 'tree_learner': 'voting'}. Best is trial 74 with value: 0.3060021768681886.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[36]\tTrain's rmse: 0.0784003\tTest's rmse: 0.306002\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001483 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tTrain's rmse: 0.144687\tTest's rmse: 0.351786\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000791 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:18,492]\u001b[0m Trial 76 finished with value: 0.3255476314473759 and parameters: {'learning_rate': 0.6776253562955405, 'num_leaves': 8, 'tree_learner': 'serial'}. Best is trial 74 with value: 0.3060021768681886.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:18,646]\u001b[0m Trial 77 finished with value: 0.32223033758364755 and parameters: {'learning_rate': 0.6929626123295566, 'num_leaves': 8, 'tree_learner': 'serial'}. Best is trial 74 with value: 0.3060021768681886.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[5]\tTrain's rmse: 0.152582\tTest's rmse: 0.325548\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001601 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tTrain's rmse: 0.155788\tTest's rmse: 0.32223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:18,791]\u001b[0m Trial 78 finished with value: 0.34625886191549815 and parameters: {'learning_rate': 0.6964829026502019, 'num_leaves': 13, 'tree_learner': 'serial'}. Best is trial 74 with value: 0.3060021768681886.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tTrain's rmse: 0.125296\tTest's rmse: 0.346259\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:18,901]\u001b[0m Trial 79 finished with value: 0.35218078851253204 and parameters: {'learning_rate': 0.7197030233533921, 'num_leaves': 11, 'tree_learner': 'serial'}. Best is trial 74 with value: 0.3060021768681886.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:19,023]\u001b[0m Trial 80 finished with value: 0.3445222104658245 and parameters: {'learning_rate': 0.6261795060389412, 'num_leaves': 18, 'tree_learner': 'serial'}. Best is trial 74 with value: 0.3060021768681886.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[2]\tTrain's rmse: 0.182014\tTest's rmse: 0.352181\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tTrain's rmse: 0.168629\tTest's rmse: 0.344522\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tTrain's rmse: 0.152566\tTest's rmse: 0.325524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:19,103]\u001b[0m Trial 81 finished with value: 0.3255238484907054 and parameters: {'learning_rate': 0.6748131919131676, 'num_leaves': 8, 'tree_learner': 'serial'}. Best is trial 74 with value: 0.3060021768681886.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:19,215]\u001b[0m Trial 82 finished with value: 0.31092817494078856 and parameters: {'learning_rate': 0.6674568593744942, 'num_leaves': 8, 'tree_learner': 'serial'}. Best is trial 74 with value: 0.3060021768681886.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.046439\tTest's rmse: 0.310928\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000881 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.0315294\tTest's rmse: 0.322913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:19,318]\u001b[0m Trial 83 finished with value: 0.3229130080744064 and parameters: {'learning_rate': 0.7282559772893055, 'num_leaves': 7, 'tree_learner': 'serial'}. Best is trial 74 with value: 0.3060021768681886.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:19,393]\u001b[0m Trial 84 finished with value: 0.3509630219186765 and parameters: {'learning_rate': 0.7430159486877104, 'num_leaves': 10, 'tree_learner': 'serial'}. Best is trial 74 with value: 0.3060021768681886.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:19,473]\u001b[0m Trial 85 finished with value: 0.3202138555913711 and parameters: {'learning_rate': 0.7080395856500951, 'num_leaves': 8, 'tree_learner': 'serial'}. Best is trial 74 with value: 0.3060021768681886.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000935 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tTrain's rmse: 0.181177\tTest's rmse: 0.350963\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tTrain's rmse: 0.155675\tTest's rmse: 0.320214\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001009 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:19,568]\u001b[0m Trial 86 finished with value: 0.3508462324325712 and parameters: {'learning_rate': 0.7234182349102731, 'num_leaves': 12, 'tree_learner': 'serial'}. Best is trial 74 with value: 0.3060021768681886.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:19,639]\u001b[0m Trial 87 finished with value: 0.323061088574167 and parameters: {'learning_rate': 0.6112996844277678, 'num_leaves': 6, 'tree_learner': 'serial'}. Best is trial 74 with value: 0.3060021768681886.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:19,719]\u001b[0m Trial 88 finished with value: 0.3484759506292763 and parameters: {'learning_rate': 0.6093147052811383, 'num_leaves': 9, 'tree_learner': 'serial'}. Best is trial 74 with value: 0.3060021768681886.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[2]\tTrain's rmse: 0.179851\tTest's rmse: 0.350846\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001243 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tTrain's rmse: 0.14661\tTest's rmse: 0.323061\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tTrain's rmse: 0.175911\tTest's rmse: 0.348476\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:19,858]\u001b[0m Trial 89 finished with value: 0.3563311482931849 and parameters: {'learning_rate': 0.7075532212983181, 'num_leaves': 13, 'tree_learner': 'serial'}. Best is trial 74 with value: 0.3060021768681886.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.0698478\tTest's rmse: 0.356331\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001340 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tTrain's rmse: 0.159464\tTest's rmse: 0.327807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:19,938]\u001b[0m Trial 90 finished with value: 0.3278065892029281 and parameters: {'learning_rate': 0.6523354322129759, 'num_leaves': 7, 'tree_learner': 'serial'}. Best is trial 74 with value: 0.3060021768681886.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:20,048]\u001b[0m Trial 91 finished with value: 0.3245563198340559 and parameters: {'learning_rate': 0.7552556168939503, 'num_leaves': 6, 'tree_learner': 'serial'}. Best is trial 74 with value: 0.3060021768681886.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:20,126]\u001b[0m Trial 92 finished with value: 0.32622685584783356 and parameters: {'learning_rate': 0.5913885281987276, 'num_leaves': 6, 'tree_learner': 'serial'}. Best is trial 74 with value: 0.3060021768681886.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\tTrain's rmse: 0.089195\tTest's rmse: 0.324556\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001409 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tTrain's rmse: 0.156726\tTest's rmse: 0.326227\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:20,211]\u001b[0m Trial 93 finished with value: 0.3366694473514907 and parameters: {'learning_rate': 0.6217473192438971, 'num_leaves': 10, 'tree_learner': 'serial'}. Best is trial 74 with value: 0.3060021768681886.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:20,304]\u001b[0m Trial 94 finished with value: 0.3120661011321638 and parameters: {'learning_rate': 0.6465788777492969, 'num_leaves': 8, 'tree_learner': 'serial'}. Best is trial 74 with value: 0.3060021768681886.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tTrain's rmse: 0.145855\tTest's rmse: 0.336669\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001358 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tTrain's rmse: 0.0908669\tTest's rmse: 0.312066\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002512 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:20,406]\u001b[0m Trial 95 finished with value: 0.3121437625420051 and parameters: {'learning_rate': 0.6440896052567635, 'num_leaves': 8, 'tree_learner': 'serial'}. Best is trial 74 with value: 0.3060021768681886.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:20,505]\u001b[0m Trial 96 finished with value: 0.3496425260325191 and parameters: {'learning_rate': 0.6484989630770087, 'num_leaves': 11, 'tree_learner': 'serial'}. Best is trial 74 with value: 0.3060021768681886.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:20,585]\u001b[0m Trial 97 finished with value: 0.32001528135271295 and parameters: {'learning_rate': 0.7170635201287242, 'num_leaves': 8, 'tree_learner': 'serial'}. Best is trial 74 with value: 0.3060021768681886.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tTrain's rmse: 0.0910109\tTest's rmse: 0.312144\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001403 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tTrain's rmse: 0.143434\tTest's rmse: 0.349643\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001463 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tTrain's rmse: 0.155674\tTest's rmse: 0.320015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:20,674]\u001b[0m Trial 98 finished with value: 0.34781935371304984 and parameters: {'learning_rate': 0.7513047651787493, 'num_leaves': 12, 'tree_learner': 'serial'}. Best is trial 74 with value: 0.3060021768681886.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:20,770]\u001b[0m Trial 99 finished with value: 0.35485407914385986 and parameters: {'learning_rate': 0.7115613016648923, 'num_leaves': 9, 'tree_learner': 'serial'}. Best is trial 74 with value: 0.3060021768681886.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001442 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tTrain's rmse: 0.176358\tTest's rmse: 0.347819\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\tTrain's rmse: 0.122134\tTest's rmse: 0.354854\n",
      "{'learning_rate': 0.6667334354547906, 'num_leaves': 8, 'tree_learner': 'voting'}\n",
      "{'learning_rate': 0.6667334354547906, 'num_leaves': 8, 'tree_learner': 'voting', 'objective': 'regression', 'metric': 'rmse', 'task': 'train', 'seed': 42}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001303 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 10909, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.356349\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\tTrain's rmse: 0.0784003\tTest's rmse: 0.306002\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:21,037]\u001b[0m A new study created in memory with name: no-name-e5b2efa9-a66b-4bfe-97a6-197c5b900a4c\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000840 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.116216\tTest's rmse: 0.128094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:21,277]\u001b[0m Trial 0 finished with value: 0.1280939699870691 and parameters: {'learning_rate': 0.23018857747259022, 'num_leaves': 29, 'tree_learner': 'feature'}. Best is trial 0 with value: 0.1280939699870691.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:21,448]\u001b[0m Trial 1 finished with value: 0.11265433349346586 and parameters: {'learning_rate': 0.4224301905736748, 'num_leaves': 30, 'tree_learner': 'voting'}. Best is trial 1 with value: 0.11265433349346586.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001392 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\tTrain's rmse: 0.146866\tTest's rmse: 0.112654\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:21,598]\u001b[0m Trial 2 finished with value: 0.12897437970355338 and parameters: {'learning_rate': 0.8477191551436323, 'num_leaves': 34, 'tree_learner': 'serial'}. Best is trial 1 with value: 0.11265433349346586.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:21,701]\u001b[0m Trial 3 finished with value: 0.12290120407131627 and parameters: {'learning_rate': 0.8267531768982845, 'num_leaves': 19, 'tree_learner': 'data'}. Best is trial 1 with value: 0.11265433349346586.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[11]\tTrain's rmse: 0.158479\tTest's rmse: 0.128974\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tTrain's rmse: 0.154575\tTest's rmse: 0.122901\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000588 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tTrain's rmse: 0.152498\tTest's rmse: 0.129769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:21,781]\u001b[0m Trial 4 finished with value: 0.12976857051605437 and parameters: {'learning_rate': 0.9224393404625999, 'num_leaves': 14, 'tree_learner': 'feature'}. Best is trial 1 with value: 0.11265433349346586.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:21,950]\u001b[0m Trial 5 finished with value: 0.11604951594415668 and parameters: {'learning_rate': 0.5903720761134541, 'num_leaves': 33, 'tree_learner': 'feature'}. Best is trial 1 with value: 0.11265433349346586.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001318 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tTrain's rmse: 0.153819\tTest's rmse: 0.11605\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001201 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:22,076]\u001b[0m Trial 6 finished with value: 0.12548017248029955 and parameters: {'learning_rate': 0.2419785482746114, 'num_leaves': 13, 'tree_learner': 'voting'}. Best is trial 1 with value: 0.11265433349346586.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:22,214]\u001b[0m Trial 7 finished with value: 0.12453121989864507 and parameters: {'learning_rate': 0.7054313292740293, 'num_leaves': 34, 'tree_learner': 'serial'}. Best is trial 1 with value: 0.11265433349346586.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.111807\tTest's rmse: 0.12548\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001294 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tTrain's rmse: 0.152604\tTest's rmse: 0.124531\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000633 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:22,287]\u001b[0m Trial 8 finished with value: 0.12467917018243443 and parameters: {'learning_rate': 0.8467152492516271, 'num_leaves': 9, 'tree_learner': 'serial'}. Best is trial 1 with value: 0.11265433349346586.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tTrain's rmse: 0.136388\tTest's rmse: 0.124679\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001459 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tTrain's rmse: 0.150945\tTest's rmse: 0.122056"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:22,482]\u001b[0m Trial 9 finished with value: 0.12205642940862084 and parameters: {'learning_rate': 0.38973450781403085, 'num_leaves': 35, 'tree_learner': 'data'}. Best is trial 1 with value: 0.11265433349346586.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000883 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:22,707]\u001b[0m Trial 10 finished with value: 0.10996480111810611 and parameters: {'learning_rate': 0.43848430790671045, 'num_leaves': 49, 'tree_learner': 'voting'}. Best is trial 10 with value: 0.10996480111810611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[21]\tTrain's rmse: 0.147376\tTest's rmse: 0.109965\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001968 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:22,989]\u001b[0m Trial 11 finished with value: 0.11703681140506164 and parameters: {'learning_rate': 0.41341360226163637, 'num_leaves': 50, 'tree_learner': 'voting'}. Best is trial 10 with value: 0.10996480111810611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[32]\tTrain's rmse: 0.144969\tTest's rmse: 0.117037\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:23,333]\u001b[0m Trial 12 finished with value: 0.11365455218418735 and parameters: {'learning_rate': 0.44584503760453353, 'num_leaves': 50, 'tree_learner': 'voting'}. Best is trial 10 with value: 0.10996480111810611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[26]\tTrain's rmse: 0.146427\tTest's rmse: 0.113655\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001435 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:23,686]\u001b[0m Trial 13 finished with value: 0.11220286566033146 and parameters: {'learning_rate': 0.10958921961050283, 'num_leaves': 43, 'tree_learner': 'voting'}. Best is trial 10 with value: 0.10996480111810611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.147977\tTest's rmse: 0.112203\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001710 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:23,967]\u001b[0m Trial 14 finished with value: 0.11849533150674522 and parameters: {'learning_rate': 0.14862444706125044, 'num_leaves': 42, 'tree_learner': 'voting'}. Best is trial 10 with value: 0.10996480111810611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.133922\tTest's rmse: 0.118495\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:24,205]\u001b[0m Trial 15 finished with value: 0.11384769451378567 and parameters: {'learning_rate': 0.5992769137363322, 'num_leaves': 44, 'tree_learner': 'voting'}. Best is trial 10 with value: 0.10996480111810611.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[25]\tTrain's rmse: 0.139735\tTest's rmse: 0.113848\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001530 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:24,533]\u001b[0m Trial 16 finished with value: 0.1096250569734718 and parameters: {'learning_rate': 0.1234187588315436, 'num_leaves': 43, 'tree_learner': 'voting'}. Best is trial 16 with value: 0.1096250569734718.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:24,701]\u001b[0m Trial 17 finished with value: 0.1113285473635086 and parameters: {'learning_rate': 0.29658575330007836, 'num_leaves': 23, 'tree_learner': 'voting'}. Best is trial 16 with value: 0.1096250569734718.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.145459\tTest's rmse: 0.109625\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000878 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\tTrain's rmse: 0.144053\tTest's rmse: 0.111329\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001166 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:24,919]\u001b[0m Trial 18 finished with value: 0.10888180316190495 and parameters: {'learning_rate': 0.5165028782277457, 'num_leaves': 39, 'tree_learner': 'data'}. Best is trial 18 with value: 0.10888180316190495.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[28]\tTrain's rmse: 0.135077\tTest's rmse: 0.108882\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000504 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tTrain's rmse: 0.152157\tTest's rmse: 0.124408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:25,115]\u001b[0m Trial 19 finished with value: 0.12440763356061574 and parameters: {'learning_rate': 0.711208015701533, 'num_leaves': 40, 'tree_learner': 'data'}. Best is trial 18 with value: 0.10888180316190495.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001643 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\tTrain's rmse: 0.126913\tTest's rmse: 0.108555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:25,331]\u001b[0m Trial 20 finished with value: 0.10855487146761844 and parameters: {'learning_rate': 0.5250595425570751, 'num_leaves': 38, 'tree_learner': 'data'}. Best is trial 20 with value: 0.10855487146761844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001201 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:25,565]\u001b[0m Trial 21 finished with value: 0.11217870945571773 and parameters: {'learning_rate': 0.5226927056258638, 'num_leaves': 40, 'tree_learner': 'data'}. Best is trial 20 with value: 0.10855487146761844.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:25,741]\u001b[0m Trial 22 finished with value: 0.11036572330747405 and parameters: {'learning_rate': 0.6516071689572714, 'num_leaves': 37, 'tree_learner': 'data'}. Best is trial 20 with value: 0.10855487146761844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[36]\tTrain's rmse: 0.1259\tTest's rmse: 0.112179\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000905 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tTrain's rmse: 0.139039\tTest's rmse: 0.110366\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001228 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tTrain's rmse: 0.149531\tTest's rmse: 0.115783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:25,966]\u001b[0m Trial 23 finished with value: 0.11578324941213741 and parameters: {'learning_rate': 0.5185439129124211, 'num_leaves': 46, 'tree_learner': 'data'}. Best is trial 20 with value: 0.10855487146761844.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:26,147]\u001b[0m Trial 24 finished with value: 0.11558074179115188 and parameters: {'learning_rate': 0.2988882081967613, 'num_leaves': 26, 'tree_learner': 'data'}. Best is trial 20 with value: 0.10855487146761844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000952 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\tTrain's rmse: 0.142824\tTest's rmse: 0.115581\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001535 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:26,388]\u001b[0m Trial 25 finished with value: 0.10867301104605968 and parameters: {'learning_rate': 0.34703849792103725, 'num_leaves': 39, 'tree_learner': 'data'}. Best is trial 20 with value: 0.10855487146761844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[40]\tTrain's rmse: 0.136997\tTest's rmse: 0.108673\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:26,611]\u001b[0m Trial 26 finished with value: 0.10979489879777159 and parameters: {'learning_rate': 0.3487810164944869, 'num_leaves': 38, 'tree_learner': 'data'}. Best is trial 20 with value: 0.10855487146761844.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:26,788]\u001b[0m Trial 27 finished with value: 0.11210377120550975 and parameters: {'learning_rate': 0.5096246101734289, 'num_leaves': 31, 'tree_learner': 'data'}. Best is trial 20 with value: 0.10855487146761844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[36]\tTrain's rmse: 0.143313\tTest's rmse: 0.109795\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000887 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tTrain's rmse: 0.141698\tTest's rmse: 0.112104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:26,924]\u001b[0m Trial 28 finished with value: 0.1100343348415512 and parameters: {'learning_rate': 0.4866736126117922, 'num_leaves': 25, 'tree_learner': 'data'}. Best is trial 20 with value: 0.10855487146761844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001382 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tTrain's rmse: 0.162476\tTest's rmse: 0.110034\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:27,220]\u001b[0m Trial 29 finished with value: 0.12359475921506387 and parameters: {'learning_rate': 0.2133136491371368, 'num_leaves': 46, 'tree_learner': 'feature'}. Best is trial 20 with value: 0.10855487146761844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.119922\tTest's rmse: 0.123595\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tTrain's rmse: 0.158949\tTest's rmse: 0.117876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:27,401]\u001b[0m Trial 30 finished with value: 0.11787626841356617 and parameters: {'learning_rate': 0.5924261182609082, 'num_leaves': 28, 'tree_learner': 'data'}. Best is trial 20 with value: 0.10855487146761844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001014 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:27,642]\u001b[0m Trial 31 finished with value: 0.12408718578111351 and parameters: {'learning_rate': 0.1848920474111562, 'num_leaves': 37, 'tree_learner': 'data'}. Best is trial 20 with value: 0.10855487146761844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.124169\tTest's rmse: 0.124087\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000866 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\tTrain's rmse: 0.145145\tTest's rmse: 0.113217"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:27,828]\u001b[0m Trial 32 finished with value: 0.11321667680576131 and parameters: {'learning_rate': 0.33558852815056006, 'num_leaves': 41, 'tree_learner': 'data'}. Best is trial 20 with value: 0.10855487146761844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000894 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\tTrain's rmse: 0.143099\tTest's rmse: 0.112013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:28,004]\u001b[0m Trial 33 finished with value: 0.11201278083659358 and parameters: {'learning_rate': 0.2567620195349922, 'num_leaves': 30, 'tree_learner': 'serial'}. Best is trial 20 with value: 0.10855487146761844.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:28,189]\u001b[0m Trial 34 finished with value: 0.11896528436217628 and parameters: {'learning_rate': 0.6793728184488126, 'num_leaves': 46, 'tree_learner': 'data'}. Best is trial 20 with value: 0.10855487146761844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000842 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tTrain's rmse: 0.142621\tTest's rmse: 0.118965\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000849 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:28,359]\u001b[0m Trial 35 finished with value: 0.1211450318479667 and parameters: {'learning_rate': 0.3741855077083231, 'num_leaves': 39, 'tree_learner': 'feature'}. Best is trial 20 with value: 0.10855487146761844.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:28,498]\u001b[0m Trial 36 finished with value: 0.12367355135820861 and parameters: {'learning_rate': 0.7493896705622455, 'num_leaves': 44, 'tree_learner': 'data'}. Best is trial 20 with value: 0.10855487146761844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[32]\tTrain's rmse: 0.147436\tTest's rmse: 0.121145\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000858 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tTrain's rmse: 0.164161\tTest's rmse: 0.123674\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001120 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:28,627]\u001b[0m Trial 37 finished with value: 0.12425888605178428 and parameters: {'learning_rate': 0.997063958993052, 'num_leaves': 32, 'tree_learner': 'serial'}. Best is trial 20 with value: 0.10855487146761844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tTrain's rmse: 0.152605\tTest's rmse: 0.124259\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001594 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:28,844]\u001b[0m Trial 38 finished with value: 0.11805093168009533 and parameters: {'learning_rate': 0.47210828409784183, 'num_leaves': 36, 'tree_learner': 'feature'}. Best is trial 20 with value: 0.10855487146761844.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:29,015]\u001b[0m Trial 39 finished with value: 0.12063102919776204 and parameters: {'learning_rate': 0.629586844170193, 'num_leaves': 33, 'tree_learner': 'data'}. Best is trial 20 with value: 0.10855487146761844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[26]\tTrain's rmse: 0.140786\tTest's rmse: 0.118051\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tTrain's rmse: 0.146714\tTest's rmse: 0.120631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:29,132]\u001b[0m Trial 40 finished with value: 0.1145842333512851 and parameters: {'learning_rate': 0.5513366750510207, 'num_leaves': 19, 'tree_learner': 'data'}. Best is trial 20 with value: 0.10855487146761844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001496 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tTrain's rmse: 0.151097\tTest's rmse: 0.114584\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:29,369]\u001b[0m Trial 41 finished with value: 0.11055764423334598 and parameters: {'learning_rate': 0.3357910405698896, 'num_leaves': 38, 'tree_learner': 'data'}. Best is trial 20 with value: 0.10855487146761844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[41]\tTrain's rmse: 0.141723\tTest's rmse: 0.110558\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001424 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:29,639]\u001b[0m Trial 42 finished with value: 0.11300455714773269 and parameters: {'learning_rate': 0.10596662392794032, 'num_leaves': 35, 'tree_learner': 'data'}. Best is trial 20 with value: 0.10855487146761844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.149561\tTest's rmse: 0.113005\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001264 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tTrain's rmse: 0.16977\tTest's rmse: 0.130743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:29,821]\u001b[0m Trial 43 finished with value: 0.1307425893251741 and parameters: {'learning_rate': 0.7830069785178753, 'num_leaves': 42, 'tree_learner': 'data'}. Best is trial 20 with value: 0.10855487146761844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:30,076]\u001b[0m Trial 44 finished with value: 0.11693886296364546 and parameters: {'learning_rate': 0.3520901328275966, 'num_leaves': 47, 'tree_learner': 'serial'}. Best is trial 20 with value: 0.10855487146761844.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:30,178]\u001b[0m Trial 45 finished with value: 0.11823484732548577 and parameters: {'learning_rate': 0.2774001131378296, 'num_leaves': 6, 'tree_learner': 'voting'}. Best is trial 20 with value: 0.10855487146761844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[34]\tTrain's rmse: 0.144402\tTest's rmse: 0.116939\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001412 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\tTrain's rmse: 0.143245\tTest's rmse: 0.118235\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:30,391]\u001b[0m Trial 46 finished with value: 0.11053706798813191 and parameters: {'learning_rate': 0.4165431257605796, 'num_leaves': 39, 'tree_learner': 'data'}. Best is trial 20 with value: 0.10855487146761844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[25]\tTrain's rmse: 0.147169\tTest's rmse: 0.110537\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:30,615]\u001b[0m Trial 47 finished with value: 0.12474567350470005 and parameters: {'learning_rate': 0.1860245881901982, 'num_leaves': 34, 'tree_learner': 'voting'}. Best is trial 20 with value: 0.10855487146761844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.12156\tTest's rmse: 0.124746\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001361 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tTrain's rmse: 0.156313\tTest's rmse: 0.118905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:30,806]\u001b[0m Trial 48 finished with value: 0.1189046946328166 and parameters: {'learning_rate': 0.4608630862737021, 'num_leaves': 44, 'tree_learner': 'feature'}. Best is trial 20 with value: 0.10855487146761844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000860 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:31,063]\u001b[0m Trial 49 finished with value: 0.11035819490342373 and parameters: {'learning_rate': 0.38811770141583957, 'num_leaves': 48, 'tree_learner': 'data'}. Best is trial 20 with value: 0.10855487146761844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[34]\tTrain's rmse: 0.138032\tTest's rmse: 0.110358\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001397 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:31,331]\u001b[0m Trial 50 finished with value: 0.11205442378322562 and parameters: {'learning_rate': 0.15667327567837164, 'num_leaves': 41, 'tree_learner': 'voting'}. Best is trial 20 with value: 0.10855487146761844.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.130662\tTest's rmse: 0.112054\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:31,563]\u001b[0m Trial 51 finished with value: 0.10686171524552107 and parameters: {'learning_rate': 0.5483157899538417, 'num_leaves': 50, 'tree_learner': 'voting'}. Best is trial 51 with value: 0.10686171524552107.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[22]\tTrain's rmse: 0.150555\tTest's rmse: 0.106862\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001392 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:31,787]\u001b[0m Trial 52 finished with value: 0.10900039687267339 and parameters: {'learning_rate': 0.5389592221194109, 'num_leaves': 50, 'tree_learner': 'voting'}. Best is trial 51 with value: 0.10686171524552107.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[20]\tTrain's rmse: 0.149705\tTest's rmse: 0.109\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:32,017]\u001b[0m Trial 53 finished with value: 0.10697445346396287 and parameters: {'learning_rate': 0.5498991096540682, 'num_leaves': 50, 'tree_learner': 'voting'}. Best is trial 51 with value: 0.10686171524552107.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[22]\tTrain's rmse: 0.149649\tTest's rmse: 0.106974\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001291 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:32,239]\u001b[0m Trial 54 finished with value: 0.11347042469005937 and parameters: {'learning_rate': 0.557187878309539, 'num_leaves': 50, 'tree_learner': 'voting'}. Best is trial 51 with value: 0.10686171524552107.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tTrain's rmse: 0.155457\tTest's rmse: 0.11347\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:32,472]\u001b[0m Trial 55 finished with value: 0.11041025576602688 and parameters: {'learning_rate': 0.5682136227004414, 'num_leaves': 48, 'tree_learner': 'voting'}. Best is trial 51 with value: 0.10686171524552107.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[26]\tTrain's rmse: 0.142095\tTest's rmse: 0.11041\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:32,685]\u001b[0m Trial 56 finished with value: 0.11438583998160053 and parameters: {'learning_rate': 0.612826164190733, 'num_leaves': 49, 'tree_learner': 'voting'}. Best is trial 51 with value: 0.10686171524552107.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[17]\tTrain's rmse: 0.143092\tTest's rmse: 0.114386\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001408 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tTrain's rmse: 0.145056\tTest's rmse: 0.12002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:32,886]\u001b[0m Trial 57 finished with value: 0.12001982124193498 and parameters: {'learning_rate': 0.6445925118793199, 'num_leaves': 45, 'tree_learner': 'voting'}. Best is trial 51 with value: 0.10686171524552107.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:33,114]\u001b[0m Trial 58 finished with value: 0.11397092798635676 and parameters: {'learning_rate': 0.5334779163648192, 'num_leaves': 50, 'tree_learner': 'voting'}. Best is trial 51 with value: 0.10686171524552107.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[21]\tTrain's rmse: 0.147257\tTest's rmse: 0.113971\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\tTrain's rmse: 0.145614\tTest's rmse: 0.113999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:33,317]\u001b[0m Trial 59 finished with value: 0.11399924113278334 and parameters: {'learning_rate': 0.4823931047849576, 'num_leaves': 43, 'tree_learner': 'voting'}. Best is trial 51 with value: 0.10686171524552107.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001294 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tTrain's rmse: 0.152681\tTest's rmse: 0.108712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:33,523]\u001b[0m Trial 60 finished with value: 0.10871220635152748 and parameters: {'learning_rate': 0.43938385627467585, 'num_leaves': 47, 'tree_learner': 'voting'}. Best is trial 51 with value: 0.10686171524552107.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:33,731]\u001b[0m Trial 61 finished with value: 0.1102318813644299 and parameters: {'learning_rate': 0.44272474203168566, 'num_leaves': 48, 'tree_learner': 'voting'}. Best is trial 51 with value: 0.10686171524552107.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[21]\tTrain's rmse: 0.147279\tTest's rmse: 0.110232\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001356 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tTrain's rmse: 0.152455\tTest's rmse: 0.113908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:33,939]\u001b[0m Trial 62 finished with value: 0.11390770969908327 and parameters: {'learning_rate': 0.5004550577184269, 'num_leaves': 47, 'tree_learner': 'voting'}. Best is trial 51 with value: 0.10686171524552107.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:34,223]\u001b[0m Trial 63 finished with value: 0.14497129643184523 and parameters: {'learning_rate': 0.4168357844167291, 'num_leaves': 45, 'tree_learner': 'voting'}. Best is trial 51 with value: 0.10686171524552107.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.0774554\tTest's rmse: 0.144971\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001275 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:34,449]\u001b[0m Trial 64 finished with value: 0.10784130834776906 and parameters: {'learning_rate': 0.5710036653029422, 'num_leaves': 50, 'tree_learner': 'voting'}. Best is trial 51 with value: 0.10686171524552107.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tTrain's rmse: 0.145743\tTest's rmse: 0.107841\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000967 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:34,671]\u001b[0m Trial 65 finished with value: 0.11208921681434637 and parameters: {'learning_rate': 0.5818262048488653, 'num_leaves': 47, 'tree_learner': 'voting'}. Best is trial 51 with value: 0.10686171524552107.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tTrain's rmse: 0.145207\tTest's rmse: 0.112089\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:34,900]\u001b[0m Trial 66 finished with value: 0.10832298043298487 and parameters: {'learning_rate': 0.6912186574488536, 'num_leaves': 49, 'tree_learner': 'voting'}. Best is trial 51 with value: 0.10686171524552107.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[20]\tTrain's rmse: 0.140635\tTest's rmse: 0.108323\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001260 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tTrain's rmse: 0.139314\tTest's rmse: 0.121781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:35,099]\u001b[0m Trial 67 finished with value: 0.12178086240725278 and parameters: {'learning_rate': 0.7065664506063544, 'num_leaves': 49, 'tree_learner': 'voting'}. Best is trial 51 with value: 0.10686171524552107.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tTrain's rmse: 0.13949\tTest's rmse: 0.117005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:35,311]\u001b[0m Trial 68 finished with value: 0.1170050522998636 and parameters: {'learning_rate': 0.6753578787225982, 'num_leaves': 46, 'tree_learner': 'voting'}. Best is trial 51 with value: 0.10686171524552107.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:35,515]\u001b[0m Trial 69 finished with value: 0.12351904114664042 and parameters: {'learning_rate': 0.7552717143486163, 'num_leaves': 48, 'tree_learner': 'voting'}. Best is trial 51 with value: 0.10686171524552107.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tTrain's rmse: 0.163832\tTest's rmse: 0.123519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:35,667]\u001b[0m Trial 70 finished with value: 0.12089062796956546 and parameters: {'learning_rate': 0.8708571739635329, 'num_leaves': 45, 'tree_learner': 'voting'}. Best is trial 51 with value: 0.10686171524552107.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001248 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tTrain's rmse: 0.146531\tTest's rmse: 0.120891\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000845 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:35,824]\u001b[0m Trial 71 finished with value: 0.11264604716290837 and parameters: {'learning_rate': 0.5011406975696084, 'num_leaves': 41, 'tree_learner': 'serial'}. Best is trial 51 with value: 0.10686171524552107.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:35,978]\u001b[0m Trial 72 finished with value: 0.11774034575616124 and parameters: {'learning_rate': 0.5995734637431398, 'num_leaves': 50, 'tree_learner': 'voting'}. Best is trial 51 with value: 0.10686171524552107.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tTrain's rmse: 0.15255\tTest's rmse: 0.112646\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000860 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tTrain's rmse: 0.159055\tTest's rmse: 0.11774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:36,172]\u001b[0m Trial 73 finished with value: 0.11344317024502 and parameters: {'learning_rate': 0.6278024778367429, 'num_leaves': 43, 'tree_learner': 'voting'}. Best is trial 51 with value: 0.10686171524552107.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000558 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\tTrain's rmse: 0.120347\tTest's rmse: 0.113443\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000893 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:36,287]\u001b[0m Trial 74 finished with value: 0.12221897205370892 and parameters: {'learning_rate': 0.45980050172394415, 'num_leaves': 21, 'tree_learner': 'feature'}. Best is trial 51 with value: 0.10686171524552107.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\tTrain's rmse: 0.138705\tTest's rmse: 0.122219\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000873 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:36,486]\u001b[0m Trial 75 finished with value: 0.11710213640844809 and parameters: {'learning_rate': 0.5192738283922429, 'num_leaves': 47, 'tree_learner': 'data'}. Best is trial 51 with value: 0.10686171524552107.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:36,570]\u001b[0m Trial 76 finished with value: 0.11910132563574026 and parameters: {'learning_rate': 0.5608165948571877, 'num_leaves': 13, 'tree_learner': 'voting'}. Best is trial 51 with value: 0.10686171524552107.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[10]\tTrain's rmse: 0.165698\tTest's rmse: 0.117102\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001267 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tTrain's rmse: 0.142387\tTest's rmse: 0.119101\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001399 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:36,742]\u001b[0m Trial 77 finished with value: 0.11212349564688881 and parameters: {'learning_rate': 0.6720728395700055, 'num_leaves': 36, 'tree_learner': 'data'}. Best is trial 51 with value: 0.10686171524552107.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[20]\tTrain's rmse: 0.136176\tTest's rmse: 0.112123\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:36,987]\u001b[0m Trial 78 finished with value: 0.1031734898537942 and parameters: {'learning_rate': 0.43550137332894606, 'num_leaves': 49, 'tree_learner': 'serial'}. Best is trial 78 with value: 0.1031734898537942.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[28]\tTrain's rmse: 0.141122\tTest's rmse: 0.103173\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:37,284]\u001b[0m Trial 79 finished with value: 0.13160099052809385 and parameters: {'learning_rate': 0.30935447634488505, 'num_leaves': 49, 'tree_learner': 'serial'}. Best is trial 78 with value: 0.1031734898537942.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.0970059\tTest's rmse: 0.131601\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001403 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:37,567]\u001b[0m Trial 80 finished with value: 0.10773516337620175 and parameters: {'learning_rate': 0.3739682820104328, 'num_leaves': 49, 'tree_learner': 'serial'}. Best is trial 78 with value: 0.1031734898537942.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[36]\tTrain's rmse: 0.13312\tTest's rmse: 0.107735\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tTrain's rmse: 0.18805\tTest's rmse: 0.118831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:37,755]\u001b[0m Trial 81 finished with value: 0.11883102032246151 and parameters: {'learning_rate': 0.3788906403950345, 'num_leaves': 48, 'tree_learner': 'serial'}. Best is trial 78 with value: 0.1031734898537942.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:37,998]\u001b[0m Trial 82 finished with value: 0.11086884381081245 and parameters: {'learning_rate': 0.44067165489108556, 'num_leaves': 49, 'tree_learner': 'serial'}. Best is trial 78 with value: 0.1031734898537942.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[27]\tTrain's rmse: 0.1408\tTest's rmse: 0.110869\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:38,234]\u001b[0m Trial 83 finished with value: 0.12258656197451896 and parameters: {'learning_rate': 0.39617121840444375, 'num_leaves': 45, 'tree_learner': 'serial'}. Best is trial 78 with value: 0.1031734898537942.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[31]\tTrain's rmse: 0.145795\tTest's rmse: 0.122587\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001394 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tTrain's rmse: 0.183374\tTest's rmse: 0.115305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:38,404]\u001b[0m Trial 84 finished with value: 0.11530474138619777 and parameters: {'learning_rate': 0.42929118217614065, 'num_leaves': 47, 'tree_learner': 'serial'}. Best is trial 78 with value: 0.1031734898537942.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001362 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:38,682]\u001b[0m Trial 85 finished with value: 0.11100374526866537 and parameters: {'learning_rate': 0.34964214185894804, 'num_leaves': 50, 'tree_learner': 'serial'}. Best is trial 78 with value: 0.1031734898537942.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[36]\tTrain's rmse: 0.143535\tTest's rmse: 0.111004\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001052 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:38,918]\u001b[0m Trial 86 finished with value: 0.12128898083012421 and parameters: {'learning_rate': 0.40469740734587645, 'num_leaves': 46, 'tree_learner': 'serial'}. Best is trial 78 with value: 0.1031734898537942.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[29]\tTrain's rmse: 0.149428\tTest's rmse: 0.121289\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:39,154]\u001b[0m Trial 87 finished with value: 0.11586710637636284 and parameters: {'learning_rate': 0.36937685820006994, 'num_leaves': 44, 'tree_learner': 'serial'}. Best is trial 78 with value: 0.1031734898537942.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[31]\tTrain's rmse: 0.149321\tTest's rmse: 0.115867\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:39,374]\u001b[0m Trial 88 finished with value: 0.11857018938896073 and parameters: {'learning_rate': 0.460720713287666, 'num_leaves': 49, 'tree_learner': 'voting'}. Best is trial 78 with value: 0.1031734898537942.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tTrain's rmse: 0.15459\tTest's rmse: 0.11857\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:39,649]\u001b[0m Trial 89 finished with value: 0.10747545497264042 and parameters: {'learning_rate': 0.31647496672329434, 'num_leaves': 48, 'tree_learner': 'serial'}. Best is trial 78 with value: 0.1031734898537942.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[46]\tTrain's rmse: 0.137021\tTest's rmse: 0.107475\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:39,867]\u001b[0m Trial 90 finished with value: 0.1294131181214369 and parameters: {'learning_rate': 0.24100150910846913, 'num_leaves': 27, 'tree_learner': 'serial'}. Best is trial 78 with value: 0.1031734898537942.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.116238\tTest's rmse: 0.129413\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001384 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:40,169]\u001b[0m Trial 91 finished with value: 0.11175009895153848 and parameters: {'learning_rate': 0.25936111939088824, 'num_leaves': 48, 'tree_learner': 'serial'}. Best is trial 78 with value: 0.1031734898537942.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[49]\tTrain's rmse: 0.142113\tTest's rmse: 0.11175\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:40,379]\u001b[0m Trial 92 finished with value: 0.11882186453059607 and parameters: {'learning_rate': 0.5796104610873559, 'num_leaves': 50, 'tree_learner': 'serial'}. Best is trial 78 with value: 0.1031734898537942.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[17]\tTrain's rmse: 0.162583\tTest's rmse: 0.118822\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:40,666]\u001b[0m Trial 93 finished with value: 0.1170975503262458 and parameters: {'learning_rate': 0.29557051870701173, 'num_leaves': 47, 'tree_learner': 'serial'}. Best is trial 78 with value: 0.1031734898537942.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[29]\tTrain's rmse: 0.146648\tTest's rmse: 0.117098\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:41,006]\u001b[0m Trial 94 finished with value: 0.12990437123505752 and parameters: {'learning_rate': 0.3252346077789838, 'num_leaves': 46, 'tree_learner': 'feature'}. Best is trial 78 with value: 0.1031734898537942.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.0979163\tTest's rmse: 0.129904\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001226 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:41,241]\u001b[0m Trial 95 finished with value: 0.11348478754518088 and parameters: {'learning_rate': 0.48622000517363295, 'num_leaves': 49, 'tree_learner': 'voting'}. Best is trial 78 with value: 0.1031734898537942.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[19]\tTrain's rmse: 0.153372\tTest's rmse: 0.113485\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:41,483]\u001b[0m Trial 96 finished with value: 0.11468516818948953 and parameters: {'learning_rate': 0.36588642357447215, 'num_leaves': 42, 'tree_learner': 'serial'}. Best is trial 78 with value: 0.1031734898537942.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[34]\tTrain's rmse: 0.144396\tTest's rmse: 0.114685\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001438 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:41,696]\u001b[0m Trial 97 finished with value: 0.10965731293655546 and parameters: {'learning_rate': 0.5363431968686051, 'num_leaves': 44, 'tree_learner': 'voting'}. Best is trial 78 with value: 0.1031734898537942.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[20]\tTrain's rmse: 0.150771\tTest's rmse: 0.109657\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:41,908]\u001b[0m Trial 98 finished with value: 0.1228967174815457 and parameters: {'learning_rate': 0.7364165066717788, 'num_leaves': 48, 'tree_learner': 'voting'}. Best is trial 78 with value: 0.1031734898537942.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tTrain's rmse: 0.163065\tTest's rmse: 0.122897\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001207 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:42,202]\u001b[0m Trial 99 finished with value: 0.1154021702456583 and parameters: {'learning_rate': 0.3134650224365839, 'num_leaves': 49, 'tree_learner': 'serial'}. Best is trial 78 with value: 0.1031734898537942.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[37]\tTrain's rmse: 0.143252\tTest's rmse: 0.115402\n",
      "{'learning_rate': 0.43550137332894606, 'num_leaves': 49, 'tree_learner': 'serial'}\n",
      "{'learning_rate': 0.43550137332894606, 'num_leaves': 49, 'tree_learner': 'serial', 'objective': 'regression', 'metric': 'rmse', 'task': 'train', 'seed': 42}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 10933, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.345808\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\tTrain's rmse: 0.141122\tTest's rmse: 0.103173\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:42,638]\u001b[0m A new study created in memory with name: no-name-40a0ba33-a14b-4bb5-a43e-57ce49f05235\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002049 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:42,949]\u001b[0m Trial 0 finished with value: 0.1407062059614464 and parameters: {'learning_rate': 0.2979705344345628, 'num_leaves': 49, 'tree_learner': 'serial'}. Best is trial 0 with value: 0.1407062059614464.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:43,027]\u001b[0m Trial 1 finished with value: 0.13463842859370312 and parameters: {'learning_rate': 0.861589497484195, 'num_leaves': 18, 'tree_learner': 'serial'}. Best is trial 1 with value: 0.13463842859370312.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.0917939\tTest's rmse: 0.140706\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tTrain's rmse: 0.151285\tTest's rmse: 0.134638\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001269 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:43,188]\u001b[0m Trial 2 finished with value: 0.12425958651190454 and parameters: {'learning_rate': 0.6232360350085951, 'num_leaves': 41, 'tree_learner': 'data'}. Best is trial 2 with value: 0.12425958651190454.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:43,320]\u001b[0m Trial 3 finished with value: 0.12773111292898143 and parameters: {'learning_rate': 0.6835352886891323, 'num_leaves': 37, 'tree_learner': 'data'}. Best is trial 2 with value: 0.12425958651190454.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[25]\tTrain's rmse: 0.149876\tTest's rmse: 0.12426\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tTrain's rmse: 0.158101\tTest's rmse: 0.127731\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001280 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\tTrain's rmse: 0.154814\tTest's rmse: 0.130013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:43,405]\u001b[0m Trial 4 finished with value: 0.13001347937836724 and parameters: {'learning_rate': 0.44586611361048045, 'num_leaves': 15, 'tree_learner': 'data'}. Best is trial 2 with value: 0.12425958651190454.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:43,551]\u001b[0m Trial 5 finished with value: 0.11786081451359401 and parameters: {'learning_rate': 0.778699073288406, 'num_leaves': 43, 'tree_learner': 'data'}. Best is trial 5 with value: 0.11786081451359401.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001440 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tTrain's rmse: 0.154948\tTest's rmse: 0.117861\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001472 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:43,767]\u001b[0m Trial 6 finished with value: 0.14215414702896673 and parameters: {'learning_rate': 0.26003848582644085, 'num_leaves': 41, 'tree_learner': 'serial'}. Best is trial 5 with value: 0.11786081451359401.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:43,834]\u001b[0m Trial 7 finished with value: 0.1333215889749752 and parameters: {'learning_rate': 0.868752601831233, 'num_leaves': 13, 'tree_learner': 'voting'}. Best is trial 5 with value: 0.11786081451359401.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.117982\tTest's rmse: 0.142154\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tTrain's rmse: 0.120274\tTest's rmse: 0.133322\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tTrain's rmse: 0.158453\tTest's rmse: 0.122039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:43,951]\u001b[0m Trial 8 finished with value: 0.12203940777863719 and parameters: {'learning_rate': 0.6623752220562652, 'num_leaves': 32, 'tree_learner': 'serial'}. Best is trial 5 with value: 0.11786081451359401.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:44,055]\u001b[0m Trial 9 finished with value: 0.12523014975624175 and parameters: {'learning_rate': 0.8373365331149919, 'num_leaves': 35, 'tree_learner': 'serial'}. Best is trial 5 with value: 0.11786081451359401.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001236 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tTrain's rmse: 0.160183\tTest's rmse: 0.12523\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000815 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:44,205]\u001b[0m Trial 10 finished with value: 0.12221307977526273 and parameters: {'learning_rate': 0.4912332640400179, 'num_leaves': 24, 'tree_learner': 'feature'}. Best is trial 5 with value: 0.11786081451359401.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:44,316]\u001b[0m Trial 11 finished with value: 0.13170358620923897 and parameters: {'learning_rate': 0.9910375267497196, 'num_leaves': 29, 'tree_learner': 'voting'}. Best is trial 5 with value: 0.11786081451359401.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[35]\tTrain's rmse: 0.136843\tTest's rmse: 0.122213\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tTrain's rmse: 0.158735\tTest's rmse: 0.131704\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.0635598\tTest's rmse: 0.151427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:44,405]\u001b[0m Trial 12 finished with value: 0.1514270721842119 and parameters: {'learning_rate': 0.7285704027982042, 'num_leaves': 5, 'tree_learner': 'feature'}. Best is trial 5 with value: 0.11786081451359401.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:44,583]\u001b[0m Trial 13 finished with value: 0.13100469250268976 and parameters: {'learning_rate': 0.5548542708761347, 'num_leaves': 48, 'tree_learner': 'data'}. Best is trial 5 with value: 0.11786081451359401.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\tTrain's rmse: 0.143661\tTest's rmse: 0.131005\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000829 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:44,766]\u001b[0m Trial 14 finished with value: 0.1362009362697704 and parameters: {'learning_rate': 0.13716006383895085, 'num_leaves': 30, 'tree_learner': 'serial'}. Best is trial 5 with value: 0.11786081451359401.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.141737\tTest's rmse: 0.136201\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000969 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tTrain's rmse: 0.157765\tTest's rmse: 0.112935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:44,939]\u001b[0m Trial 15 finished with value: 0.11293473408464653 and parameters: {'learning_rate': 0.7627227644950743, 'num_leaves': 44, 'tree_learner': 'data'}. Best is trial 15 with value: 0.11293473408464653.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:45,115]\u001b[0m Trial 16 finished with value: 0.13231418198195063 and parameters: {'learning_rate': 0.99274191042808, 'num_leaves': 44, 'tree_learner': 'data'}. Best is trial 15 with value: 0.11293473408464653.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001278 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tTrain's rmse: 0.151768\tTest's rmse: 0.132314\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001317 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:45,284]\u001b[0m Trial 17 finished with value: 0.11966537996523291 and parameters: {'learning_rate': 0.7734917513404946, 'num_leaves': 45, 'tree_learner': 'data'}. Best is trial 15 with value: 0.11293473408464653.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:45,388]\u001b[0m Trial 18 finished with value: 0.12905758446101012 and parameters: {'learning_rate': 0.5795594833165962, 'num_leaves': 24, 'tree_learner': 'data'}. Best is trial 15 with value: 0.11293473408464653.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[16]\tTrain's rmse: 0.154847\tTest's rmse: 0.119665\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000971 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tTrain's rmse: 0.154992\tTest's rmse: 0.129058\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001396 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:45,591]\u001b[0m Trial 19 finished with value: 0.1323840255597523 and parameters: {'learning_rate': 0.41862843538018224, 'num_leaves': 38, 'tree_learner': 'data'}. Best is trial 15 with value: 0.11293473408464653.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[39]\tTrain's rmse: 0.142122\tTest's rmse: 0.132384\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001315 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:45,794]\u001b[0m Trial 20 finished with value: 0.11813338395822894 and parameters: {'learning_rate': 0.7799748437064135, 'num_leaves': 44, 'tree_learner': 'voting'}. Best is trial 15 with value: 0.11293473408464653.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[16]\tTrain's rmse: 0.15488\tTest's rmse: 0.118133\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:46,009]\u001b[0m Trial 21 finished with value: 0.11760578953519463 and parameters: {'learning_rate': 0.7703996497452739, 'num_leaves': 50, 'tree_learner': 'voting'}. Best is trial 15 with value: 0.11293473408464653.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:46,180]\u001b[0m Trial 22 finished with value: 0.12949253870800936 and parameters: {'learning_rate': 0.912309657728877, 'num_leaves': 50, 'tree_learner': 'voting'}. Best is trial 15 with value: 0.11293473408464653.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[16]\tTrain's rmse: 0.155339\tTest's rmse: 0.117606\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001285 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tTrain's rmse: 0.161795\tTest's rmse: 0.129493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:46,349]\u001b[0m Trial 23 finished with value: 0.11530503544438264 and parameters: {'learning_rate': 0.7444148597193838, 'num_leaves': 41, 'tree_learner': 'voting'}. Best is trial 15 with value: 0.11293473408464653.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001410 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tTrain's rmse: 0.159403\tTest's rmse: 0.115305\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:46,539]\u001b[0m Trial 24 finished with value: 0.1269847195185377 and parameters: {'learning_rate': 0.7035582823035408, 'num_leaves': 46, 'tree_learner': 'voting'}. Best is trial 15 with value: 0.11293473408464653.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[17]\tTrain's rmse: 0.157092\tTest's rmse: 0.126985\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tTrain's rmse: 0.148406\tTest's rmse: 0.120208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:46,750]\u001b[0m Trial 25 finished with value: 0.12020837752983882 and parameters: {'learning_rate': 0.9237562539557627, 'num_leaves': 39, 'tree_learner': 'voting'}. Best is trial 15 with value: 0.11293473408464653.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:46,903]\u001b[0m Trial 26 finished with value: 0.12634815552516676 and parameters: {'learning_rate': 0.6255901008213995, 'num_leaves': 34, 'tree_learner': 'voting'}. Best is trial 15 with value: 0.11293473408464653.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tTrain's rmse: 0.161011\tTest's rmse: 0.126348\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:47,090]\u001b[0m Trial 27 finished with value: 0.12926883119165208 and parameters: {'learning_rate': 0.8220475015647036, 'num_leaves': 50, 'tree_learner': 'voting'}. Best is trial 15 with value: 0.11293473408464653.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[10]\tTrain's rmse: 0.168606\tTest's rmse: 0.129269\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:47,284]\u001b[0m Trial 28 finished with value: 0.12978837885105265 and parameters: {'learning_rate': 0.7326660983178542, 'num_leaves': 47, 'tree_learner': 'feature'}. Best is trial 15 with value: 0.11293473408464653.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[17]\tTrain's rmse: 0.156843\tTest's rmse: 0.129788\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001307 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:47,531]\u001b[0m Trial 29 finished with value: 0.1365862135896373 and parameters: {'learning_rate': 0.34901383536150155, 'num_leaves': 42, 'tree_learner': 'voting'}. Best is trial 15 with value: 0.11293473408464653.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[44]\tTrain's rmse: 0.149065\tTest's rmse: 0.136586\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001230 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:47,738]\u001b[0m Trial 30 finished with value: 0.13255644339141687 and parameters: {'learning_rate': 0.9246233471296312, 'num_leaves': 47, 'tree_learner': 'voting'}. Best is trial 15 with value: 0.11293473408464653.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[10]\tTrain's rmse: 0.164619\tTest's rmse: 0.132556\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001526 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tTrain's rmse: 0.158503\tTest's rmse: 0.113247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:47,932]\u001b[0m Trial 31 finished with value: 0.1132467423719509 and parameters: {'learning_rate': 0.7449681293305123, 'num_leaves': 42, 'tree_learner': 'data'}. Best is trial 15 with value: 0.11293473408464653.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:48,121]\u001b[0m Trial 32 finished with value: 0.12841402396110985 and parameters: {'learning_rate': 0.6338825211113063, 'num_leaves': 39, 'tree_learner': 'data'}. Best is trial 15 with value: 0.11293473408464653.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\tTrain's rmse: 0.140948\tTest's rmse: 0.128414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:48,280]\u001b[0m Trial 33 finished with value: 0.12926937680692493 and parameters: {'learning_rate': 0.8100691645609177, 'num_leaves': 41, 'tree_learner': 'data'}. Best is trial 15 with value: 0.11293473408464653.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001211 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tTrain's rmse: 0.168045\tTest's rmse: 0.129269\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001245 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:48,435]\u001b[0m Trial 34 finished with value: 0.1250518488323528 and parameters: {'learning_rate': 0.7236994013574438, 'num_leaves': 36, 'tree_learner': 'feature'}. Best is trial 15 with value: 0.11293473408464653.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[20]\tTrain's rmse: 0.153156\tTest's rmse: 0.125052\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:48,621]\u001b[0m Trial 35 finished with value: 0.12337344394724824 and parameters: {'learning_rate': 0.8774405909253327, 'num_leaves': 50, 'tree_learner': 'data'}. Best is trial 15 with value: 0.11293473408464653.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[14]\tTrain's rmse: 0.159888\tTest's rmse: 0.123373\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001353 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:48,863]\u001b[0m Trial 36 finished with value: 0.1220318168899253 and parameters: {'learning_rate': 0.49934603496312485, 'num_leaves': 47, 'tree_learner': 'voting'}. Best is trial 15 with value: 0.11293473408464653.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:48,994]\u001b[0m Trial 37 finished with value: 0.1315470388591077 and parameters: {'learning_rate': 0.5930560305874755, 'num_leaves': 41, 'tree_learner': 'data'}. Best is trial 15 with value: 0.11293473408464653.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[33]\tTrain's rmse: 0.140344\tTest's rmse: 0.122032\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001125 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tTrain's rmse: 0.158927\tTest's rmse: 0.131547\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000837 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:49,158]\u001b[0m Trial 38 finished with value: 0.12517290919423765 and parameters: {'learning_rate': 0.671921793204591, 'num_leaves': 33, 'tree_learner': 'data'}. Best is trial 15 with value: 0.11293473408464653.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:49,286]\u001b[0m Trial 39 finished with value: 0.113399914476715 and parameters: {'learning_rate': 0.7696212404945756, 'num_leaves': 26, 'tree_learner': 'voting'}. Best is trial 15 with value: 0.11293473408464653.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[15]\tTrain's rmse: 0.163388\tTest's rmse: 0.125173\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001243 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tTrain's rmse: 0.157723\tTest's rmse: 0.1134\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:49,423]\u001b[0m Trial 40 finished with value: 0.11748596148877954 and parameters: {'learning_rate': 0.6687489312388857, 'num_leaves': 26, 'tree_learner': 'serial'}. Best is trial 15 with value: 0.11293473408464653.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:49,549]\u001b[0m Trial 41 finished with value: 0.11825189213385003 and parameters: {'learning_rate': 0.6545948062373959, 'num_leaves': 25, 'tree_learner': 'serial'}. Best is trial 15 with value: 0.11293473408464653.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[21]\tTrain's rmse: 0.154919\tTest's rmse: 0.117486\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tTrain's rmse: 0.15669\tTest's rmse: 0.118252\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001289 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:49,677]\u001b[0m Trial 42 finished with value: 0.11838848316471129 and parameters: {'learning_rate': 0.6991475070795753, 'num_leaves': 20, 'tree_learner': 'serial'}. Best is trial 15 with value: 0.11293473408464653.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:49,795]\u001b[0m Trial 43 finished with value: 0.1285336291798079 and parameters: {'learning_rate': 0.7541388043693732, 'num_leaves': 20, 'tree_learner': 'serial'}. Best is trial 15 with value: 0.11293473408464653.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[17]\tTrain's rmse: 0.158769\tTest's rmse: 0.118388\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tTrain's rmse: 0.144714\tTest's rmse: 0.128534\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:49,935]\u001b[0m Trial 44 finished with value: 0.11277713134401189 and parameters: {'learning_rate': 0.8336026480781311, 'num_leaves': 27, 'tree_learner': 'serial'}. Best is trial 44 with value: 0.11277713134401189.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:50,073]\u001b[0m Trial 45 finished with value: 0.12459830983403025 and parameters: {'learning_rate': 0.8603871176237321, 'num_leaves': 32, 'tree_learner': 'serial'}. Best is trial 44 with value: 0.11277713134401189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[21]\tTrain's rmse: 0.12655\tTest's rmse: 0.112777\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001283 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tTrain's rmse: 0.157967\tTest's rmse: 0.124598\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:50,220]\u001b[0m Trial 46 finished with value: 0.1217634461775816 and parameters: {'learning_rate': 0.8098830252166347, 'num_leaves': 29, 'tree_learner': 'feature'}. Best is trial 44 with value: 0.11277713134401189.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:50,304]\u001b[0m Trial 47 finished with value: 0.13370948717372066 and parameters: {'learning_rate': 0.891036644847591, 'num_leaves': 16, 'tree_learner': 'data'}. Best is trial 44 with value: 0.11277713134401189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[28]\tTrain's rmse: 0.132704\tTest's rmse: 0.121763\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001022 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tTrain's rmse: 0.173069\tTest's rmse: 0.133709\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:50,427]\u001b[0m Trial 48 finished with value: 0.13426189631494811 and parameters: {'learning_rate': 0.9389065501690411, 'num_leaves': 21, 'tree_learner': 'serial'}. Best is trial 44 with value: 0.11277713134401189.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:50,561]\u001b[0m Trial 49 finished with value: 0.12484819833565945 and parameters: {'learning_rate': 0.9616649215338837, 'num_leaves': 27, 'tree_learner': 'voting'}. Best is trial 44 with value: 0.11277713134401189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[8]\tTrain's rmse: 0.170802\tTest's rmse: 0.134262\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001204 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tTrain's rmse: 0.160281\tTest's rmse: 0.124848\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001307 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:50,623]\u001b[0m Trial 50 finished with value: 0.14757383473035396 and parameters: {'learning_rate': 0.8508312599619721, 'num_leaves': 12, 'tree_learner': 'data'}. Best is trial 44 with value: 0.11277713134401189.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:50,746]\u001b[0m Trial 51 finished with value: 0.11827791792470987 and parameters: {'learning_rate': 0.7935966489809788, 'num_leaves': 23, 'tree_learner': 'serial'}. Best is trial 44 with value: 0.11277713134401189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[11]\tTrain's rmse: 0.155531\tTest's rmse: 0.147574\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001085 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tTrain's rmse: 0.160988\tTest's rmse: 0.118278\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:50,871]\u001b[0m Trial 52 finished with value: 0.11705549175995708 and parameters: {'learning_rate': 0.738043739624357, 'num_leaves': 26, 'tree_learner': 'serial'}. Best is trial 44 with value: 0.11277713134401189.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:51,001]\u001b[0m Trial 53 finished with value: 0.1281179418138006 and parameters: {'learning_rate': 0.8431297352079281, 'num_leaves': 30, 'tree_learner': 'serial'}. Best is trial 44 with value: 0.11277713134401189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[21]\tTrain's rmse: 0.149496\tTest's rmse: 0.117055\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001018 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tTrain's rmse: 0.163459\tTest's rmse: 0.128118\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001029 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:51,116]\u001b[0m Trial 54 finished with value: 0.11885930073386515 and parameters: {'learning_rate': 0.7380746933581477, 'num_leaves': 28, 'tree_learner': 'serial'}. Best is trial 44 with value: 0.11277713134401189.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:51,277]\u001b[0m Trial 55 finished with value: 0.1280161697046887 and parameters: {'learning_rate': 0.7028151913740502, 'num_leaves': 36, 'tree_learner': 'serial'}. Best is trial 44 with value: 0.11277713134401189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[15]\tTrain's rmse: 0.158051\tTest's rmse: 0.118859\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tTrain's rmse: 0.157252\tTest's rmse: 0.128016\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:51,400]\u001b[0m Trial 56 finished with value: 0.13593973363192635 and parameters: {'learning_rate': 0.7834099804314406, 'num_leaves': 22, 'tree_learner': 'data'}. Best is trial 44 with value: 0.11277713134401189.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:51,568]\u001b[0m Trial 57 finished with value: 0.12491172110137805 and parameters: {'learning_rate': 0.5159242556320527, 'num_leaves': 31, 'tree_learner': 'voting'}. Best is trial 44 with value: 0.11277713134401189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[14]\tTrain's rmse: 0.160996\tTest's rmse: 0.13594\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\tTrain's rmse: 0.143388\tTest's rmse: 0.124912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:51,742]\u001b[0m Trial 58 finished with value: 0.11528016776757179 and parameters: {'learning_rate': 0.7553323712409123, 'num_leaves': 43, 'tree_learner': 'serial'}. Best is trial 44 with value: 0.11277713134401189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tTrain's rmse: 0.15799\tTest's rmse: 0.11528\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001273 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:52,032]\u001b[0m Trial 59 finished with value: 0.14075899029366068 and parameters: {'learning_rate': 0.11571385840747667, 'num_leaves': 45, 'tree_learner': 'voting'}. Best is trial 44 with value: 0.11277713134401189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.149917\tTest's rmse: 0.140759\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001523 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:52,257]\u001b[0m Trial 60 finished with value: 0.123278098815594 and parameters: {'learning_rate': 0.6026178866717278, 'num_leaves': 43, 'tree_learner': 'feature'}. Best is trial 44 with value: 0.11277713134401189.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:52,412]\u001b[0m Trial 61 finished with value: 0.11506787050141455 and parameters: {'learning_rate': 0.7480012888231714, 'num_leaves': 39, 'tree_learner': 'serial'}. Best is trial 44 with value: 0.11277713134401189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[27]\tTrain's rmse: 0.143603\tTest's rmse: 0.123278\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001264 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tTrain's rmse: 0.159381\tTest's rmse: 0.115068\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:52,597]\u001b[0m Trial 62 finished with value: 0.11427954801596472 and parameters: {'learning_rate': 0.7602190397417673, 'num_leaves': 38, 'tree_learner': 'serial'}. Best is trial 44 with value: 0.11277713134401189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tTrain's rmse: 0.152996\tTest's rmse: 0.11428\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:52,780]\u001b[0m Trial 63 finished with value: 0.12018303277562678 and parameters: {'learning_rate': 0.8047669582846658, 'num_leaves': 37, 'tree_learner': 'serial'}. Best is trial 44 with value: 0.11277713134401189.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:52,942]\u001b[0m Trial 64 finished with value: 0.11616414975104458 and parameters: {'learning_rate': 0.7652276181350471, 'num_leaves': 39, 'tree_learner': 'serial'}. Best is trial 44 with value: 0.11277713134401189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tTrain's rmse: 0.153231\tTest's rmse: 0.120183\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001325 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tTrain's rmse: 0.154763\tTest's rmse: 0.116164\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001222 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:53,137]\u001b[0m Trial 65 finished with value: 0.12615195385787262 and parameters: {'learning_rate': 0.8985246502532934, 'num_leaves': 43, 'tree_learner': 'serial'}. Best is trial 44 with value: 0.11277713134401189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tTrain's rmse: 0.16052\tTest's rmse: 0.126152\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001289 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:53,407]\u001b[0m Trial 66 finished with value: 0.13858275726482394 and parameters: {'learning_rate': 0.20151693481990696, 'num_leaves': 39, 'tree_learner': 'serial'}. Best is trial 44 with value: 0.11277713134401189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.14037\tTest's rmse: 0.138583\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001033 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tTrain's rmse: 0.155039\tTest's rmse: 0.123903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:53,576]\u001b[0m Trial 67 finished with value: 0.12390253695962751 and parameters: {'learning_rate': 0.8210265894779499, 'num_leaves': 34, 'tree_learner': 'serial'}. Best is trial 44 with value: 0.11277713134401189.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:53,743]\u001b[0m Trial 68 finished with value: 0.12784439286061197 and parameters: {'learning_rate': 0.6979655126330523, 'num_leaves': 45, 'tree_learner': 'serial'}. Best is trial 44 with value: 0.11277713134401189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tTrain's rmse: 0.15749\tTest's rmse: 0.127844\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001060 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:53,975]\u001b[0m Trial 69 finished with value: 0.12837368371051677 and parameters: {'learning_rate': 0.6399165438650414, 'num_leaves': 40, 'tree_learner': 'data'}. Best is trial 44 with value: 0.11277713134401189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[30]\tTrain's rmse: 0.13012\tTest's rmse: 0.128374\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001489 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tTrain's rmse: 0.168191\tTest's rmse: 0.129557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:54,155]\u001b[0m Trial 70 finished with value: 0.12955731287499034 and parameters: {'learning_rate': 0.8320180114679984, 'num_leaves': 48, 'tree_learner': 'serial'}. Best is trial 44 with value: 0.11277713134401189.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:54,349]\u001b[0m Trial 71 finished with value: 0.11389539002307376 and parameters: {'learning_rate': 0.7636292572500443, 'num_leaves': 42, 'tree_learner': 'voting'}. Best is trial 44 with value: 0.11277713134401189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001343 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tTrain's rmse: 0.157567\tTest's rmse: 0.113895\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001911 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:54,553]\u001b[0m Trial 72 finished with value: 0.11736669796561273 and parameters: {'learning_rate': 0.7719828897143309, 'num_leaves': 42, 'tree_learner': 'voting'}. Best is trial 44 with value: 0.11277713134401189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tTrain's rmse: 0.154919\tTest's rmse: 0.117367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:54,752]\u001b[0m Trial 73 finished with value: 0.1248621437688727 and parameters: {'learning_rate': 0.7184990374167974, 'num_leaves': 44, 'tree_learner': 'data'}. Best is trial 44 with value: 0.11277713134401189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001903 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tTrain's rmse: 0.15333\tTest's rmse: 0.124862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:54,898]\u001b[0m Trial 74 finished with value: 0.11341548662857108 and parameters: {'learning_rate': 0.755868807771214, 'num_leaves': 37, 'tree_learner': 'voting'}. Best is trial 44 with value: 0.11277713134401189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tTrain's rmse: 0.157858\tTest's rmse: 0.113415\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001216 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:55,054]\u001b[0m Trial 75 finished with value: 0.12732304136833278 and parameters: {'learning_rate': 0.6854486703055502, 'num_leaves': 37, 'tree_learner': 'voting'}. Best is trial 44 with value: 0.11277713134401189.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:55,216]\u001b[0m Trial 76 finished with value: 0.12692794541076285 and parameters: {'learning_rate': 0.8662068406831511, 'num_leaves': 40, 'tree_learner': 'voting'}. Best is trial 44 with value: 0.11277713134401189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[17]\tTrain's rmse: 0.157881\tTest's rmse: 0.127323\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tTrain's rmse: 0.16171\tTest's rmse: 0.126928\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:55,362]\u001b[0m Trial 77 finished with value: 0.12045477151446227 and parameters: {'learning_rate': 0.7867067264353457, 'num_leaves': 35, 'tree_learner': 'voting'}. Best is trial 44 with value: 0.11277713134401189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[16]\tTrain's rmse: 0.153029\tTest's rmse: 0.120455\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001105 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tTrain's rmse: 0.162911\tTest's rmse: 0.122386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:55,552]\u001b[0m Trial 78 finished with value: 0.12238585315658662 and parameters: {'learning_rate': 0.5634714440312429, 'num_leaves': 42, 'tree_learner': 'voting'}. Best is trial 44 with value: 0.11277713134401189.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:55,712]\u001b[0m Trial 79 finished with value: 0.11320295173073491 and parameters: {'learning_rate': 0.7186170492265543, 'num_leaves': 33, 'tree_learner': 'data'}. Best is trial 44 with value: 0.11277713134401189.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001122 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tTrain's rmse: 0.153534\tTest's rmse: 0.113203\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:55,868]\u001b[0m Trial 80 finished with value: 0.10749593802589563 and parameters: {'learning_rate': 0.723383566622474, 'num_leaves': 33, 'tree_learner': 'data'}. Best is trial 80 with value: 0.10749593802589563.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:22:56,023]\u001b[0m Trial 81 finished with value: 0.1156280958378486 and parameters: {'learning_rate': 0.7104138337407562, 'num_leaves': 31, 'tree_learner': 'data'}. Best is trial 80 with value: 0.10749593802589563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[22]\tTrain's rmse: 0.149332\tTest's rmse: 0.107496\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tTrain's rmse: 0.157402\tTest's rmse: 0.115628\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001120 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:56,177]\u001b[0m Trial 82 finished with value: 0.12107011919633127 and parameters: {'learning_rate': 0.7989465296774588, 'num_leaves': 33, 'tree_learner': 'data'}. Best is trial 80 with value: 0.10749593802589563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tTrain's rmse: 0.152977\tTest's rmse: 0.12107\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001274 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:56,353]\u001b[0m Trial 83 finished with value: 0.12995972673425804 and parameters: {'learning_rate': 0.82802756750284, 'num_leaves': 35, 'tree_learner': 'data'}. Best is trial 80 with value: 0.10749593802589563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tTrain's rmse: 0.165013\tTest's rmse: 0.12996\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001318 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:56,594]\u001b[0m Trial 84 finished with value: 0.1181010080810937 and parameters: {'learning_rate': 0.6642404416348314, 'num_leaves': 28, 'tree_learner': 'data'}. Best is trial 80 with value: 0.10749593802589563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[17]\tTrain's rmse: 0.159929\tTest's rmse: 0.118101\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:57,003]\u001b[0m Trial 85 finished with value: 0.13449611139495368 and parameters: {'learning_rate': 0.4285222129595001, 'num_leaves': 38, 'tree_learner': 'data'}. Best is trial 80 with value: 0.10749593802589563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[37]\tTrain's rmse: 0.144555\tTest's rmse: 0.134496\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:57,230]\u001b[0m Trial 86 finished with value: 0.11566042312038466 and parameters: {'learning_rate': 0.7204143969668874, 'num_leaves': 25, 'tree_learner': 'data'}. Best is trial 80 with value: 0.10749593802589563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[17]\tTrain's rmse: 0.157761\tTest's rmse: 0.11566\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001260 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:57,507]\u001b[0m Trial 87 finished with value: 0.1269822417322277 and parameters: {'learning_rate': 0.685571090584353, 'num_leaves': 33, 'tree_learner': 'data'}. Best is trial 80 with value: 0.10749593802589563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[17]\tTrain's rmse: 0.158138\tTest's rmse: 0.126982\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:57,805]\u001b[0m Trial 88 finished with value: 0.11507315763513794 and parameters: {'learning_rate': 0.7692517678726754, 'num_leaves': 36, 'tree_learner': 'data'}. Best is trial 80 with value: 0.10749593802589563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[17]\tTrain's rmse: 0.154939\tTest's rmse: 0.115073\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:58,120]\u001b[0m Trial 89 finished with value: 0.12407487213176958 and parameters: {'learning_rate': 0.6090308730586219, 'num_leaves': 30, 'tree_learner': 'voting'}. Best is trial 80 with value: 0.10749593802589563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[28]\tTrain's rmse: 0.143439\tTest's rmse: 0.124075\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001442 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:58,372]\u001b[0m Trial 90 finished with value: 0.12258597542279767 and parameters: {'learning_rate': 0.8844496156431635, 'num_leaves': 38, 'tree_learner': 'feature'}. Best is trial 80 with value: 0.10749593802589563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[8]\tTrain's rmse: 0.168443\tTest's rmse: 0.122586\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001411 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:58,733]\u001b[0m Trial 91 finished with value: 0.11650737648037753 and parameters: {'learning_rate': 0.7470499075035039, 'num_leaves': 40, 'tree_learner': 'data'}. Best is trial 80 with value: 0.10749593802589563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[26]\tTrain's rmse: 0.142309\tTest's rmse: 0.116507\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:59,053]\u001b[0m Trial 92 finished with value: 0.10861826914583159 and parameters: {'learning_rate': 0.7342000296164439, 'num_leaves': 37, 'tree_learner': 'voting'}. Best is trial 80 with value: 0.10749593802589563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[22]\tTrain's rmse: 0.148675\tTest's rmse: 0.108618\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:59,357]\u001b[0m Trial 93 finished with value: 0.12957028780854904 and parameters: {'learning_rate': 0.7300105178083541, 'num_leaves': 37, 'tree_learner': 'voting'}. Best is trial 80 with value: 0.10749593802589563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[17]\tTrain's rmse: 0.157005\tTest's rmse: 0.12957\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:59,618]\u001b[0m Trial 94 finished with value: 0.11823008329240497 and parameters: {'learning_rate': 0.7909939079557516, 'num_leaves': 32, 'tree_learner': 'voting'}. Best is trial 80 with value: 0.10749593802589563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[15]\tTrain's rmse: 0.15722\tTest's rmse: 0.11823\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001123 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:22:59,830]\u001b[0m Trial 95 finished with value: 0.12121373929333977 and parameters: {'learning_rate': 0.6420316745415114, 'num_leaves': 29, 'tree_learner': 'voting'}. Best is trial 80 with value: 0.10749593802589563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tTrain's rmse: 0.160161\tTest's rmse: 0.121214\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000876 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:00,043]\u001b[0m Trial 96 finished with value: 0.12719330534620785 and parameters: {'learning_rate': 0.8083771884855344, 'num_leaves': 34, 'tree_learner': 'voting'}. Best is trial 80 with value: 0.10749593802589563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[6]\tTrain's rmse: 0.184776\tTest's rmse: 0.127193\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001216 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:00,277]\u001b[0m Trial 97 finished with value: 0.11324751631264654 and parameters: {'learning_rate': 0.7575945661189829, 'num_leaves': 26, 'tree_learner': 'voting'}. Best is trial 80 with value: 0.10749593802589563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[19]\tTrain's rmse: 0.153294\tTest's rmse: 0.113248\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:00,515]\u001b[0m Trial 98 finished with value: 0.11527543041914724 and parameters: {'learning_rate': 0.8521767236675343, 'num_leaves': 26, 'tree_learner': 'voting'}. Best is trial 80 with value: 0.10749593802589563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[29]\tTrain's rmse: 0.110066\tTest's rmse: 0.115275\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:00,722]\u001b[0m Trial 99 finished with value: 0.11537706011218983 and parameters: {'learning_rate': 0.6974553027608681, 'num_leaves': 25, 'tree_learner': 'voting'}. Best is trial 80 with value: 0.10749593802589563.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[21]\tTrain's rmse: 0.153892\tTest's rmse: 0.115377\n",
      "{'learning_rate': 0.723383566622474, 'num_leaves': 33, 'tree_learner': 'data'}\n",
      "{'learning_rate': 0.723383566622474, 'num_leaves': 33, 'tree_learner': 'data', 'objective': 'regression', 'metric': 'rmse', 'task': 'train', 'seed': 42}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001226 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 10965, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 0.383112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\tTrain's rmse: 0.149332\tTest's rmse: 0.107496\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:01,214]\u001b[0m A new study created in memory with name: no-name-600d3cfd-bb09-485c-aa33-293f9debdf75\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:01,374]\u001b[0m Trial 0 finished with value: 0.023273978758332682 and parameters: {'learning_rate': 0.20765510304548548, 'num_leaves': 9, 'tree_learner': 'data'}. Best is trial 0 with value: 0.023273978758332682.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001278 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tTrain's rmse: 0.162744\tTest's rmse: 0.023274\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:01,542]\u001b[0m Trial 1 finished with value: 0.026493111760182632 and parameters: {'learning_rate': 0.6955521364524527, 'num_leaves': 20, 'tree_learner': 'data'}. Best is trial 0 with value: 0.023273978758332682.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:01,713]\u001b[0m Trial 2 finished with value: 0.026590964766617427 and parameters: {'learning_rate': 0.6982380155127281, 'num_leaves': 27, 'tree_learner': 'data'}. Best is trial 0 with value: 0.023273978758332682.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[10]\tTrain's rmse: 0.165241\tTest's rmse: 0.0264931\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001488 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tTrain's rmse: 0.173212\tTest's rmse: 0.026591\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:02,029]\u001b[0m Trial 3 finished with value: 0.02325154852888797 and parameters: {'learning_rate': 0.5140594685341867, 'num_leaves': 46, 'tree_learner': 'data'}. Best is trial 3 with value: 0.02325154852888797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[10]\tTrain's rmse: 0.160577\tTest's rmse: 0.0232515\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:02,251]\u001b[0m Trial 4 finished with value: 0.031244568534553215 and parameters: {'learning_rate': 0.9020439854837975, 'num_leaves': 39, 'tree_learner': 'data'}. Best is trial 3 with value: 0.02325154852888797.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:02,338]\u001b[0m Trial 5 finished with value: 0.039925417530635804 and parameters: {'learning_rate': 0.39443637626866, 'num_leaves': 6, 'tree_learner': 'feature'}. Best is trial 3 with value: 0.02325154852888797.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:02,425]\u001b[0m Trial 6 finished with value: 0.03465930995473229 and parameters: {'learning_rate': 0.5558265355326605, 'num_leaves': 7, 'tree_learner': 'data'}. Best is trial 3 with value: 0.02325154852888797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[2]\tTrain's rmse: 0.193778\tTest's rmse: 0.0312446\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000663 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tTrain's rmse: 0.138833\tTest's rmse: 0.0399254\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000710 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\tTrain's rmse: 0.143242\tTest's rmse: 0.0346593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:02,568]\u001b[0m Trial 7 finished with value: 0.02957293632272744 and parameters: {'learning_rate': 0.47640194206904585, 'num_leaves': 23, 'tree_learner': 'voting'}. Best is trial 3 with value: 0.02325154852888797.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001635 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tTrain's rmse: 0.174824\tTest's rmse: 0.0295729\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001195 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:02,802]\u001b[0m Trial 8 finished with value: 0.0218563832810307 and parameters: {'learning_rate': 0.23162344439430566, 'num_leaves': 34, 'tree_learner': 'voting'}. Best is trial 8 with value: 0.0218563832810307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[20]\tTrain's rmse: 0.168562\tTest's rmse: 0.0218564\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:03,005]\u001b[0m Trial 9 finished with value: 0.022165469252533137 and parameters: {'learning_rate': 0.1355971715513618, 'num_leaves': 21, 'tree_learner': 'voting'}. Best is trial 8 with value: 0.0218563832810307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[29]\tTrain's rmse: 0.168603\tTest's rmse: 0.0221655\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000846 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:03,306]\u001b[0m Trial 10 finished with value: 0.023963383682300964 and parameters: {'learning_rate': 0.295756284317756, 'num_leaves': 37, 'tree_learner': 'serial'}. Best is trial 8 with value: 0.0218563832810307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[17]\tTrain's rmse: 0.174843\tTest's rmse: 0.0239634\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001979 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:03,665]\u001b[0m Trial 11 finished with value: 0.022107916759179662 and parameters: {'learning_rate': 0.10873272354224335, 'num_leaves': 33, 'tree_learner': 'voting'}. Best is trial 8 with value: 0.0218563832810307.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[44]\tTrain's rmse: 0.163654\tTest's rmse: 0.0221079\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000921 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:04,019]\u001b[0m Trial 12 finished with value: 0.020868091107132475 and parameters: {'learning_rate': 0.10180240007144567, 'num_leaves': 35, 'tree_learner': 'voting'}. Best is trial 12 with value: 0.020868091107132475.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[46]\tTrain's rmse: 0.164654\tTest's rmse: 0.0208681\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000858 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:04,347]\u001b[0m Trial 13 finished with value: 0.023930063556336912 and parameters: {'learning_rate': 0.2890142391033489, 'num_leaves': 46, 'tree_learner': 'voting'}. Best is trial 12 with value: 0.020868091107132475.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[13]\tTrain's rmse: 0.169153\tTest's rmse: 0.0239301\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:04,597]\u001b[0m Trial 14 finished with value: 0.025912841741850257 and parameters: {'learning_rate': 0.2297500496425574, 'num_leaves': 32, 'tree_learner': 'voting'}. Best is trial 12 with value: 0.020868091107132475.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tTrain's rmse: 0.163421\tTest's rmse: 0.0259128\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001278 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:04,873]\u001b[0m Trial 15 finished with value: 0.02804789551116757 and parameters: {'learning_rate': 0.37577471765170267, 'num_leaves': 41, 'tree_learner': 'feature'}. Best is trial 12 with value: 0.020868091107132475.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[11]\tTrain's rmse: 0.167378\tTest's rmse: 0.0280479\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:05,177]\u001b[0m Trial 16 finished with value: 0.0220932146367158 and parameters: {'learning_rate': 0.10611230532041943, 'num_leaves': 31, 'tree_learner': 'serial'}. Best is trial 12 with value: 0.020868091107132475.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[40]\tTrain's rmse: 0.166491\tTest's rmse: 0.0220932\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001228 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:05,533]\u001b[0m Trial 17 finished with value: 0.02128820789607295 and parameters: {'learning_rate': 0.22210549107589744, 'num_leaves': 50, 'tree_learner': 'voting'}. Best is trial 12 with value: 0.020868091107132475.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[19]\tTrain's rmse: 0.166152\tTest's rmse: 0.0212882\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:05,848]\u001b[0m Trial 18 finished with value: 0.026046935564147937 and parameters: {'learning_rate': 0.37703734448197723, 'num_leaves': 49, 'tree_learner': 'voting'}. Best is trial 12 with value: 0.020868091107132475.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:05,981]\u001b[0m Trial 19 finished with value: 0.03250141153281227 and parameters: {'learning_rate': 0.9170048243004578, 'num_leaves': 14, 'tree_learner': 'voting'}. Best is trial 12 with value: 0.020868091107132475.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[16]\tTrain's rmse: 0.164615\tTest's rmse: 0.0260469\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001826 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tTrain's rmse: 0.165605\tTest's rmse: 0.0325014\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:06,259]\u001b[0m Trial 20 finished with value: 0.025934129591497955 and parameters: {'learning_rate': 0.6768680520207438, 'num_leaves': 43, 'tree_learner': 'feature'}. Best is trial 12 with value: 0.020868091107132475.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[4]\tTrain's rmse: 0.180786\tTest's rmse: 0.0259341\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001703 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:06,559]\u001b[0m Trial 21 finished with value: 0.02112087336772345 and parameters: {'learning_rate': 0.2058554794954884, 'num_leaves': 35, 'tree_learner': 'voting'}. Best is trial 12 with value: 0.020868091107132475.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[22]\tTrain's rmse: 0.166363\tTest's rmse: 0.0211209\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000600 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:06,929]\u001b[0m Trial 22 finished with value: 0.021548378013716143 and parameters: {'learning_rate': 0.21232924950166265, 'num_leaves': 50, 'tree_learner': 'voting'}. Best is trial 12 with value: 0.020868091107132475.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[20]\tTrain's rmse: 0.169234\tTest's rmse: 0.0215484\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001339 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:07,153]\u001b[0m Trial 23 finished with value: 0.02473460266713057 and parameters: {'learning_rate': 0.30537002264027124, 'num_leaves': 26, 'tree_learner': 'voting'}. Best is trial 12 with value: 0.020868091107132475.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[14]\tTrain's rmse: 0.169889\tTest's rmse: 0.0247346\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000877 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:07,449]\u001b[0m Trial 24 finished with value: 0.020802969532363515 and parameters: {'learning_rate': 0.16925180616783098, 'num_leaves': 37, 'tree_learner': 'serial'}. Best is trial 24 with value: 0.020802969532363515.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[27]\tTrain's rmse: 0.167538\tTest's rmse: 0.020803\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001317 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:07,782]\u001b[0m Trial 25 finished with value: 0.023741206914690123 and parameters: {'learning_rate': 0.1509086077456351, 'num_leaves': 36, 'tree_learner': 'serial'}. Best is trial 24 with value: 0.020802969532363515.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[26]\tTrain's rmse: 0.1672\tTest's rmse: 0.0237412\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001272 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:08,068]\u001b[0m Trial 26 finished with value: 0.02130202440358876 and parameters: {'learning_rate': 0.1684358844212746, 'num_leaves': 30, 'tree_learner': 'serial'}. Best is trial 24 with value: 0.020802969532363515.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[29]\tTrain's rmse: 0.1736\tTest's rmse: 0.021302\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001319 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:08,326]\u001b[0m Trial 27 finished with value: 0.02078244450868839 and parameters: {'learning_rate': 0.43612169629680786, 'num_leaves': 39, 'tree_learner': 'serial'}. Best is trial 27 with value: 0.02078244450868839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[9]\tTrain's rmse: 0.16998\tTest's rmse: 0.0207824\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:08,579]\u001b[0m Trial 28 finished with value: 0.028509643306802508 and parameters: {'learning_rate': 0.8193745941990029, 'num_leaves': 42, 'tree_learner': 'serial'}. Best is trial 27 with value: 0.02078244450868839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[5]\tTrain's rmse: 0.181497\tTest's rmse: 0.0285096\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001431 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:08,811]\u001b[0m Trial 29 finished with value: 0.02584814321104962 and parameters: {'learning_rate': 0.6156887601319012, 'num_leaves': 38, 'tree_learner': 'serial'}. Best is trial 27 with value: 0.02078244450868839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[8]\tTrain's rmse: 0.166051\tTest's rmse: 0.0258481\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001297 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:09,082]\u001b[0m Trial 30 finished with value: 0.02766624027340042 and parameters: {'learning_rate': 0.4478855865864253, 'num_leaves': 44, 'tree_learner': 'serial'}. Best is trial 27 with value: 0.02078244450868839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[9]\tTrain's rmse: 0.168326\tTest's rmse: 0.0276662\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:09,361]\u001b[0m Trial 31 finished with value: 0.022954965521181984 and parameters: {'learning_rate': 0.3065318475696055, 'num_leaves': 35, 'tree_learner': 'serial'}. Best is trial 27 with value: 0.02078244450868839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[14]\tTrain's rmse: 0.16502\tTest's rmse: 0.022955\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:09,719]\u001b[0m Trial 32 finished with value: 0.0224233728384791 and parameters: {'learning_rate': 0.17856748651287227, 'num_leaves': 39, 'tree_learner': 'serial'}. Best is trial 27 with value: 0.02078244450868839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[27]\tTrain's rmse: 0.16184\tTest's rmse: 0.0224234\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001356 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tTrain's rmse: 0.169583\tTest's rmse: 0.0237261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:09,932]\u001b[0m Trial 33 finished with value: 0.023726116119170013 and parameters: {'learning_rate': 0.2668243960090811, 'num_leaves': 28, 'tree_learner': 'serial'}. Best is trial 27 with value: 0.02078244450868839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000992 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:10,222]\u001b[0m Trial 34 finished with value: 0.022382380402958972 and parameters: {'learning_rate': 0.43549348990472037, 'num_leaves': 40, 'tree_learner': 'feature'}. Best is trial 27 with value: 0.02078244450868839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[10]\tTrain's rmse: 0.168605\tTest's rmse: 0.0223824\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001294 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:10,455]\u001b[0m Trial 35 finished with value: 0.024469039288834465 and parameters: {'learning_rate': 0.3449422453230468, 'num_leaves': 25, 'tree_learner': 'data'}. Best is trial 27 with value: 0.02078244450868839.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:10,586]\u001b[0m Trial 36 finished with value: 0.03232776679034261 and parameters: {'learning_rate': 0.7885706731352073, 'num_leaves': 14, 'tree_learner': 'serial'}. Best is trial 27 with value: 0.02078244450868839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[17]\tTrain's rmse: 0.154693\tTest's rmse: 0.024469\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001301 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tTrain's rmse: 0.169995\tTest's rmse: 0.0323278\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000846 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:10,819]\u001b[0m Trial 37 finished with value: 0.0216923431443874 and parameters: {'learning_rate': 0.5524664379274691, 'num_leaves': 29, 'tree_learner': 'data'}. Best is trial 27 with value: 0.02078244450868839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[7]\tTrain's rmse: 0.17478\tTest's rmse: 0.0216923\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001939 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:11,162]\u001b[0m Trial 38 finished with value: 0.02166018125819199 and parameters: {'learning_rate': 0.18056027288313758, 'num_leaves': 36, 'tree_learner': 'voting'}. Best is trial 27 with value: 0.02078244450868839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tTrain's rmse: 0.169099\tTest's rmse: 0.0216602\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000648 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:11,490]\u001b[0m Trial 39 finished with value: 0.02647932852475202 and parameters: {'learning_rate': 0.5032437194213003, 'num_leaves': 46, 'tree_learner': 'serial'}. Best is trial 27 with value: 0.02078244450868839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[8]\tTrain's rmse: 0.167645\tTest's rmse: 0.0264793\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000896 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:11,891]\u001b[0m Trial 40 finished with value: 0.02176284970128963 and parameters: {'learning_rate': 0.10331014829549645, 'num_leaves': 33, 'tree_learner': 'feature'}. Best is trial 27 with value: 0.02078244450868839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\tTrain's rmse: 0.16494\tTest's rmse: 0.0217629\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:12,258]\u001b[0m Trial 41 finished with value: 0.024739066904008965 and parameters: {'learning_rate': 0.26259214179949275, 'num_leaves': 48, 'tree_learner': 'voting'}. Best is trial 27 with value: 0.02078244450868839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[21]\tTrain's rmse: 0.154143\tTest's rmse: 0.0247391\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:12,671]\u001b[0m Trial 42 finished with value: 0.021961574691580214 and parameters: {'learning_rate': 0.20663513168084338, 'num_leaves': 45, 'tree_learner': 'voting'}. Best is trial 27 with value: 0.02078244450868839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[23]\tTrain's rmse: 0.164649\tTest's rmse: 0.0219616\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:12,969]\u001b[0m Trial 43 finished with value: 0.023717542409972425 and parameters: {'learning_rate': 0.24420262639929413, 'num_leaves': 38, 'tree_learner': 'voting'}. Best is trial 27 with value: 0.02078244450868839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[21]\tTrain's rmse: 0.163824\tTest's rmse: 0.0237175\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001301 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:13,218]\u001b[0m Trial 44 finished with value: 0.022879362221206897 and parameters: {'learning_rate': 0.33756915440103524, 'num_leaves': 34, 'tree_learner': 'voting'}. Best is trial 27 with value: 0.02078244450868839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[15]\tTrain's rmse: 0.162318\tTest's rmse: 0.0228794\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000843 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:13,585]\u001b[0m Trial 45 finished with value: 0.022151214804556806 and parameters: {'learning_rate': 0.14499284807581056, 'num_leaves': 41, 'tree_learner': 'voting'}. Best is trial 27 with value: 0.02078244450868839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[29]\tTrain's rmse: 0.167817\tTest's rmse: 0.0221512\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\tTrain's rmse: 0.169834\tTest's rmse: 0.0217257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:13,778]\u001b[0m Trial 46 finished with value: 0.02172564847495537 and parameters: {'learning_rate': 0.18700124084945485, 'num_leaves': 23, 'tree_learner': 'data'}. Best is trial 27 with value: 0.02078244450868839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001262 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:14,020]\u001b[0m Trial 47 finished with value: 0.02469125360190063 and parameters: {'learning_rate': 0.4287003113520362, 'num_leaves': 31, 'tree_learner': 'voting'}. Best is trial 27 with value: 0.02078244450868839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[9]\tTrain's rmse: 0.170058\tTest's rmse: 0.0246913\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:14,440]\u001b[0m Trial 48 finished with value: 0.02085491336023865 and parameters: {'learning_rate': 0.13039864164211237, 'num_leaves': 47, 'tree_learner': 'voting'}. Best is trial 27 with value: 0.02078244450868839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[33]\tTrain's rmse: 0.167286\tTest's rmse: 0.0208549\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:14,891]\u001b[0m Trial 49 finished with value: 0.0211049511813424 and parameters: {'learning_rate': 0.10995360650544653, 'num_leaves': 47, 'tree_learner': 'voting'}. Best is trial 27 with value: 0.02078244450868839.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[41]\tTrain's rmse: 0.164292\tTest's rmse: 0.021105\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:15,286]\u001b[0m Trial 50 finished with value: 0.020420414122997988 and parameters: {'learning_rate': 0.13108976893663318, 'num_leaves': 46, 'tree_learner': 'serial'}. Best is trial 50 with value: 0.020420414122997988.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[34]\tTrain's rmse: 0.168006\tTest's rmse: 0.0204204\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001280 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:15,557]\u001b[0m Trial 51 finished with value: 0.025154264934133516 and parameters: {'learning_rate': 0.9799225307341667, 'num_leaves': 47, 'tree_learner': 'serial'}. Best is trial 50 with value: 0.020420414122997988.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[7]\tTrain's rmse: 0.177793\tTest's rmse: 0.0251543\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001297 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:15,923]\u001b[0m Trial 52 finished with value: 0.02096205170343346 and parameters: {'learning_rate': 0.14101891946401063, 'num_leaves': 44, 'tree_learner': 'serial'}. Best is trial 50 with value: 0.020420414122997988.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[31]\tTrain's rmse: 0.166013\tTest's rmse: 0.0209621\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001537 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:16,323]\u001b[0m Trial 53 finished with value: 0.020624269225745707 and parameters: {'learning_rate': 0.13560757251683472, 'num_leaves': 42, 'tree_learner': 'serial'}. Best is trial 50 with value: 0.020420414122997988.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[29]\tTrain's rmse: 0.168609\tTest's rmse: 0.0206243\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001308 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:16,723]\u001b[0m Trial 54 finished with value: 0.02222794319943891 and parameters: {'learning_rate': 0.13211437627143, 'num_leaves': 42, 'tree_learner': 'serial'}. Best is trial 50 with value: 0.020420414122997988.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[30]\tTrain's rmse: 0.169783\tTest's rmse: 0.0222279\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:16,947]\u001b[0m Trial 55 finished with value: 0.02932222739261083 and parameters: {'learning_rate': 0.5968485495968481, 'num_leaves': 40, 'tree_learner': 'serial'}. Best is trial 50 with value: 0.020420414122997988.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[5]\tTrain's rmse: 0.173794\tTest's rmse: 0.0293222\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:17,291]\u001b[0m Trial 56 finished with value: 0.02123676173702446 and parameters: {'learning_rate': 0.160415823969227, 'num_leaves': 43, 'tree_learner': 'serial'}. Best is trial 50 with value: 0.020420414122997988.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[28]\tTrain's rmse: 0.166252\tTest's rmse: 0.0212368\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:17,572]\u001b[0m Trial 57 finished with value: 0.02434295020931479 and parameters: {'learning_rate': 0.2626905648936132, 'num_leaves': 37, 'tree_learner': 'serial'}. Best is trial 50 with value: 0.020420414122997988.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[21]\tTrain's rmse: 0.154136\tTest's rmse: 0.024343\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001243 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:18,028]\u001b[0m Trial 58 finished with value: 0.021525890108685414 and parameters: {'learning_rate': 0.10420077545050974, 'num_leaves': 45, 'tree_learner': 'serial'}. Best is trial 50 with value: 0.020420414122997988.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[37]\tTrain's rmse: 0.173519\tTest's rmse: 0.0215259\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001286 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:18,414]\u001b[0m Trial 59 finished with value: 0.021824879832333586 and parameters: {'learning_rate': 0.23566535324180635, 'num_leaves': 49, 'tree_learner': 'serial'}. Best is trial 50 with value: 0.020420414122997988.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[16]\tTrain's rmse: 0.169578\tTest's rmse: 0.0218249\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001826 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:18,900]\u001b[0m Trial 60 finished with value: 0.021295647519031805 and parameters: {'learning_rate': 0.19147864767887723, 'num_leaves': 41, 'tree_learner': 'feature'}. Best is trial 50 with value: 0.020420414122997988.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[28]\tTrain's rmse: 0.164774\tTest's rmse: 0.0212956\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001303 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:19,362]\u001b[0m Trial 61 finished with value: 0.02323397315669798 and parameters: {'learning_rate': 0.14168073448520932, 'num_leaves': 44, 'tree_learner': 'serial'}. Best is trial 50 with value: 0.020420414122997988.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[31]\tTrain's rmse: 0.164513\tTest's rmse: 0.023234\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001865 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:19,854]\u001b[0m Trial 62 finished with value: 0.021588438591058943 and parameters: {'learning_rate': 0.13304950134667826, 'num_leaves': 43, 'tree_learner': 'serial'}. Best is trial 50 with value: 0.020420414122997988.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[34]\tTrain's rmse: 0.165311\tTest's rmse: 0.0215884\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002616 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:20,240]\u001b[0m Trial 63 finished with value: 0.020881386493663074 and parameters: {'learning_rate': 0.1593742556160937, 'num_leaves': 39, 'tree_learner': 'serial'}. Best is trial 50 with value: 0.020420414122997988.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[25]\tTrain's rmse: 0.166797\tTest's rmse: 0.0208814\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000798 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:20,706]\u001b[0m Trial 64 finished with value: 0.02084635481640051 and parameters: {'learning_rate': 0.1688406215641684, 'num_leaves': 39, 'tree_learner': 'serial'}. Best is trial 50 with value: 0.020420414122997988.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[25]\tTrain's rmse: 0.166966\tTest's rmse: 0.0208464\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001338 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:21,287]\u001b[0m Trial 65 finished with value: 0.022867706478256557 and parameters: {'learning_rate': 0.20055113544459624, 'num_leaves': 40, 'tree_learner': 'serial'}. Best is trial 50 with value: 0.020420414122997988.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[22]\tTrain's rmse: 0.167353\tTest's rmse: 0.0228677\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000967 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:21,591]\u001b[0m Trial 66 finished with value: 0.024583771557596525 and parameters: {'learning_rate': 0.3333890289738325, 'num_leaves': 37, 'tree_learner': 'serial'}. Best is trial 50 with value: 0.020420414122997988.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[14]\tTrain's rmse: 0.164058\tTest's rmse: 0.0245838\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001309 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:21,991]\u001b[0m Trial 67 finished with value: 0.021205983612689487 and parameters: {'learning_rate': 0.23467279018709997, 'num_leaves': 47, 'tree_learner': 'data'}. Best is trial 50 with value: 0.020420414122997988.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[19]\tTrain's rmse: 0.166877\tTest's rmse: 0.021206\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000968 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:22,460]\u001b[0m Trial 68 finished with value: 0.0214060581465804 and parameters: {'learning_rate': 0.12336223174839782, 'num_leaves': 42, 'tree_learner': 'serial'}. Best is trial 50 with value: 0.020420414122997988.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tTrain's rmse: 0.165031\tTest's rmse: 0.0214061\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001216 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:22,748]\u001b[0m Trial 69 finished with value: 0.02413621912972225 and parameters: {'learning_rate': 0.29311270593325506, 'num_leaves': 35, 'tree_learner': 'serial'}. Best is trial 50 with value: 0.020420414122997988.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[13]\tTrain's rmse: 0.178837\tTest's rmse: 0.0241362\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:22,981]\u001b[0m Trial 70 finished with value: 0.02585709590367987 and parameters: {'learning_rate': 0.7428783484182717, 'num_leaves': 38, 'tree_learner': 'feature'}. Best is trial 50 with value: 0.020420414122997988.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[3]\tTrain's rmse: 0.190009\tTest's rmse: 0.0258571\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:23,352]\u001b[0m Trial 71 finished with value: 0.01946861960634616 and parameters: {'learning_rate': 0.1691201673106029, 'num_leaves': 40, 'tree_learner': 'serial'}. Best is trial 71 with value: 0.01946861960634616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[27]\tTrain's rmse: 0.165719\tTest's rmse: 0.0194686\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:23,673]\u001b[0m Trial 72 finished with value: 0.02076569749643054 and parameters: {'learning_rate': 0.16964972768083225, 'num_leaves': 33, 'tree_learner': 'serial'}. Best is trial 71 with value: 0.01946861960634616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[28]\tTrain's rmse: 0.167625\tTest's rmse: 0.0207657\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000678 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:23,958]\u001b[0m Trial 73 finished with value: 0.02122948539079294 and parameters: {'learning_rate': 0.1647686058981519, 'num_leaves': 32, 'tree_learner': 'serial'}. Best is trial 71 with value: 0.01946861960634616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[26]\tTrain's rmse: 0.165843\tTest's rmse: 0.0212295\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001135 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:24,301]\u001b[0m Trial 74 finished with value: 0.023715653110201986 and parameters: {'learning_rate': 0.2171936466392036, 'num_leaves': 39, 'tree_learner': 'serial'}. Best is trial 71 with value: 0.01946861960634616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[19]\tTrain's rmse: 0.165502\tTest's rmse: 0.0237157\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:24,597]\u001b[0m Trial 75 finished with value: 0.021056877455494276 and parameters: {'learning_rate': 0.17871209130560084, 'num_leaves': 45, 'tree_learner': 'serial'}. Best is trial 71 with value: 0.01946861960634616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tTrain's rmse: 0.16928\tTest's rmse: 0.0210569\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001425 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:24,837]\u001b[0m Trial 76 finished with value: 0.026088124559984792 and parameters: {'learning_rate': 0.2725709594237697, 'num_leaves': 36, 'tree_learner': 'serial'}. Best is trial 71 with value: 0.01946861960634616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[13]\tTrain's rmse: 0.170231\tTest's rmse: 0.0260881\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000869 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:25,124]\u001b[0m Trial 77 finished with value: 0.02035579627471195 and parameters: {'learning_rate': 0.20870690685836596, 'num_leaves': 34, 'tree_learner': 'serial'}. Best is trial 71 with value: 0.01946861960634616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[25]\tTrain's rmse: 0.16444\tTest's rmse: 0.0203558\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001296 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:25,369]\u001b[0m Trial 78 finished with value: 0.022936207473807802 and parameters: {'learning_rate': 0.2444529043007803, 'num_leaves': 33, 'tree_learner': 'serial'}. Best is trial 71 with value: 0.01946861960634616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[19]\tTrain's rmse: 0.166968\tTest's rmse: 0.0229362\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:25,704]\u001b[0m Trial 79 finished with value: 0.020521872137237693 and parameters: {'learning_rate': 0.211333465473045, 'num_leaves': 34, 'tree_learner': 'serial'}. Best is trial 71 with value: 0.01946861960634616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[19]\tTrain's rmse: 0.167492\tTest's rmse: 0.0205219\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001796 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:26,023]\u001b[0m Trial 80 finished with value: 0.02195357991733273 and parameters: {'learning_rate': 0.2176690452493096, 'num_leaves': 30, 'tree_learner': 'serial'}. Best is trial 71 with value: 0.01946861960634616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[20]\tTrain's rmse: 0.167797\tTest's rmse: 0.0219536\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:26,358]\u001b[0m Trial 81 finished with value: 0.02116749027470344 and parameters: {'learning_rate': 0.19342059045983617, 'num_leaves': 33, 'tree_learner': 'serial'}. Best is trial 71 with value: 0.01946861960634616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[21]\tTrain's rmse: 0.170424\tTest's rmse: 0.0211675\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001318 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:26,734]\u001b[0m Trial 82 finished with value: 0.01986350710165981 and parameters: {'learning_rate': 0.16373765518832756, 'num_leaves': 37, 'tree_learner': 'serial'}. Best is trial 71 with value: 0.01946861960634616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[28]\tTrain's rmse: 0.16739\tTest's rmse: 0.0198635\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001319 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:27,295]\u001b[0m Trial 83 finished with value: 0.022004903167467924 and parameters: {'learning_rate': 0.15318260085155747, 'num_leaves': 35, 'tree_learner': 'serial'}. Best is trial 71 with value: 0.01946861960634616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[31]\tTrain's rmse: 0.161579\tTest's rmse: 0.0220049\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002248 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:27,764]\u001b[0m Trial 84 finished with value: 0.02241390271601557 and parameters: {'learning_rate': 0.2509462859255977, 'num_leaves': 37, 'tree_learner': 'serial'}. Best is trial 71 with value: 0.01946861960634616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tTrain's rmse: 0.163643\tTest's rmse: 0.0224139\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:28,059]\u001b[0m Trial 85 finished with value: 0.030145561219287548 and parameters: {'learning_rate': 0.4007023188278033, 'num_leaves': 34, 'tree_learner': 'serial'}. Best is trial 71 with value: 0.01946861960634616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[14]\tTrain's rmse: 0.155093\tTest's rmse: 0.0301456\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001816 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:28,346]\u001b[0m Trial 86 finished with value: 0.024414045252745938 and parameters: {'learning_rate': 0.3145302969427297, 'num_leaves': 31, 'tree_learner': 'serial'}. Best is trial 71 with value: 0.01946861960634616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[13]\tTrain's rmse: 0.168681\tTest's rmse: 0.024414\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000990 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:28,640]\u001b[0m Trial 87 finished with value: 0.030902849136819524 and parameters: {'learning_rate': 0.5130565548918125, 'num_leaves': 36, 'tree_learner': 'serial'}. Best is trial 71 with value: 0.01946861960634616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[5]\tTrain's rmse: 0.178609\tTest's rmse: 0.0309029\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001768 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:28,922]\u001b[0m Trial 88 finished with value: 0.024844037376837328 and parameters: {'learning_rate': 0.2792451262094433, 'num_leaves': 29, 'tree_learner': 'serial'}. Best is trial 71 with value: 0.01946861960634616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[20]\tTrain's rmse: 0.161247\tTest's rmse: 0.024844\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:29,224]\u001b[0m Trial 89 finished with value: 0.024385611544487647 and parameters: {'learning_rate': 0.47753024499783386, 'num_leaves': 34, 'tree_learner': 'serial'}. Best is trial 71 with value: 0.01946861960634616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[9]\tTrain's rmse: 0.161214\tTest's rmse: 0.0243856\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:29,559]\u001b[0m Trial 90 finished with value: 0.021817633611100687 and parameters: {'learning_rate': 0.11847719271710791, 'num_leaves': 27, 'tree_learner': 'data'}. Best is trial 71 with value: 0.01946861960634616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tTrain's rmse: 0.166552\tTest's rmse: 0.0218176\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001429 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:29,945]\u001b[0m Trial 91 finished with value: 0.02223720656203685 and parameters: {'learning_rate': 0.17215851458482506, 'num_leaves': 38, 'tree_learner': 'serial'}. Best is trial 71 with value: 0.01946861960634616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[26]\tTrain's rmse: 0.16792\tTest's rmse: 0.0222372\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001343 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:30,392]\u001b[0m Trial 92 finished with value: 0.022931700278238376 and parameters: {'learning_rate': 0.21204464744188856, 'num_leaves': 40, 'tree_learner': 'serial'}. Best is trial 71 with value: 0.01946861960634616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[19]\tTrain's rmse: 0.167606\tTest's rmse: 0.0229317\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002772 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:31,206]\u001b[0m Trial 93 finished with value: 0.021807139379993335 and parameters: {'learning_rate': 0.18591284509443395, 'num_leaves': 42, 'tree_learner': 'serial'}. Best is trial 71 with value: 0.01946861960634616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tTrain's rmse: 0.164849\tTest's rmse: 0.0218071\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002505 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:31,829]\u001b[0m Trial 94 finished with value: 0.022020311705012122 and parameters: {'learning_rate': 0.15288829192505027, 'num_leaves': 37, 'tree_learner': 'serial'}. Best is trial 71 with value: 0.01946861960634616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[25]\tTrain's rmse: 0.169263\tTest's rmse: 0.0220203\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001402 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:32,189]\u001b[0m Trial 95 finished with value: 0.02961353035891432 and parameters: {'learning_rate': 0.6432623897817598, 'num_leaves': 41, 'tree_learner': 'serial'}. Best is trial 71 with value: 0.01946861960634616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[4]\tTrain's rmse: 0.187712\tTest's rmse: 0.0296135\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:32,577]\u001b[0m Trial 96 finished with value: 0.022181395437829106 and parameters: {'learning_rate': 0.12338998034483643, 'num_leaves': 32, 'tree_learner': 'serial'}. Best is trial 71 with value: 0.01946861960634616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[35]\tTrain's rmse: 0.164489\tTest's rmse: 0.0221814\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:32,958]\u001b[0m Trial 97 finished with value: 0.020044191219426872 and parameters: {'learning_rate': 0.20335477450323228, 'num_leaves': 39, 'tree_learner': 'serial'}. Best is trial 71 with value: 0.01946861960634616.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:33,094]\u001b[0m Trial 98 finished with value: 0.03427475480018838 and parameters: {'learning_rate': 0.2248457217472556, 'num_leaves': 5, 'tree_learner': 'serial'}. Best is trial 71 with value: 0.01946861960634616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[20]\tTrain's rmse: 0.169586\tTest's rmse: 0.0200442\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001701 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\tTrain's rmse: 0.172613\tTest's rmse: 0.0342748\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001620 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:33,438]\u001b[0m Trial 99 finished with value: 0.0220959837002175 and parameters: {'learning_rate': 0.20426729853334186, 'num_leaves': 38, 'tree_learner': 'feature'}. Best is trial 71 with value: 0.01946861960634616.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tTrain's rmse: 0.161562\tTest's rmse: 0.022096\n",
      "{'learning_rate': 0.1691201673106029, 'num_leaves': 40, 'tree_learner': 'serial'}\n",
      "{'learning_rate': 0.1691201673106029, 'num_leaves': 40, 'tree_learner': 'serial', 'objective': 'regression', 'metric': 'rmse', 'task': 'train', 'seed': 42}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001096 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 10733, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.394992\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tTrain's rmse: 0.165719\tTest's rmse: 0.0194686\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:34,022]\u001b[0m A new study created in memory with name: no-name-483d2789-70ef-472f-9d38-f6de2b084e72\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:34,194]\u001b[0m Trial 0 finished with value: 0.3747862075923346 and parameters: {'learning_rate': 0.1666576629933066, 'num_leaves': 18, 'tree_learner': 'feature'}. Best is trial 0 with value: 0.3747862075923346.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tTrain's rmse: 0.160415\tTest's rmse: 0.374786\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:34,419]\u001b[0m Trial 1 finished with value: 0.36521370247742335 and parameters: {'learning_rate': 0.3210734397823005, 'num_leaves': 37, 'tree_learner': 'voting'}. Best is trial 1 with value: 0.36521370247742335.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[10]\tTrain's rmse: 0.153412\tTest's rmse: 0.365214\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:34,713]\u001b[0m Trial 2 finished with value: 0.3694937447834595 and parameters: {'learning_rate': 0.34382989446392287, 'num_leaves': 49, 'tree_learner': 'feature'}. Best is trial 1 with value: 0.36521370247742335.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[10]\tTrain's rmse: 0.15205\tTest's rmse: 0.369494\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:34,909]\u001b[0m Trial 3 finished with value: 0.37662963873044514 and parameters: {'learning_rate': 0.11583801818330541, 'num_leaves': 22, 'tree_learner': 'voting'}. Best is trial 1 with value: 0.36521370247742335.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[30]\tTrain's rmse: 0.155807\tTest's rmse: 0.37663\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001205 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:35,111]\u001b[0m Trial 4 finished with value: 0.3767814195357042 and parameters: {'learning_rate': 0.5478850624484968, 'num_leaves': 26, 'tree_learner': 'data'}. Best is trial 1 with value: 0.36521370247742335.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[5]\tTrain's rmse: 0.160605\tTest's rmse: 0.376781\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001373 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tTrain's rmse: 0.184479\tTest's rmse: 0.367957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:35,297]\u001b[0m Trial 5 finished with value: 0.36795710247643154 and parameters: {'learning_rate': 0.9958962314638299, 'num_leaves': 30, 'tree_learner': 'data'}. Best is trial 1 with value: 0.36521370247742335.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001516 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:35,551]\u001b[0m Trial 6 finished with value: 0.3703947438791577 and parameters: {'learning_rate': 0.17325005411253472, 'num_leaves': 33, 'tree_learner': 'serial'}. Best is trial 1 with value: 0.36521370247742335.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:35,688]\u001b[0m Trial 7 finished with value: 0.38721706559828234 and parameters: {'learning_rate': 0.6096769160390674, 'num_leaves': 21, 'tree_learner': 'serial'}. Best is trial 1 with value: 0.36521370247742335.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[19]\tTrain's rmse: 0.155927\tTest's rmse: 0.370395\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tTrain's rmse: 0.149953\tTest's rmse: 0.387217\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001319 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:35,825]\u001b[0m Trial 8 finished with value: 0.36035424629844404 and parameters: {'learning_rate': 0.4394767390958213, 'num_leaves': 17, 'tree_learner': 'serial'}. Best is trial 8 with value: 0.36035424629844404.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[6]\tTrain's rmse: 0.161213\tTest's rmse: 0.360354\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001299 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:36,112]\u001b[0m Trial 9 finished with value: 0.373250814626678 and parameters: {'learning_rate': 0.33952122645929683, 'num_leaves': 47, 'tree_learner': 'data'}. Best is trial 8 with value: 0.36035424629844404.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:36,195]\u001b[0m Trial 10 finished with value: 0.3590849116568313 and parameters: {'learning_rate': 0.7222462120400597, 'num_leaves': 7, 'tree_learner': 'serial'}. Best is trial 10 with value: 0.3590849116568313.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:36,277]\u001b[0m Trial 11 finished with value: 0.36016329801816693 and parameters: {'learning_rate': 0.7393704747952059, 'num_leaves': 5, 'tree_learner': 'serial'}. Best is trial 10 with value: 0.3590849116568313.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[10]\tTrain's rmse: 0.15308\tTest's rmse: 0.373251\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001281 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tTrain's rmse: 0.164074\tTest's rmse: 0.359085\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001285 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\tTrain's rmse: 0.121751\tTest's rmse: 0.360163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:36,365]\u001b[0m Trial 12 finished with value: 0.33641321670672764 and parameters: {'learning_rate': 0.7842953391240057, 'num_leaves': 6, 'tree_learner': 'serial'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:36,449]\u001b[0m Trial 13 finished with value: 0.34937383267084177 and parameters: {'learning_rate': 0.8151015550339349, 'num_leaves': 5, 'tree_learner': 'serial'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001391 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tTrain's rmse: 0.170304\tTest's rmse: 0.336413\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tTrain's rmse: 0.171252\tTest's rmse: 0.349374\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001302 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:36,558]\u001b[0m Trial 14 finished with value: 0.3803098956245152 and parameters: {'learning_rate': 0.9424825662447202, 'num_leaves': 11, 'tree_learner': 'serial'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:36,663]\u001b[0m Trial 15 finished with value: 0.356758069515452 and parameters: {'learning_rate': 0.8481400295908386, 'num_leaves': 12, 'tree_learner': 'serial'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[5]\tTrain's rmse: 0.147991\tTest's rmse: 0.38031\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001099 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tTrain's rmse: 0.147027\tTest's rmse: 0.356758\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tTrain's rmse: 0.154543\tTest's rmse: 0.35669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:36,766]\u001b[0m Trial 16 finished with value: 0.3566902249841196 and parameters: {'learning_rate': 0.7889133785167255, 'num_leaves': 12, 'tree_learner': 'serial'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:36,837]\u001b[0m Trial 17 finished with value: 0.37023680274952164 and parameters: {'learning_rate': 0.6147955899799968, 'num_leaves': 6, 'tree_learner': 'voting'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000858 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tTrain's rmse: 0.194105\tTest's rmse: 0.370237\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000956 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tTrain's rmse: 0.108687\tTest's rmse: 0.36467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:36,969]\u001b[0m Trial 18 finished with value: 0.364669848597981 and parameters: {'learning_rate': 0.8564687033168272, 'num_leaves': 13, 'tree_learner': 'feature'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000879 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:37,208]\u001b[0m Trial 19 finished with value: 0.37354225403222957 and parameters: {'learning_rate': 0.6696646063258481, 'num_leaves': 41, 'tree_learner': 'serial'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:37,364]\u001b[0m Trial 20 finished with value: 0.373470153350396 and parameters: {'learning_rate': 0.8497561440475551, 'num_leaves': 25, 'tree_learner': 'serial'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[8]\tTrain's rmse: 0.143913\tTest's rmse: 0.373542\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000883 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tTrain's rmse: 0.171886\tTest's rmse: 0.37347\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:37,458]\u001b[0m Trial 21 finished with value: 0.35915753075794554 and parameters: {'learning_rate': 0.7734970110808856, 'num_leaves': 10, 'tree_learner': 'serial'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[5]\tTrain's rmse: 0.157949\tTest's rmse: 0.359158\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001245 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:37,680]\u001b[0m Trial 22 finished with value: 0.36859127988181456 and parameters: {'learning_rate': 0.8987905564000617, 'num_leaves': 16, 'tree_learner': 'serial'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:37,822]\u001b[0m Trial 23 finished with value: 0.39158946002804346 and parameters: {'learning_rate': 0.7887161524303338, 'num_leaves': 9, 'tree_learner': 'serial'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.0433243\tTest's rmse: 0.368591\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.0530215\tTest's rmse: 0.391589\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:38,005]\u001b[0m Trial 24 finished with value: 0.37120618944729167 and parameters: {'learning_rate': 0.5077921222547828, 'num_leaves': 15, 'tree_learner': 'serial'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tTrain's rmse: 0.151534\tTest's rmse: 0.371206\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:38,093]\u001b[0m Trial 25 finished with value: 0.33987862388058704 and parameters: {'learning_rate': 0.6475426376403322, 'num_leaves': 7, 'tree_learner': 'serial'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:38,166]\u001b[0m Trial 26 finished with value: 0.351036732220442 and parameters: {'learning_rate': 0.6516109983115131, 'num_leaves': 5, 'tree_learner': 'feature'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:38,254]\u001b[0m Trial 27 finished with value: 0.35311380457106467 and parameters: {'learning_rate': 0.6847033772060883, 'num_leaves': 8, 'tree_learner': 'voting'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[4]\tTrain's rmse: 0.190013\tTest's rmse: 0.339879\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tTrain's rmse: 0.178484\tTest's rmse: 0.351037\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000882 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tTrain's rmse: 0.151914\tTest's rmse: 0.353114\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000874 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:38,394]\u001b[0m Trial 28 finished with value: 0.3631801369838645 and parameters: {'learning_rate': 0.4689260669967851, 'num_leaves': 21, 'tree_learner': 'data'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tTrain's rmse: 0.15264\tTest's rmse: 0.36318\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:38,531]\u001b[0m Trial 29 finished with value: 0.3633239469844643 and parameters: {'learning_rate': 0.5958649160369325, 'num_leaves': 19, 'tree_learner': 'feature'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:38,636]\u001b[0m Trial 30 finished with value: 0.3898745972695139 and parameters: {'learning_rate': 0.9354779462563039, 'num_leaves': 14, 'tree_learner': 'serial'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:38,691]\u001b[0m Trial 31 finished with value: 0.35686198020311133 and parameters: {'learning_rate': 0.6735542916835991, 'num_leaves': 5, 'tree_learner': 'feature'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[5]\tTrain's rmse: 0.156686\tTest's rmse: 0.363324\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000881 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tTrain's rmse: 0.196366\tTest's rmse: 0.389875\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000895 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tTrain's rmse: 0.200842\tTest's rmse: 0.356862\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001299 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:38,816]\u001b[0m Trial 32 finished with value: 0.3578951814501772 and parameters: {'learning_rate': 0.6393408424815399, 'num_leaves': 9, 'tree_learner': 'feature'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:38,894]\u001b[0m Trial 33 finished with value: 0.36236399176250206 and parameters: {'learning_rate': 0.7194300413904898, 'num_leaves': 5, 'tree_learner': 'feature'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[6]\tTrain's rmse: 0.161544\tTest's rmse: 0.357895\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002195 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tTrain's rmse: 0.167686\tTest's rmse: 0.362364\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tTrain's rmse: 0.160846\tTest's rmse: 0.351311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:38,982]\u001b[0m Trial 34 finished with value: 0.3513108804435287 and parameters: {'learning_rate': 0.5759257066374481, 'num_leaves': 8, 'tree_learner': 'feature'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:39,102]\u001b[0m Trial 35 finished with value: 0.3460896929137689 and parameters: {'learning_rate': 0.8105402347312706, 'num_leaves': 10, 'tree_learner': 'voting'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001232 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tTrain's rmse: 0.155283\tTest's rmse: 0.34609\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tTrain's rmse: 0.151083\tTest's rmse: 0.342771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:39,204]\u001b[0m Trial 36 finished with value: 0.34277109356478586 and parameters: {'learning_rate': 0.8260026640235762, 'num_leaves': 10, 'tree_learner': 'voting'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:39,389]\u001b[0m Trial 37 finished with value: 0.36421892627924984 and parameters: {'learning_rate': 0.9082112647699967, 'num_leaves': 17, 'tree_learner': 'voting'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000898 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\tTrain's rmse: 0.0982858\tTest's rmse: 0.364219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:39,560]\u001b[0m Trial 38 finished with value: 0.36971938385175496 and parameters: {'learning_rate': 0.989080943609814, 'num_leaves': 29, 'tree_learner': 'voting'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000883 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tTrain's rmse: 0.184686\tTest's rmse: 0.369719\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001201 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:39,770]\u001b[0m Trial 39 finished with value: 0.3713460278840277 and parameters: {'learning_rate': 0.74873181323962, 'num_leaves': 36, 'tree_learner': 'voting'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:39,932]\u001b[0m Trial 40 finished with value: 0.3663734585728112 and parameters: {'learning_rate': 0.8262923638683313, 'num_leaves': 25, 'tree_learner': 'voting'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[3]\tTrain's rmse: 0.161836\tTest's rmse: 0.371346\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000929 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tTrain's rmse: 0.145059\tTest's rmse: 0.366373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:40,041]\u001b[0m Trial 41 finished with value: 0.3547355045393529 and parameters: {'learning_rate': 0.812743622551356, 'num_leaves': 11, 'tree_learner': 'voting'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000904 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tTrain's rmse: 0.158544\tTest's rmse: 0.354736\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001009 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:40,179]\u001b[0m Trial 42 finished with value: 0.3622741428021313 and parameters: {'learning_rate': 0.8922136176622598, 'num_leaves': 8, 'tree_learner': 'voting'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.0472323\tTest's rmse: 0.362274\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000889 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.061874\tTest's rmse: 0.343935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:40,369]\u001b[0m Trial 43 finished with value: 0.3439346456820313 and parameters: {'learning_rate': 0.7068942523309277, 'num_leaves': 14, 'tree_learner': 'data'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:40,504]\u001b[0m Trial 44 finished with value: 0.3748623513328558 and parameters: {'learning_rate': 0.249499216653285, 'num_leaves': 14, 'tree_learner': 'data'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tTrain's rmse: 0.156102\tTest's rmse: 0.374862\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:40,607]\u001b[0m Trial 45 finished with value: 0.35909959545936526 and parameters: {'learning_rate': 0.7184267978564927, 'num_leaves': 10, 'tree_learner': 'data'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:40,747]\u001b[0m Trial 46 finished with value: 0.36105047870246376 and parameters: {'learning_rate': 0.5578509791340206, 'num_leaves': 19, 'tree_learner': 'data'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[9]\tTrain's rmse: 0.142904\tTest's rmse: 0.3591\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001409 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tTrain's rmse: 0.159014\tTest's rmse: 0.36105\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:40,831]\u001b[0m Trial 47 finished with value: 0.36183495546878114 and parameters: {'learning_rate': 0.7598347255547777, 'num_leaves': 7, 'tree_learner': 'data'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[6]\tTrain's rmse: 0.161935\tTest's rmse: 0.361835\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001277 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:41,073]\u001b[0m Trial 48 finished with value: 0.36520998544237987 and parameters: {'learning_rate': 0.7151299141686407, 'num_leaves': 13, 'tree_learner': 'voting'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:41,171]\u001b[0m Trial 49 finished with value: 0.35322091129514666 and parameters: {'learning_rate': 0.414484177049702, 'num_leaves': 10, 'tree_learner': 'voting'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.0552516\tTest's rmse: 0.36521\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tTrain's rmse: 0.159919\tTest's rmse: 0.353221\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000609 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:41,314]\u001b[0m Trial 50 finished with value: 0.3584646355536725 and parameters: {'learning_rate': 0.8735692564493865, 'num_leaves': 22, 'tree_learner': 'data'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:41,394]\u001b[0m Trial 51 finished with value: 0.3600719015426457 and parameters: {'learning_rate': 0.8189026149825668, 'num_leaves': 7, 'tree_learner': 'serial'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[3]\tTrain's rmse: 0.162166\tTest's rmse: 0.358465\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tTrain's rmse: 0.198907\tTest's rmse: 0.360072\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001318 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tTrain's rmse: 0.169518\tTest's rmse: 0.375892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:41,501]\u001b[0m Trial 52 finished with value: 0.3758919312877996 and parameters: {'learning_rate': 0.8064381529159967, 'num_leaves': 12, 'tree_learner': 'serial'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:41,578]\u001b[0m Trial 53 finished with value: 0.34838573418320595 and parameters: {'learning_rate': 0.6967855060349801, 'num_leaves': 7, 'tree_learner': 'serial'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:41,662]\u001b[0m Trial 54 finished with value: 0.3436341937853038 and parameters: {'learning_rate': 0.6260476218677006, 'num_leaves': 7, 'tree_learner': 'serial'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001059 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tTrain's rmse: 0.172378\tTest's rmse: 0.348386\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000874 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tTrain's rmse: 0.190528\tTest's rmse: 0.343634\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:41,756]\u001b[0m Trial 55 finished with value: 0.35019016806895287 and parameters: {'learning_rate': 0.6359828559892534, 'num_leaves': 10, 'tree_learner': 'voting'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:41,878]\u001b[0m Trial 56 finished with value: 0.35961984699279337 and parameters: {'learning_rate': 0.6116876536829553, 'num_leaves': 15, 'tree_learner': 'serial'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[5]\tTrain's rmse: 0.159711\tTest's rmse: 0.35019\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tTrain's rmse: 0.152723\tTest's rmse: 0.35962\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000764 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:42,150]\u001b[0m Trial 57 finished with value: 0.3514137543488436 and parameters: {'learning_rate': 0.7730953595616396, 'num_leaves': 50, 'tree_learner': 'data'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:42,254]\u001b[0m Trial 58 finished with value: 0.36274511506381646 and parameters: {'learning_rate': 0.5290024715503643, 'num_leaves': 12, 'tree_learner': 'serial'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[5]\tTrain's rmse: 0.149285\tTest's rmse: 0.351414\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001161 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tTrain's rmse: 0.161501\tTest's rmse: 0.362745\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000863 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tTrain's rmse: 0.166197\tTest's rmse: 0.343815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:42,328]\u001b[0m Trial 59 finished with value: 0.34381486913214315 and parameters: {'learning_rate': 0.7473452540674689, 'num_leaves': 6, 'tree_learner': 'serial'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001320 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:42,599]\u001b[0m Trial 60 finished with value: 0.3710518404967628 and parameters: {'learning_rate': 0.7516860580149543, 'num_leaves': 46, 'tree_learner': 'serial'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:42,672]\u001b[0m Trial 61 finished with value: 0.36620183674739637 and parameters: {'learning_rate': 0.6632784745979152, 'num_leaves': 6, 'tree_learner': 'serial'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:42,765]\u001b[0m Trial 62 finished with value: 0.3547451828277884 and parameters: {'learning_rate': 0.695633218001316, 'num_leaves': 9, 'tree_learner': 'serial'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[3]\tTrain's rmse: 0.161358\tTest's rmse: 0.371052\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000999 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tTrain's rmse: 0.202637\tTest's rmse: 0.366202\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001273 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tTrain's rmse: 0.172113\tTest's rmse: 0.354745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:42,839]\u001b[0m Trial 63 finished with value: 0.36580731950583295 and parameters: {'learning_rate': 0.735482650139762, 'num_leaves': 6, 'tree_learner': 'serial'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:42,956]\u001b[0m Trial 64 finished with value: 0.3571199328747946 and parameters: {'learning_rate': 0.7879796620281808, 'num_leaves': 11, 'tree_learner': 'serial'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tTrain's rmse: 0.200396\tTest's rmse: 0.365807\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000876 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tTrain's rmse: 0.155546\tTest's rmse: 0.35712\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003718 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:43,070]\u001b[0m Trial 65 finished with value: 0.3527576747354433 and parameters: {'learning_rate': 0.8600813667471032, 'num_leaves': 8, 'tree_learner': 'voting'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tTrain's rmse: 0.115336\tTest's rmse: 0.352758\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001004 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:43,289]\u001b[0m Trial 66 finished with value: 0.3652519527808508 and parameters: {'learning_rate': 0.6342925423063673, 'num_leaves': 32, 'tree_learner': 'serial'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:43,358]\u001b[0m Trial 67 finished with value: 0.34451299530509194 and parameters: {'learning_rate': 0.9364130101490836, 'num_leaves': 5, 'tree_learner': 'serial'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:43,431]\u001b[0m Trial 68 finished with value: 0.3540091399883667 and parameters: {'learning_rate': 0.9942172558576674, 'num_leaves': 5, 'tree_learner': 'serial'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[6]\tTrain's rmse: 0.150692\tTest's rmse: 0.365252\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001313 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tTrain's rmse: 0.209849\tTest's rmse: 0.344513\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tTrain's rmse: 0.229793\tTest's rmse: 0.354009\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000918 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:43,508]\u001b[0m Trial 69 finished with value: 0.3686773964418699 and parameters: {'learning_rate': 0.9396265207402497, 'num_leaves': 7, 'tree_learner': 'serial'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:43,583]\u001b[0m Trial 70 finished with value: 0.3673678845517098 and parameters: {'learning_rate': 0.589489483668345, 'num_leaves': 5, 'tree_learner': 'serial'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:43,674]\u001b[0m Trial 71 finished with value: 0.3673018868188153 and parameters: {'learning_rate': 0.8865054494841007, 'num_leaves': 9, 'tree_learner': 'serial'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tTrain's rmse: 0.232386\tTest's rmse: 0.368677\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001291 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tTrain's rmse: 0.156497\tTest's rmse: 0.367368\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001212 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tTrain's rmse: 0.164365\tTest's rmse: 0.367302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:43,797]\u001b[0m Trial 72 finished with value: 0.36548021925124996 and parameters: {'learning_rate': 0.8374221493553166, 'num_leaves': 13, 'tree_learner': 'serial'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:43,883]\u001b[0m Trial 73 finished with value: 0.3526658893715786 and parameters: {'learning_rate': 0.6935800556912346, 'num_leaves': 8, 'tree_learner': 'voting'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001326 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tTrain's rmse: 0.147014\tTest's rmse: 0.36548\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001266 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tTrain's rmse: 0.150942\tTest's rmse: 0.352666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:43,957]\u001b[0m Trial 74 finished with value: 0.3384876009318426 and parameters: {'learning_rate': 0.9618177811409166, 'num_leaves': 6, 'tree_learner': 'data'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:44,030]\u001b[0m Trial 75 finished with value: 0.33841351341919845 and parameters: {'learning_rate': 0.9643225877373245, 'num_leaves': 6, 'tree_learner': 'data'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tTrain's rmse: 0.197483\tTest's rmse: 0.338488\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001273 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tTrain's rmse: 0.197581\tTest's rmse: 0.338414\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001520 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:44,103]\u001b[0m Trial 76 finished with value: 0.37052731603156136 and parameters: {'learning_rate': 0.9727336992496246, 'num_leaves': 6, 'tree_learner': 'data'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:44,202]\u001b[0m Trial 77 finished with value: 0.38339184310949537 and parameters: {'learning_rate': 0.9658043563614325, 'num_leaves': 11, 'tree_learner': 'data'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1]\tTrain's rmse: 0.249663\tTest's rmse: 0.370527\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001563 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tTrain's rmse: 0.150298\tTest's rmse: 0.383392\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tTrain's rmse: 0.16119\tTest's rmse: 0.366434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:44,288]\u001b[0m Trial 78 finished with value: 0.36643448828024977 and parameters: {'learning_rate': 0.9580991435565364, 'num_leaves': 9, 'tree_learner': 'data'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:44,372]\u001b[0m Trial 79 finished with value: 0.3550576536842673 and parameters: {'learning_rate': 0.5008671903126778, 'num_leaves': 7, 'tree_learner': 'data'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tTrain's rmse: 0.157488\tTest's rmse: 0.355058\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001325 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\tTrain's rmse: 0.154037\tTest's rmse: 0.350715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:44,498]\u001b[0m Trial 80 finished with value: 0.3507148662547661 and parameters: {'learning_rate': 0.12179639900596145, 'num_leaves': 6, 'tree_learner': 'data'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:44,574]\u001b[0m Trial 81 finished with value: 0.34412627859959843 and parameters: {'learning_rate': 0.9169339222839893, 'num_leaves': 5, 'tree_learner': 'data'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:44,662]\u001b[0m Trial 82 finished with value: 0.4044774768825698 and parameters: {'learning_rate': 0.908201851304272, 'num_leaves': 8, 'tree_learner': 'data'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001288 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tTrain's rmse: 0.158992\tTest's rmse: 0.344126\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001266 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2]\tTrain's rmse: 0.182516\tTest's rmse: 0.404477\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:44,767]\u001b[0m Trial 83 finished with value: 0.36160083225756107 and parameters: {'learning_rate': 0.9213792290634627, 'num_leaves': 6, 'tree_learner': 'data'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:44,867]\u001b[0m Trial 84 finished with value: 0.3908680165901176 and parameters: {'learning_rate': 0.8640201542889588, 'num_leaves': 9, 'tree_learner': 'data'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[8]\tTrain's rmse: 0.157417\tTest's rmse: 0.361601\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001652 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tTrain's rmse: 0.135189\tTest's rmse: 0.390868\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001381 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tTrain's rmse: 0.172556\tTest's rmse: 0.355765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:44,961]\u001b[0m Trial 85 finished with value: 0.3557651511775746 and parameters: {'learning_rate': 0.7930486547018782, 'num_leaves': 7, 'tree_learner': 'data'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:45,068]\u001b[0m Trial 86 finished with value: 0.3597910458396216 and parameters: {'learning_rate': 0.8403485931523632, 'num_leaves': 11, 'tree_learner': 'data'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:45,147]\u001b[0m Trial 87 finished with value: 0.34417191144785647 and parameters: {'learning_rate': 0.9183024250462255, 'num_leaves': 5, 'tree_learner': 'data'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001291 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tTrain's rmse: 0.152197\tTest's rmse: 0.359791\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tTrain's rmse: 0.158978\tTest's rmse: 0.344172\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:45,234]\u001b[0m Trial 88 finished with value: 0.35208049603679403 and parameters: {'learning_rate': 0.7309314338729573, 'num_leaves': 8, 'tree_learner': 'data'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:45,344]\u001b[0m Trial 89 finished with value: 0.35900475661352615 and parameters: {'learning_rate': 0.7689506759464118, 'num_leaves': 10, 'tree_learner': 'data'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tTrain's rmse: 0.164647\tTest's rmse: 0.35208\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tTrain's rmse: 0.158157\tTest's rmse: 0.359005\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:45,465]\u001b[0m Trial 90 finished with value: 0.37595213792842574 and parameters: {'learning_rate': 0.8816949000460401, 'num_leaves': 14, 'tree_learner': 'data'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:45,547]\u001b[0m Trial 91 finished with value: 0.3441688267182088 and parameters: {'learning_rate': 0.9182103089176018, 'num_leaves': 5, 'tree_learner': 'data'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tTrain's rmse: 0.152351\tTest's rmse: 0.375952\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000961 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tTrain's rmse: 0.158979\tTest's rmse: 0.344169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:45,626]\u001b[0m Trial 92 finished with value: 0.3607410440261389 and parameters: {'learning_rate': 0.9625938307321602, 'num_leaves': 7, 'tree_learner': 'data'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:45,697]\u001b[0m Trial 93 finished with value: 0.3638790197561309 and parameters: {'learning_rate': 0.9976939911544891, 'num_leaves': 6, 'tree_learner': 'data'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tTrain's rmse: 0.22996\tTest's rmse: 0.360741\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tTrain's rmse: 0.248938\tTest's rmse: 0.363879\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001203 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:45,768]\u001b[0m Trial 94 finished with value: 0.3632319343787057 and parameters: {'learning_rate': 0.660352348485791, 'num_leaves': 5, 'tree_learner': 'feature'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:45,911]\u001b[0m Trial 95 finished with value: 0.37309457214190284 and parameters: {'learning_rate': 0.898843935264515, 'num_leaves': 8, 'tree_learner': 'data'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[5]\tTrain's rmse: 0.191912\tTest's rmse: 0.363232\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001243 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.0289646\tTest's rmse: 0.373095\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001788 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:46,103]\u001b[0m Trial 96 finished with value: 0.3480904138544388 and parameters: {'learning_rate': 0.71378071183368, 'num_leaves': 12, 'tree_learner': 'data'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:46,187]\u001b[0m Trial 97 finished with value: 0.3438830999818651 and parameters: {'learning_rate': 0.6244213301506654, 'num_leaves': 7, 'tree_learner': 'data'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tTrain's rmse: 0.0518194\tTest's rmse: 0.34809\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tTrain's rmse: 0.19054\tTest's rmse: 0.343883\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001291 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tTrain's rmse: 0.156409\tTest's rmse: 0.360248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-27 16:23:46,290]\u001b[0m Trial 98 finished with value: 0.36024778236757404 and parameters: {'learning_rate': 0.572199355916612, 'num_leaves': 10, 'tree_learner': 'serial'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n",
      "\u001b[32m[I 2021-12-27 16:23:46,386]\u001b[0m Trial 99 finished with value: 0.34251410999875437 and parameters: {'learning_rate': 0.6181182440535021, 'num_leaves': 9, 'tree_learner': 'data'}. Best is trial 12 with value: 0.33641321670672764.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001272 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tTrain's rmse: 0.153225\tTest's rmse: 0.342514\n",
      "{'learning_rate': 0.7842953391240057, 'num_leaves': 6, 'tree_learner': 'serial'}\n",
      "{'learning_rate': 0.7842953391240057, 'num_leaves': 6, 'tree_learner': 'serial', 'objective': 'regression', 'metric': 'rmse', 'task': 'train', 'seed': 42}\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001274 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 10820, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 0.352462\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tTrain's rmse: 0.170304\tTest's rmse: 0.336413\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: [0.3060021768681886, 0.1031734898537942, 0.10749593802589563, 0.01946861960634616, 0.33641321670672764]\n",
      "RMSE: 0.17451068821219046\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train.reset_index(drop=True)\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "groups = X_train_ce[\"Genre\"]\n",
    "\n",
    "params = {\n",
    "          'task': 'train',              # タスクを訓練に設定\n",
    "          'boosting_type': 'gbdt',      # GBDTを指定\n",
    "          'objective': 'regression',    # 回帰を指定\n",
    "          'metric': 'rmse',             # 回帰の損失（誤差）\n",
    "          'learning_rate': 0.1,         # 学習率\n",
    "          'seed': SEED                   # シード値\n",
    "          }\n",
    "\n",
    "cv_result_opt2 = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(gkf.split(X_train_ce, y_train, groups)):\n",
    "    X_train_gkf, X_test_gkf = X_train_ce.iloc[train_index], X_train_ce.iloc[test_index]\n",
    "    y_train_gkf, y_test_gkf = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "    # 学習、推論\n",
    "    lgb_train = lgb.Dataset(X_train_gkf, y_train_gkf)\n",
    "    lgb_test = lgb.Dataset(X_test_gkf, y_test_gkf, reference=lgb_train)\n",
    "\n",
    "    lgb_results = {}                                    # 学習の履歴を入れる入物\n",
    "    \n",
    "    study = optuna.create_study()\n",
    "    study.optimize(objective, n_trials=100)\n",
    "\n",
    "    print(study.best_params)\n",
    "\n",
    "    best_params = study.best_params\n",
    "\n",
    "    add_params = {\n",
    "        'objective':'regression', \n",
    "        'metric': 'rmse', \n",
    "        'task': 'train', \n",
    "        'seed': SEED\n",
    "        }\n",
    "\n",
    "    best_params.update(add_params)\n",
    "\n",
    "    print(best_params)\n",
    "\n",
    "    model = lgb.train(\n",
    "                    params=best_params,               # ハイパーパラメータをセット\n",
    "                    train_set=lgb_train,              # 訓練データを訓練用にセット\n",
    "                    valid_sets=[lgb_train, lgb_test], # 訓練データとテストデータをセット\n",
    "                    valid_names=['Train', 'Test'],    # データセットの名前をそれぞれ設定\n",
    "                    num_boost_round=100,              # 計算回数\n",
    "                    early_stopping_rounds=50,         # アーリーストッピング設定\n",
    "                    evals_result=lgb_results,\n",
    "                    verbose_eval=-1,                  # ログを最後の1つだけ表示\n",
    "                    )\n",
    "\n",
    "    # 損失推移を表示\n",
    "    loss_train = lgb_results['Train']['rmse']\n",
    "    loss_test = lgb_results['Test']['rmse']   \n",
    "    \n",
    "    fig = plt.figure()\n",
    "    \n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('logloss')\n",
    "\n",
    "    plt.title(f\"fold:{fold}\")\n",
    "    plt.plot(loss_train, label='train loss')\n",
    "    plt.plot(loss_test, label='test loss')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # 推論\n",
    "    y_pred = model.predict(X_test_gkf)\n",
    "\n",
    "    # 評価\n",
    "    rmse = mean_squared_error(y_test_gkf, y_pred, squared=False)\n",
    "    cv_result_opt2.append(rmse)\n",
    "\n",
    "print(\"RMSE:\", cv_result_opt2)\n",
    "print(\"RMSE:\", np.mean(cv_result_opt2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5kNarUXOe2k7",
    "outputId": "9f1d7099-c1ce-45b2-98fe-371ab6d6676d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.199\n",
      "Optuna によるハイパラ調整 1 RMSE: 0.182\n",
      "Optuna によるハイパラ調整 2 RMSE: 0.175\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE:\", round(np.mean(cv_result), 3))\n",
    "print(\"Optuna によるハイパラ調整 1 RMSE:\", round(np.mean(cv_result_opt), 3))\n",
    "print(\"Optuna によるハイパラ調整 2 RMSE:\", round(np.mean(cv_result_opt2), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "24iOMAJyNG_y"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "09_optuna_hyper_parameter_tuning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
